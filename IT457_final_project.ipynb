{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqd5evBR6CZ-"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgYGAYQZFR5f",
        "outputId": "f2e924bc-2110-4059-da07-916b47149615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting word2number\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=728b5377984b9fdbaa3fe76077b0b8e8597172f0766438d3a5f2d1da3df4e9ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install word2number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltPmUaBVFPlB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from word2number import w2n\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Dense,ELU\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import BatchNormalization,LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import torch\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5fw_GBdV96N"
      },
      "source": [
        "# Importing nltk for removing stopwords, word_tokenize and WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZxcDsfAV9KT",
        "outputId": "3fe629ef-f4f1-41d2-8764-82df424477b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frXLvLN_bqNH"
      },
      "source": [
        "# Importing Fiqatask1 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcysNKiG6N3C"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/fiqatask1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eRepYOBc6XRw",
        "outputId": "1902cd7b-05eb-4885-b9ed-541553800f1f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 498,\n  \"fields\": [\n    {\n      \"column\": \"No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 512.897703134483,\n        \"min\": 1.0,\n        \"max\": 1779.0,\n        \"num_unique_values\": 436,\n        \"samples\": [\n          1581.0,\n          257.0,\n          1052.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 436,\n        \"samples\": [\n          \"Berkshire discloses unit's ties to Iran, opens probe\",\n          \"How Kraft-Heinz Merger Came Together in Speedy 10 Weeks\",\n          \"US dollar wipes out sales gains for SABMiller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__snippets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 458,\n        \"samples\": [\n          \"['chases Acerta to secure next cancer drug winner']\",\n          \"['Smartphone Market Regains Strength']\",\n          \"['Britain's FTSE outperforms Europe, Royal Mail and Tesco rise']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 226,\n        \"samples\": [\n          \"Royal Dutch Shell\",\n          \"JP Morgan Chase\",\n          \"Zurich Insurance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_sentiment_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3757132285813035,\n        \"min\": -0.938,\n        \"max\": 0.975,\n        \"num_unique_values\": 407,\n        \"samples\": [\n          0.315,\n          0.357,\n          0.593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_aspects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 82,\n        \"samples\": [\n          \"['Corporate/Appointment/Staff Hiring']\",\n          \"['Corporate/Appointment']\",\n          \"['Corporate/Dividend Policy/Dividend/Dividend going up']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cf57eed2-2abe-4af7-95a1-c8e92ee1edba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>sentence</th>\n",
              "      <th>info__snippets</th>\n",
              "      <th>info__target</th>\n",
              "      <th>info_sentiment_score</th>\n",
              "      <th>info_aspects</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
              "      <td>['set to step down']</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
              "      <td>['Facing Tough Competition']</td>\n",
              "      <td>AstraZeneca</td>\n",
              "      <td>-0.240</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>UPDATE 1-Dairy Crest loses a third of Morrison...</td>\n",
              "      <td>['Crest loses a third of Morrisons milk contra...</td>\n",
              "      <td>Morrisons</td>\n",
              "      <td>-0.161</td>\n",
              "      <td>['Corporate/Sales/Failed Contract Discussion']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.0</td>\n",
              "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
              "      <td>['hires Aviva's David Hillier for multi-asset ...</td>\n",
              "      <td>Insight</td>\n",
              "      <td>0.137</td>\n",
              "      <td>['Corporate/Appointment/Executive Appointment']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.0</td>\n",
              "      <td>Primark racks up a happy Christmas after stron...</td>\n",
              "      <td>['after strong sales']</td>\n",
              "      <td>Primark</td>\n",
              "      <td>0.704</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>1750.0</td>\n",
              "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
              "      <td>['M&amp;G suspend property funds as investors panic']</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>-0.807</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>1754.0</td>\n",
              "      <td>UK housing market steadies after Brexit dip, P...</td>\n",
              "      <td>['housing market']</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>0.339</td>\n",
              "      <td>['Market/Market']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1755.0</td>\n",
              "      <td>BRIEF-Aviva aims to increase dividend pay-out ...</td>\n",
              "      <td>['increase dividend pay-out']</td>\n",
              "      <td>Aviva</td>\n",
              "      <td>0.439</td>\n",
              "      <td>['Corporate/Dividend Policy']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1764.0</td>\n",
              "      <td>Builder Persimmon hails 6% rise in house sales</td>\n",
              "      <td>['6% rise in house sales']</td>\n",
              "      <td>Persimmon</td>\n",
              "      <td>0.435</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1779.0</td>\n",
              "      <td>EasyJet attracts more passengers in June but s...</td>\n",
              "      <td>['attracts more passengers']</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>0.259</td>\n",
              "      <td>['Corporate/Sales/Sales']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf57eed2-2abe-4af7-95a1-c8e92ee1edba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf57eed2-2abe-4af7-95a1-c8e92ee1edba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf57eed2-2abe-4af7-95a1-c8e92ee1edba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-df2aa700-e598-4fe2-a2a5-bc43525ffbca\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-df2aa700-e598-4fe2-a2a5-bc43525ffbca')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-df2aa700-e598-4fe2-a2a5-bc43525ffbca button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ab1a69db-8382-4f86-ab99-e661f72785d7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ab1a69db-8382-4f86-ab99-e661f72785d7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         No                                           sentence  \\\n",
              "0       1.0  Royal Mail chairman Donald Brydon set to step ...   \n",
              "1       7.0  Stakes High for AstraZeneca Heart Drug Facing ...   \n",
              "2       8.0  UPDATE 1-Dairy Crest loses a third of Morrison...   \n",
              "3      22.0  Insight hires Aviva's David Hillier for multi-...   \n",
              "4      30.0  Primark racks up a happy Christmas after stron...   \n",
              "..      ...                                                ...   \n",
              "493  1750.0  Aviva, M&G suspend property funds as investors...   \n",
              "494  1754.0  UK housing market steadies after Brexit dip, P...   \n",
              "495  1755.0  BRIEF-Aviva aims to increase dividend pay-out ...   \n",
              "496  1764.0     Builder Persimmon hails 6% rise in house sales   \n",
              "497  1779.0  EasyJet attracts more passengers in June but s...   \n",
              "\n",
              "                                        info__snippets info__target  \\\n",
              "0                                 ['set to step down']   Royal Mail   \n",
              "1                         ['Facing Tough Competition']  AstraZeneca   \n",
              "2    ['Crest loses a third of Morrisons milk contra...    Morrisons   \n",
              "3    ['hires Aviva's David Hillier for multi-asset ...      Insight   \n",
              "4                               ['after strong sales']      Primark   \n",
              "..                                                 ...          ...   \n",
              "493  ['M&G suspend property funds as investors panic']          M&G   \n",
              "494                                 ['housing market']    Perssimon   \n",
              "495                      ['increase dividend pay-out']        Aviva   \n",
              "496                         ['6% rise in house sales']    Persimmon   \n",
              "497                       ['attracts more passengers']      Ryanair   \n",
              "\n",
              "     info_sentiment_score                                     info_aspects  \n",
              "0                  -0.374                        ['Corporate/Appointment']  \n",
              "1                  -0.240                              ['Corporate/Risks']  \n",
              "2                  -0.161   ['Corporate/Sales/Failed Contract Discussion']  \n",
              "3                   0.137  ['Corporate/Appointment/Executive Appointment']  \n",
              "4                   0.704                              ['Corporate/Sales']  \n",
              "..                    ...                                              ...  \n",
              "493                -0.807                              ['Corporate/Risks']  \n",
              "494                 0.339                                ['Market/Market']  \n",
              "495                 0.439                    ['Corporate/Dividend Policy']  \n",
              "496                 0.435                              ['Corporate/Sales']  \n",
              "497                 0.259                        ['Corporate/Sales/Sales']  \n",
              "\n",
              "[498 rows x 6 columns]"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2A2P0NqWjtp"
      },
      "source": [
        "# info_sentiment_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "JiMj9QRzWbvY",
        "outputId": "d1a0661a-d451-4269-d1ab-0e6c099e38d8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "df['info_sentiment_score'].plot(kind='hist', bins=20, title='info_sentiment_score')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpTfe7S8Wv8-",
        "outputId": "1ee1a79b-35a1-4e20-e381-4f386d1d4629"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['No', 'sentence', 'info__snippets', 'info__target',\n",
              "       'info_sentiment_score', 'info_aspects'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjOtLbtHW4WF"
      },
      "source": [
        "#Data Preprocessing : Convert to lowercase,  Remove punctuation, Tokenizing text, Removal of stopwords, Applying lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kP_FwYKzW3po",
        "outputId": "236164c5-fc3c-479f-f353-a0c7f6dcf230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                              sentence  \\\n",
            "0    Royal Mail chairman Donald Brydon set to step ...   \n",
            "1    Stakes High for AstraZeneca Heart Drug Facing ...   \n",
            "2    UPDATE 1-Dairy Crest loses a third of Morrison...   \n",
            "3    Insight hires Aviva's David Hillier for multi-...   \n",
            "4    Primark racks up a happy Christmas after stron...   \n",
            "..                                                 ...   \n",
            "493  Aviva, M&G suspend property funds as investors...   \n",
            "494  UK housing market steadies after Brexit dip, P...   \n",
            "495  BRIEF-Aviva aims to increase dividend pay-out ...   \n",
            "496     Builder Persimmon hails 6% rise in house sales   \n",
            "497  EasyJet attracts more passengers in June but s...   \n",
            "\n",
            "                                 preprocessed_sentence  \n",
            "0           royal mail chairman donald brydon set step  \n",
            "1    stake high astrazeneca heart drug face tough c...  \n",
            "2    update 1 dairy crest lose third morrison milk ...  \n",
            "3    insight hire aviva david hillier multi asset team  \n",
            "4             primark rack happy christmas strong sale  \n",
            "..                                                 ...  \n",
            "493     aviva m&g suspend property fund investor panic  \n",
            "494  uk housing market steady brexit dip persimmon say  \n",
            "495  brief aviva aim increase dividend pay ratio 50...  \n",
            "496           builder persimmon hail 6 rise house sale  \n",
            "497         easyjet attract passenger june lag ryanair  \n",
            "\n",
            "[498 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "nlp = spacy.load('en_core_web_sm')\n",
        "def preprocess_text(text):\n",
        "    if(not isinstance(text, str)):\n",
        "        text = str(text)\n",
        "    text = text.lower()\n",
        "    doc = nlp(text)\n",
        "    tokens = []\n",
        "    for token in doc:\n",
        "        if token.like_num:\n",
        "            tokens.append(token.text)\n",
        "        elif not token.is_stop and not token.is_punct:\n",
        "            tokens.append(token.lemma_)\n",
        "    return ' '.join(tokens)\n",
        "df['preprocessed_sentence'] = df['sentence'].apply(preprocess_text)\n",
        "print(df[['sentence', 'preprocessed_sentence']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "ZiKkK71dXzmO",
        "outputId": "2af0970f-1121-4af1-fc46-028f5e465e47"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preprocessed_sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>royal mail chairman donald brydon set step</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stake high astrazeneca heart drug face tough c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>update 1 dairy crest lose third morrison milk ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>insight hire aviva david hillier multi asset team</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>primark rack happy christmas strong sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>aviva m&amp;g suspend property fund investor panic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>uk housing market steady brexit dip persimmon say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>brief aviva aim increase dividend pay ratio 50...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>builder persimmon hail 6 rise house sale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>easyjet attract passenger june lag ryanair</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0             royal mail chairman donald brydon set step\n",
              "1      stake high astrazeneca heart drug face tough c...\n",
              "2      update 1 dairy crest lose third morrison milk ...\n",
              "3      insight hire aviva david hillier multi asset team\n",
              "4               primark rack happy christmas strong sale\n",
              "                             ...                        \n",
              "493       aviva m&g suspend property fund investor panic\n",
              "494    uk housing market steady brexit dip persimmon say\n",
              "495    brief aviva aim increase dividend pay ratio 50...\n",
              "496             builder persimmon hail 6 rise house sale\n",
              "497           easyjet attract passenger june lag ryanair\n",
              "Name: preprocessed_sentence, Length: 498, dtype: object"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['preprocessed_sentence']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j0LR7QsbxE1"
      },
      "source": [
        "#Loading BERT(pre-trained model and tokenizer) and SPACY for syntactic analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "23ceec00b2d44fd79144f775f53786e9",
            "1b1397f9d3d64145b16f6d2ce0c8c514",
            "87758afdf2ca470e97b27b0e0f346bb8",
            "78ac2776d66c4baea161b859e1dd34db",
            "2d672ce54d5d4d738071aee36615ea5a",
            "e0943783430e45e18b402f7ec91bc36b",
            "0acedf7fc4b54856a3401599c4c1b575",
            "337448028f2d4fc9b3fcff45a366733a",
            "c5430d64738b4e1398e7dbab5ed4987b",
            "4d32711412964337a0f2fb31fc96250e",
            "c3f6d024b01140b4bc5cf00681f52661",
            "baa1d640bd314eb997c957c4114e32ef",
            "e37f5f982c2f45e495be8b9b8b19dcc9",
            "bb62bbbab4624dd8b87de7cb2080b221",
            "d293b7d8db6a4b729a4144c45aa58e4a",
            "e3ba76403163411885603a260e49ff71",
            "299e03e41a7448a2b43565e2309bba5e",
            "b85f118eead94e868a85a07fd80a953d",
            "53c3d7a37fa04bdca19ddf4969188447",
            "bf52c3d1a65a40aeb5300cb7553582f0",
            "6e761b8c1aa74cf795ac41e915ad4cfd",
            "20a59f96c91c4b22bd5565db386c9f03",
            "3ef6c1936d454ac9849e390a28ba7623",
            "75c2d05a172e4425b86e5dcc84aa5070",
            "8eeb10f324d745488d6d62fe6ea3f119",
            "9423f92c65604873a441dd3194b94358",
            "e6b66fdae3f349c6b51b212917ccac0e",
            "42a599a7d40d4c74b0e83016603c8251",
            "f7512de7894c4aea8f55aa4a8c9cda37",
            "8fa9168564084cd1a565e9ffe4451742",
            "7aac0e7e33714029aa0dbb637f0177db",
            "6154a16bb77e4ab18aa53d14abdb4359",
            "5a1c5fe077b2426ab33c1a78cc99fbd8",
            "e1a3e03cad8d419692cc0f5235708e6c",
            "1dfa0dba143f495a9a41145b72cb9552",
            "4f60fb876b5d439cadd16aede0a7e397",
            "1191cb75d06d475a96b4112ffd5a0351",
            "47636113d7b148d8a36e798fed528ae2",
            "65be5a8bd61a46ac8f6bd8036b0b9a74",
            "9ba12b2f82b44a3cb0fe56b5fcaea0eb",
            "2d1546ce67484d939ab466cc6c14a0b6",
            "af21d3535a0242438923f9740d89a8cf",
            "d6f7f2c806a04f5a9936fcd1cca26795",
            "98efec6368af461eb3c13ae940bee34e",
            "cee26bec055047e9acfb1d4f811e1587",
            "ed90eab72d9f4b1a96d2701a108f7beb",
            "31d54641a7ac46c6922fa695f35676b9",
            "19a88c4289e047d89941364fa6bbca89",
            "9634e556b5974b69b9b5076ccc66c8cb",
            "42f02cf2caeb4fbda1eee011e8dd9900",
            "0500ddf077224311993e90e6c8761299",
            "48be7e4d84b04e94b2f196ac7c46e263",
            "5b4efbb193d74e139e11a2c0cf70e996",
            "fe8ca4d9c71f4724a74ef2af03ab364e",
            "986d746ef78545248b7848981f2e77f9"
          ]
        },
        "id": "-M0CJyod6i27",
        "outputId": "bcaf34ed-08e5-4d30-c821-ccf370cd9f81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23ceec00b2d44fd79144f775f53786e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baa1d640bd314eb997c957c4114e32ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ef6c1936d454ac9849e390a28ba7623",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1a3e03cad8d419692cc0f5235708e6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cee26bec055047e9acfb1d4f811e1587",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',clean_up_tokenization_spaces=True)\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekWq7lQDb-IK"
      },
      "source": [
        "# BERT embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lKBZi5z6oLP"
      },
      "outputs": [],
      "source": [
        "def get_bert_embeddings(sentences, tokenizer, model):\n",
        "    sentences = [s for s in sentences if isinstance(s, str)]\n",
        "    inputs = tokenizer(sentences, return_tensors='pt', padding=True, truncation=True, max_length=50)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "    return cls_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW9qjkZK6t5l",
        "outputId": "e62d83fc-71d5-403a-a59b-426c77169ed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT Embeddings Shape: torch.Size([498, 768])\n",
            "tensor([[-0.1573,  0.1368,  0.1011,  ..., -0.1020,  0.0516,  0.1758],\n",
            "        [-0.6635,  0.0580,  0.0088,  ..., -0.2303,  0.5818,  0.1199],\n",
            "        [-0.2898, -0.1630, -0.2003,  ..., -0.1376, -0.0443,  0.4348],\n",
            "        ...,\n",
            "        [-0.3253, -0.0235,  0.2436,  ...,  0.0631,  0.3182,  0.4077],\n",
            "        [-0.1589,  0.1944,  0.1013,  ..., -0.2016,  0.0854,  0.1301],\n",
            "        [-0.2950, -0.0129,  0.2963,  ..., -0.1853,  0.3825,  0.0023]])\n"
          ]
        }
      ],
      "source": [
        "sentences = df['preprocessed_sentence'].tolist()\n",
        "\n",
        "sentences = [str(s) for s in sentences]\n",
        "\n",
        "bert_embeddings = get_bert_embeddings(sentences, tokenizer, bert_model)\n",
        "print(f\"BERT Embeddings Shape: {bert_embeddings.shape}\")\n",
        "print(bert_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34KPHzHacDXK"
      },
      "source": [
        "# Digit CNN class implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlRA-Wh06wrb"
      },
      "outputs": [],
      "source": [
        "class DigitCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DigitCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool1d(5)\n",
        "        self.fc = nn.Linear(16 * 5, 3)\n",
        "        self.out_features = self.fc.out_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = torch.relu(x)\n",
        "        if x.shape[-1] >= 2:\n",
        "            x = self.pool(x)\n",
        "        if x.shape[-1] < 5:\n",
        "            padding_needed = 5 - x.shape[-1]\n",
        "            x = torch.nn.functional.pad(x, (0, padding_needed))\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "digit_cnn = DigitCNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SRty_aFcJGc"
      },
      "source": [
        "# Dependeny tree for numerical values like monetory,percentage and temporary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnJWIMx77W46"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def extract_numerical_info(preprocessed_sentence):\n",
        "    doc = nlp(preprocessed_sentence)\n",
        "    numerical_info = []\n",
        "\n",
        "    for token in doc:\n",
        "        if token.like_num or token.is_digit or token.pos_ == \"ORDINAL\":\n",
        "            num_type = None\n",
        "            aspect = None\n",
        "\n",
        "            if token.dep_ == \"nummod\":\n",
        "                if token.head.text in [\"%\", \"percentage\", \"percent\"]:\n",
        "                    num_type = \"percentage\"\n",
        "                else:\n",
        "                    num_type = \"cardinal\"\n",
        "                aspect = token.head.text\n",
        "\n",
        "            elif token.dep_ in [\"pobj\", \"dobj\"]:\n",
        "                if token.head.text in [\"after\", \"before\", \"during\", \"since\", \"for\", \"in\"]:\n",
        "                    num_type = \"temporal\"\n",
        "                aspect = token.head.text\n",
        "\n",
        "            # Modified amod handling\n",
        "            elif token.dep_ == \"amod\":\n",
        "                if token.pos_ == \"ORDINAL\":\n",
        "                    num_type = \"ordinal\"\n",
        "                    aspect = token.head.text\n",
        "                elif token.head.ent_type_ in [\"MONEY\", \"PERCENT\", \"DATE\", \"TIME\"]:\n",
        "                    num_type = token.head.ent_type_.lower()\n",
        "                    aspect = token.head.text\n",
        "\n",
        "                elif (token.is_digit or token.like_num) and num_type is None:\n",
        "                    num_type = \"cardinal\"\n",
        "                    aspect = token.head.text\n",
        "\n",
        "            if num_type is None:\n",
        "                if token.text.startswith(\"-\"):\n",
        "                    num_type = \"negative\"\n",
        "                    aspect = \"negative value\"\n",
        "                elif token.is_digit and num_type is None:\n",
        "                    num_type = \"cardinal\"\n",
        "                    aspect = token.head.text\n",
        "\n",
        "            dep_type = token.dep_ if token.dep_ in [\"nummod\", \"amod\"] else None\n",
        "\n",
        "            if num_type is not None:\n",
        "                numerical_info.append({\n",
        "                    \"value\": token.text,\n",
        "                    \"type\": num_type,\n",
        "                    \"aspect\": aspect,\n",
        "                    \"dependency_type\": dep_type,\n",
        "                })\n",
        "\n",
        "    return numerical_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaqqoWcE7Zvo",
        "outputId": "123cdac8-93cb-4c77-825c-70f0eddaf9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[{'value': '1', 'type': 'cardinal', 'aspect': 'crest', 'dependency_type': 'nummod'}, {'value': 'third', 'type': 'cardinal', 'aspect': 'contract', 'dependency_type': 'amod'}]\n"
          ]
        }
      ],
      "source": [
        "df[\"numerical_info\"] = df[\"preprocessed_sentence\"].apply(extract_numerical_info)\n",
        "print(df['numerical_info'][0])\n",
        "print(df['numerical_info'][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RbkSSQzeQNT",
        "outputId": "ded33ad2-7e2f-481f-e63e-37d0c16984cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                                     []\n",
            "1                                                     []\n",
            "2      [{'value': '1', 'type': 'cardinal', 'aspect': ...\n",
            "3                                                     []\n",
            "4                                                     []\n",
            "                             ...                        \n",
            "493                                                   []\n",
            "494                                                   []\n",
            "495    [{'value': '50', 'type': 'cardinal', 'aspect':...\n",
            "496    [{'value': '6', 'type': 'cardinal', 'aspect': ...\n",
            "497                                                   []\n",
            "Name: numerical_info, Length: 498, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['numerical_info'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUAts6e_cM_j"
      },
      "source": [
        "# Encode numerical values using Digit CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUyydvAk7dCh"
      },
      "outputs": [],
      "source": [
        "def encode_numerical_values(numerical_info):\n",
        "    encoded_values = []\n",
        "    has_numerical_values = False\n",
        "\n",
        "    for num_info in numerical_info:\n",
        "        try:\n",
        "            num_str = num_info['value']\n",
        "            num_type = num_info['type']\n",
        "\n",
        "            if num_type == 'ordinal' or num_type == 'cardinal':\n",
        "                try:\n",
        "\n",
        "                    if num_str.isdigit() or num_str.replace('.', '', 1).isdigit():\n",
        "                        num = float(num_str)\n",
        "                    else:\n",
        "\n",
        "                        num = w2n.word_to_num(num_str.lower())\n",
        "                except ValueError:\n",
        "                    num = 0\n",
        "\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            tensor = torch.tensor([[num]], dtype=torch.float32).unsqueeze(0)\n",
        "            encoded_output = digit_cnn(tensor)\n",
        "\n",
        "            encoded_values.append(encoded_output.view(1, -1))\n",
        "            has_numerical_values = True\n",
        "\n",
        "        except ValueError:\n",
        "            print(f\"ValueError encountered for input: {num_info}\")\n",
        "            continue\n",
        "\n",
        "    if not has_numerical_values:\n",
        "        return torch.zeros(1, 3)\n",
        "\n",
        "    return torch.cat(encoded_values, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWAOieLF7s-6",
        "outputId": "7f44a9f4-6144-4feb-8ba7-4429f46f6c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.]])\n",
            "tensor([[0., 0., 0.]])\n",
            "tensor([[ 0.0584, -0.0858, -0.0869,  0.0923, -0.1185, -0.1205]],\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "df['encoded_values'] = df['numerical_info'].apply(encode_numerical_values)\n",
        "print(df['encoded_values'][0])\n",
        "print(df['encoded_values'][1])\n",
        "print(df['encoded_values'][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuwAZBfueV3Z",
        "outputId": "e139c55b-8a81-45a1-e5bc-a72bd94117d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                 [[tensor(0.), tensor(0.), tensor(0.)]]\n",
            "1                 [[tensor(0.), tensor(0.), tensor(0.)]]\n",
            "2      [[tensor(0.0584, grad_fn=<UnbindBackward0>), t...\n",
            "3                 [[tensor(0.), tensor(0.), tensor(0.)]]\n",
            "4                 [[tensor(0.), tensor(0.), tensor(0.)]]\n",
            "                             ...                        \n",
            "493               [[tensor(0.), tensor(0.), tensor(0.)]]\n",
            "494               [[tensor(0.), tensor(0.), tensor(0.)]]\n",
            "495    [[tensor(-1.7565, grad_fn=<UnbindBackward0>), ...\n",
            "496    [[tensor(-0.1363, grad_fn=<UnbindBackward0>), ...\n",
            "497               [[tensor(0.), tensor(0.), tensor(0.)]]\n",
            "Name: encoded_values, Length: 498, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df['encoded_values'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5ZiFawXcYon"
      },
      "source": [
        "### Printing sentiment scores of each sentences and modifying df inserting sentiment scores :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY9cuCyR7wFS",
        "outputId": "e4b14dbc-91e8-49b6-bd15-2c284e4c5e04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sentiment Scores for Each Sentence:\n",
            "Sentence: royal mail chairman donald brydon set step, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: stake high astrazeneca heart drug face tough competition, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 dairy crest lose third morrison milk contract, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651  0.09229714 -0.11852994 -0.12051044]]\n",
            "Sentence: insight hire aviva david hillier multi asset team, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: primark rack happy christmas strong sale, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 pearson expect grow year solid end 2014, Sentiment Scores: [[ 5.84323183e-02 -8.58367756e-02 -8.68765116e-02 -7.42767944e+01\n",
            "   1.23826485e+02 -4.18569908e+01]]\n",
            "Sentence: tesco sell blinkbox broadband service talktalk, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: unilever profit rise despite sale slump china, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco lead leap ftse 100 mark spencer drop, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: royal dutch shell profit rise dividend 4, Sentiment Scores: [[-0.06113416  0.09656806 -0.14681245]]\n",
            "Sentence: morning agenda shire deal nps, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: carnival corporation china merchant group sign memo understanding, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: teva fda approve generic version astrazeneca heartburn drug, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: passenger rise easyjet aer lingus, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco abandon video stream ambition blinkbox sale, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: fda approve nps drug validate shire takeover deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ocwen reach settlement california regulator, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: morrison face festive sale test, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco share price dip blinkbox book close end supermarket digital, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: shire buy nps $ 5.2 billion boost rare disease drug, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: astrazeneca medimmune ink licensing deal omnis pharmaceutical, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: fda approve shire vyvanse binge eat disorder, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: company thetrainline.com announce arrival london ipo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: breakingviews iag pay aer lingus, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco share price jump q3 sale estimate, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: crh concrete bid holcim lafarge asset, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: persimmon share price climb 23 rise year revenue, Sentiment Scores: [[-0.7676201  1.2736963 -0.52232  ]]\n",
            "Sentence: ruling set low limit potential fine bp, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: reed elsevi share price slide underwhelme year result, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 meggitt reiterate annual outlook tough 2014, Sentiment Scores: [[ 5.84323183e-02 -8.58367756e-02 -8.68765116e-02 -7.42767944e+01\n",
            "   1.23826485e+02 -4.18569908e+01]]\n",
            "Sentence: slump weir lead ftse record high, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bunzl lift dividend acquisition continue boost profit, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: refile update 4 britain lloyds pay first dividend rescue, Sentiment Scores: [[-0.06113416  0.09656806 -0.14681245  0.09229714 -0.11852994 -0.12051044]]\n",
            "Sentence: glaxosmithkline set complete $ 20 billion novartis asset swap week, Sentiment Scores: [[-6.5774810e-01  1.0890675e+00 -4.6030775e-01 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: meggitt share price tumble profit fall challenging year, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: analyst view astrazeneca share see recent volatility 2015, Sentiment Scores: [[-74.31373  123.88804  -41.877747]]\n",
            "Sentence: arm royalty accelerate smartphone market regain strength, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: conagra names hillshire farms ceo connolly post, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bg group appoint new ceo one month early, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: glencore cut 2015 budget plan divest lonmin, Sentiment Scores: [[-74.31373  123.88804  -41.877747]]\n",
            "Sentence: u.s debt lure schroder ecb depress rate, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tullow oil suspend dividend amid oil price fall, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: oil major like royal dutch shell chevron bp fail find reserve counter, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: standard charter lag capital worry, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: standard life share price insurer buy advice firm pearson jones, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco close new chairman dixon carphone john allan frame, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: millercoor deliver 2.9 underlie net income growth 2014, Sentiment Scores: [[-1.97756067e-02  2.80828699e-02 -1.25813127e-01 -7.42767944e+01\n",
            "   1.23826485e+02 -4.18569908e+01]]\n",
            "Sentence: rbs reportedly appoint howard davy chairman, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: hsbc hit fresh detail tax evasion claim, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: relief lewis tesco see sale grow first time year, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: morrison finance chief fill gap ceo leave early, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update persimmon profit strongly outlook positive, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: trlpc crh back lafarge holcim asset buy 6.5 bln euro bridge loan, Sentiment Scores: [[-0.15513088  0.25221616 -0.19453818]]\n",
            "Sentence: tesco shareholder itv head chairman, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: buffett berkshire build deere stake dump exxon, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aviva fine $ 27 million u.k regulator fee failing, Sentiment Scores: [[-9.1411602e-01  1.5198683e+00 -6.0500276e-01 -3.6933438e+04\n",
            "   6.1553691e+04 -2.0764678e+04]]\n",
            "Sentence: astrazeneca patent asthma drug invalidate court, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: roll royce ensure compliance petrobras bribery report, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: whitbread share price climb q4 sale growth, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: warren buffett defend berkshire hathaway conglomerate structure, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: g4s see profit rise uk contract problem remain, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: friend life lift profit 38 hike divi ahead propose aviva takeover, Sentiment Scores: [[-1.3169795  2.1968408 -0.832381 ]]\n",
            "Sentence: auto trader share price surge company float lse, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: new credit suisse boss face stiff challenge asia, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update easyjet passenger number aer lingus traffic february, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: worth invest tesco plc prudential plc, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: uk winner loser aviva friend life lead ftse 100 gainer, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: sainsbury say outperform rival tough market, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companieskingfisher bid mr bricolage run trouble, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 3 auto trader share leap uk big private equity back listing, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: london open taylor wimpey ashtead drive market higher barclay fall, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: gsk novartis complete deal reshape drugmaker, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aviva friend life forecast ahead 5.6 billion pound merger, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: citigroup sell onemain springleaf $ 4.25 billion, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: u.k stock resume gain rally record crh tullow climb, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: british american tobacco drop sue pwc pollution scandal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: uk ftse bad day far 2015 bg prudential fall, Sentiment Scores: [[-74.31373  123.88804  -41.877747]]\n",
            "Sentence: kraft cadbury britvic total recall pull product affect profit, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: kraft heinz merger come speedy 10 week, Sentiment Scores: [[-0.28672627  0.4701236  -0.26135424]]\n",
            "Sentence: astrazeneca team daiichi sankyo sell movantik, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: rbi surprises street sensex pare gain hit mount 30k, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: credit suisse poache prudential thiam asian push, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: kingfisher takeover mr bricolage hit brick wall, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: u.k stock little change near record barclay shell fall, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: insurer admiral blow hot cold aviva soar pre friends life merger, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca daiichi sankyo jointly commercialise movantik, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: legal general arm buy 50 pct stake mediacityuk manchester, Sentiment Scores: [[-1.7564672  2.9353569 -1.0804299]]\n",
            "Sentence: randgold profit hit poor gold price dividend increase, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiestravis perkin lift dividend earning rise 15, Sentiment Scores: [[-0.47462818  0.7813525  -0.3569541 ]]\n",
            "Sentence: market report aviva top market trader approve choice friend, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: insurer old mutual pick standard bank hemphill new ceo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: fda panel back safety update astrazeneca takeda drug, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiesdiageo stay neutral india boardroom turmoil, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: germanwing disaster affect image budget air travel easyjet, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: shell $ 70 billion bg deal meet shareholder skepticism, Sentiment Scores: [[-2.4889472e+00  4.1662164e+00 -1.4938446e+00 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: shell offer 50 percent premium buy bg $ 70 billion, Sentiment Scores: [[-2.4889472  4.1662164 -1.4938446]]\n",
            "Sentence: wpp boost sale despite cautious client, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: shell buy bg group $ 69.7 billion takeover, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: london morning briefing hsbc standard charter share rise, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 bp shareholder disclosure climate change risk, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: shell challenge exxon dominance 47 billion pound bid bg, Sentiment Scores: [[-1.6465955e+00  2.7507277e+00 -1.0184176e+00 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: royal dutch shell buy bg group nearly $ 70 billion, Sentiment Scores: [[-2.4889472  4.1662164 -1.4938446]]\n",
            "Sentence: city spirit sink diageo come short sale slide, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: diageo receive report united spirit financial irregularity involve, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: roll royce win $ 9.2 billion order emirate airline, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: tesco sale rise show tentative recovery continue, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: diageo sale disappoint currency comparative leave bitter taste, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca profit sale stalwart fade, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: whitbread profit sale continue rise look new ceo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glencore blame rival create metal glut, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: doubt grow glaxosmithkline $ 6 bln capital return plan, Sentiment Scores: [[-0.13633153  0.22108659 -0.18499303]]\n",
            "Sentence: easyjet lead britain ftse low global bond rout resume, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: imperial tobacco add quarterly dividend profit rise, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bg group happy shell $ 70 billion offer, Sentiment Scores: [[-2.4889472e+00  4.1662164e+00 -1.4938446e+00 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: sabmiller buy meantime quench thirst craft beer, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aviva shut friends life head office rapid integration, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: retailer kingfisher sport direct rise britain share index, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glaxosmithkline target growth unit scrap viiv ipo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco share price close high two director leave grocer, Sentiment Scores: [[ 0.01406322 -0.02795044 -0.10863185]]\n",
            "Sentence: tesco lead ftse higher clubcard bid report, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: eli lilly co. lly break new high astrazeneca collaboration, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: rpt old mutual q1 gross sale beat forecast 18 pct, Sentiment Scores: [[-0.5845002  0.9659815 -0.4189663]]\n",
            "Sentence: update 3 bp settle oil spill relate claim halliburton transocean, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glaxosmithkline share price slip fda okay asthma therapy adult, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glencore chief blame rival overproduction share price fall, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: philip morris bat sue law take brand pack, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: hargreave lansdown share price fall cost mount pension, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: press serco set appoint roy gardner ex centrica chairman ft, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 cypress semiconductor offer buy integrate silicon solution, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: update 1 nomura rbs pay $ 806 mln mortgage bond case judge, Sentiment Scores: [[  0.05843232  -0.08583678  -0.08687651 -29.661076    49.469456\n",
            "  -16.773298  ]]\n",
            "Sentence: millercoor board name gavin hattersley interim ceo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: britain ftse gain land security dividend hike, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: britain ftse bounce mondi barratt lead, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: old mutual first quarter sale 18 buoy emerge market, Sentiment Scores: [[-0.5845002  0.9659815 -0.4189663]]\n",
            "Sentence: trend underpin uk sale growth kingfisher, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aldi lidl expansion plan speed ahead tesco sainsbury morrison, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: centrica extend gas deal gazprom statoil, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aberdeen post h1 outflow say condition remain challenge, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: severn trent share price jump canadian investor renew pursuit utility, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: new morrison duo boss support diffuse investor tension, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: s&p downgrade barclay rbs government bailout fear, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: irish housebuilder cairn home plan london list, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: arm slam handset sale outlook, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companieslse add ex sec head schapiro board, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sale boost new morrison chief david potts tesco turnaround stall, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ftse 100 flat standard chartered lead riser, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: companieshoward davy appointment rbs director delay, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: keith skeoch step david nish quit chief executive standard life, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: dixon carphone profit boost strong sale, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ftse rally three month low boost stanchart sainsbury, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: royal mail johnson matthey lead ftse lower, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sainsbury sale slip price pressure toll, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sophos aim raise $ 100 m london ipo, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: update 3 stifel buy lehman brokerage barclay, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: borealis infrastructure put new severn trent bid, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ftse fall 3 month low greek debt concern easyjet skid, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: johnson matthey share price slump company post year result, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update barclay expect gain settle lehman bros trustee, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: petrofac book Ã¢Â£30 m cost shetland gas terminal delay, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: petrofac share price rise despite Ã¢Â£30 m cost north sea project, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: whitbread boss andy harrison defend sale fall blip, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: barclay share price subdue bank face fresh forex probe, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiesactelion share hit record shire takeover talk, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: lse get hong kong regulatory nod hk firm lse member, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: diageo share surge report possible takeover lemann, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: rbs chairman admit surprise size regulatory penalty, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: rsa insurance hire towergate egan chief financial officer, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: johnson matthey raise prospect investor payout, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: intercontinental hotel deny report starwood merger talk, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: refile hikma barclay help britain ftse climb high, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: fda approve astrazeneca iressa lung cancer treatment, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca suffer setback drug fail treat eye cancer, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: british american tobacco first half sale hurt currency move, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: zurich insurance consider offer uk rival rsa insurance, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: japan nikkei land financial time $ 1.3 billion deal, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: ingenious hsbc ubs coutt sue tax avoidance client, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 astrazeneca sell rare cancer drug sanofi $ 300 mln, Sentiment Scores: [[  0.05843232  -0.08583678  -0.08687651 -10.972705    18.323215\n",
            "   -6.2663875 ]]\n",
            "Sentence: sainsbury sell unit lloydspharmacy, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bae system sale boost european typhoon currency, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: royal mail breach competition law delivery service change ofcom claim, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: britain ftse steady support dixon carphone, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glaxo viiv healthcare sign china manufacturing deal desano, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca sell caprelsa right sanofi unit, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 5 barclay chairman mcfarlane axis ceo speed strategic change, Sentiment Scores: [[-0.09873284  0.1588273  -0.16590275]]\n",
            "Sentence: miner meltdown bhp rio tinto sink commodity rout, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ftse lead lower m&s glaxosmithkline, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: gkn buy fokker technology 706 mln euro, Sentiment Scores: [[-25.96772   43.31407  -14.696835]]\n",
            "Sentence: diageo sell ryder cup venue gleneagle hotel ennismore group, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update cib legal general sell egyptian life joint venture axa, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: chime communication set acquire wpp providence, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiesnew aggreko ceo reshape business strip cost, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca pay inovio $ 700 million cancer drug, Sentiment Scores: [[-2.5746120e+01  4.2944752e+01 -1.4572247e+01 -3.6933438e+04\n",
            "   6.1553691e+04 -2.0764678e+04]]\n",
            "Sentence: rio tinto ceo say iron ore market equilibrium, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sanction gazprom shell alliance plan jeopardy, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: standard charter raise capital dividend cut, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 bhp billiton credit rating fragile fy16 agency warn, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: crh add cr laurence acquisition tally $ 1.3bn, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: novartis buy remain right gsk treatment deal $ 1 billion, Sentiment Scores: [[ 5.8432318e-02 -8.5836776e-02 -8.6876512e-02 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: astrazeneca bag cancer drug deal time inovio, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: refile aviva investor 34 bln euro asset axa fund arm, Sentiment Scores: [[-1.1704837   1.9506692  -0.74969804]]\n",
            "Sentence: l&g pay price dividend cut crisis chief say, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: buffett company report 37 percent drop 2q earning, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: travis perkin hike dividend 20 profit revenue rise, Sentiment Scores: [[-0.6577481   1.0890675  -0.46030775]]\n",
            "Sentence: tesco asda sale fall march discounter continue kantar, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: shire propose $ 30 bln share tie baxalta, Sentiment Scores: [[-1.0239878  1.7044971 -0.6670151]]\n",
            "Sentence: shire ceo step drive baxalta board talk, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco asda sale fall march discounter continue kantar, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: verizon at&t accuse hurt rival, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ftse 100 fall china devaluation hit burberry mining stock, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: nine bank include barclay citi agree pay $ 2 billion settle forex, Sentiment Scores: [[-2.4912760e-01  4.0786433e-01 -2.4226393e-01  1.4063217e-02\n",
            "  -2.7950443e-02 -1.0863185e-01 -3.6933544e+07  6.1553836e+07\n",
            "  -2.0764644e+07]]\n",
            "Sentence: companiescar insurer hastings group drive Ã¢Â£180 m ipo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glencore slump 25 pct debt fear grow, Sentiment Scores: [[-0.840868   1.3967822 -0.5636614]]\n",
            "Sentence: horizonte acquire neighbouring glencore nickel property brazil, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 engineering firm smith group confirm ceo appointment, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: industry newsmorrison unveil store close 900 job face axe, Sentiment Scores: [[-33.13283   55.255524 -18.725174]]\n",
            "Sentence: glencore slump 30 percent debt fear grow, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aberdeen asset management gain foothold china, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: arm holdings plc partner international business machines corp drive, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ftse 100 drop 2.5 pct glencore metal price fear, Sentiment Scores: [[-3.5876660e+00  6.0125060e+00 -2.1139667e+00 -4.7361180e-03\n",
            "   3.1791702e-03 -1.1817701e-01]]\n",
            "Sentence: barclay bank america citigroup blockchain sight, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ab inbev approach sabmiller explore $ 250bn tie, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: eu regulator back approval gsk injectable asthma drug, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glencore fight debt fear lift share, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: news feedftse 100 mover ashtead jump strong interim glencore bp, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: brewer ab inbev seek $ 275 bln tie sabmiller, Sentiment Scores: [[-10.049366  16.78437   -5.747272]]\n",
            "Sentence: ab inbev look win sabmiller investor, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 eu regulator back approval gsk injectable asthma drug, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: copper market 2003 style supply shock glencore closure, Sentiment Scores: [[-73.87053  123.1494   -41.628574]]\n",
            "Sentence: talktalk hire bae system investigate cyber attack, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: renew ab inbev bid sabmiller up stake beer battle, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiesab inbev signal will hostile sabmiller, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca diabete drug combination face delay fda rebuff, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: mylan appoint ranjan ray chaudhuri global commercial lead mylan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sabmiller revenue hit weak em currency, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 5 sabmiller reject ab inbev $ 104 bln takeover approach, Sentiment Scores: [[-0.09873284  0.1588273  -0.16590275 -3.7341619   6.2586775  -2.1966498 ]]\n",
            "Sentence: market report eight day rally end ftse 100 standard charter, Sentiment Scores: [[-0.2115289   0.34560505 -0.22317363 -3.587666    6.012506   -2.1139667 ]]\n",
            "Sentence: ab inbev offer sabmiller $ 3 billion breakup fee, Sentiment Scores: [[-2.3535475e-02  3.4308814e-02 -1.2772216e-01 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: gsk join china trade push uk trumpets healthcare deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ab inbev up offer sabmiller deadline loom, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco plc recovery continue Ã¢Â£250 m cash infusion, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: metal zinc surge 12 pct glencore cut output fuel metal rally, Sentiment Scores: [[-0.36192364  0.59464204 -0.29953483]]\n",
            "Sentence: companiesunilever sale lift ice cream soft economy, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ab inbev late bid say unlikely win sabmiller approval, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: britain ftse forge ahead shire surge, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ab inbev attack sabmiller bid rebuffal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: anheuser busch inbev increase offer rival sabmiller, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: buy arm holdings plc bhp billiton plc today, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: barclays plc lloyds banking group plc 2 bank buy today, Sentiment Scores: [[ 0.01406322 -0.02795044 -0.10863185]]\n",
            "Sentence: easyjet dismisse lufthansa low cost plan contest germany, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: exclusive bp china cnpc unveil oil alliance source, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sab chairman dig board divide inbev offer, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: kinder morgan bp form joint venture limited liability company purchase, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: supreme court uphold $ 236 million jury award exxonmobil, Sentiment Scores: [[-8.6089563e+00  1.4383768e+01 -4.9374514e+00 -3.6933438e+04\n",
            "   6.1553691e+04 -2.0764678e+04]]\n",
            "Sentence: standard chartered share plunge 7 fitch downgrade, Sentiment Scores: [[-0.1739302   0.28334582 -0.20408335]]\n",
            "Sentence: wpp win race programmatic buying agency essence digital, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bhp billiton share price brazil sue samarco Ã¢Â£3.5bn, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: g4s slide balance sheet worry, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: fda approve astrazeneca drug advanced lung cancer, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: hsbc appoint business leader board, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: hsbc shake board two new business chief three departure, Sentiment Scores: [[ 0.01406322 -0.02795044 -0.10863185 -0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: astrazeneca win fda approval key new lung cancer pill, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 lloyds cut 945 job 3 year restructuring plan, Sentiment Scores: [[ 5.8432318e-02 -8.5836776e-02 -8.6876512e-02 -3.4794842e+01\n",
            "   5.8025444e+01 -1.9659582e+01 -2.3535475e-02  3.4308814e-02\n",
            "  -1.2772216e-01]]\n",
            "Sentence: standard charter shift emerge market strategy loss, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca lung cancer drug tagrisso get fda approval, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: severn trent share price rise first half profit inch customer, Sentiment Scores: [[ 0.09229714 -0.11852994 -0.12051044]]\n",
            "Sentence: glencore see tripoli base noc sole legal seller libyan oil, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: lloyds cut 945 job three year restructuring strategy, Sentiment Scores: [[-3.4794842e+01  5.8025444e+01 -1.9659582e+01 -2.3535475e-02\n",
            "   3.4308814e-02 -1.2772216e-01]]\n",
            "Sentence: astrazeneca buy zs pharma $ 2.7 billion, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ackman email say support valeant ceo pearson, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca sell drug right perrigo $ 380 mln, Sentiment Scores: [[-13.927387  23.247522  -7.92756 ]]\n",
            "Sentence: update 1 astrazeneca buy zs pharma $ 2.7 billion pip actelion, Sentiment Scores: [[ 5.8432318e-02 -8.5836776e-02 -8.6876512e-02 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: correct shire buy dyax $ 5.9 bln, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: barclay poise replace sir mike rake head exit, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca acquire zs pharma $ 2.7 billion deal, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: astrazeneca share climb 3 drug maker up profit forecast, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: peroni grolsch sale ab inbev plan acquisition sabmiller, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: easyjet expect resilient demand withstand security fear, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: compass group say positive year ahead, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: dollar wipe sale gain sabmiller, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 sabmiller 2nd quarter underlying sale rise forex impact margin, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: update 2 pricey beer lift sabmiller quarterly underlying sale, Sentiment Scores: [[ 0.01406322 -0.02795044 -0.10863185]]\n",
            "Sentence: valeant ceo pledge heed critic ` painful experience, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aviva plc direct line insurance group plc admiral group plc set soar, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: stanchart rbs struggle bank england stress test, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: barclays sell benchmark index unit bloomberg, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sainsbury asda tesco morrison cut petrol price oil fall, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: eu drop shell bp statoil ethanol benchmark investigation, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca explore potential deal acerta cancer drug, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: shell bg shareholder vote deal end january, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca chase acerta secure cancer drug winner, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiestesco bad start xmas Ã¢â‚¬ kantar, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: dbs julius baer emerge potential bidder barclays asia wealth unit, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca plc dixons carphone plc red hot growth star, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bbcn bancorp buy wilshire bancorp $ 1 bln deal, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: itv share price jump report comcast nbcuniversal bidding takeover, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glencore study possible ipo agricultural trading business, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: christmas save sainsbury plc tesco plc, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 astrazeneca boost respiratory unit $ 575 mln takeda deal, Sentiment Scores: [[  0.05843232  -0.08583678  -0.08687651 -21.129429    35.250523\n",
            "  -11.976666  ]]\n",
            "Sentence: bilfinger industrial service win Ã¢Â£100 m bp contract extension, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: standard chartered rbs escape capital raising stress test, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca weigh acerta bid secure blood cancer drug, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: 2 turnaround buy 2016 bhp billiton plc home retail group plc, Sentiment Scores: [[ 1.4063217e-02 -2.7950443e-02 -1.0863185e-01 -7.4350662e+01\n",
            "   1.2394960e+02 -4.1898514e+01]]\n",
            "Sentence: l&g complete uk large medically underwritten bulk pension risk deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: drugmaker shire buy baxalta $ 32 billion 6 month pursuit, Sentiment Scores: [[-1.0972358e+00  1.8275831e+00 -7.0835650e-01 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07 -1.3633153e-01  2.2108659e-01\n",
            "  -1.8499303e-01]]\n",
            "Sentence: kingfisher share price slide cost implement new strategy, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: shire say internal synergy goal baxalta deal higher, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: european share plunge roil bhp oil hope turn ecb, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: morrison debenham surprise city christmas bounce, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: britain ftse fall ashtead commodity pressure, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco share jump 6 christmas sale beat expectation, Sentiment Scores: [[-0.13633153  0.22108659 -0.18499303]]\n",
            "Sentence: ceos bpm ubi meet italy econ minister m&a talk heat, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companieshome retail trim gain consider play, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: philippine san miguel say partner kirin bid sabmiller, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: investor remain skeptical shell bg deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: marketsshire 2.5 baxalta 6 $ 32bn deal, Sentiment Scores: [[-0.00473612  0.00317917 -0.11817701 -0.13633153  0.22108659 -0.18499303]]\n",
            "Sentence: shire share price pressure $ 32bn baxalta deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: valeant name interim leader ceo remains hospitalize, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: valeant say new ceo pearson hospitalize, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: share bae system hit 10 month high rating upgrade, Sentiment Scores: [[-0.28672627  0.4701236  -0.26135424]]\n",
            "Sentence: japan asahi submit bid week sabmiller grolsch peroni yomiuri, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiesdixon carphone close 134 uk store sale jump, Sentiment Scores: [[-4.841735   8.105277  -2.8194575]]\n",
            "Sentence: broker tip rbs croda sage, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: shell share price standard life announce position bg acquisition, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco share price grocer face sfo investigation outcome, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: britain ftse outperform europe royal mail tesco rise, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: greene king third quarter sale boost festive season, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: intercontinental hotels group share price climb $ 1.5bn special dividend, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: amazon attack uk grocery market morrison deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: astrazeneca share price acerta deal pay orphan drug status, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bhp billiton post big loss slash dividend, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: merge lse deutsche bÃ£Â¶rse lead germany kengeter, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: buy jumbo yielder british american tobacco plc centrica plc john wood group plc, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: trouble brew legal general group plc aviva plc, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bhp billiton drag ftse lower slash dividend, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bhp billiton slashes dividend post $ 5.67 billion net loss, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: companiesmeggitt profit hit weak energy military market, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: royal mail share price edge lower group raise stamp price, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: glaxosmithkline start hunt successor ceo witty, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: rio tinto swing loss drop dividend policy, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: france raise concern propose lse deutsche boerse deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: marketsbp promote upstream boss deputy ceo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: legal general share price finance chief step, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: barclay poache new chief operating officer paul compton jp morgan chase, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: arm profit sale shift away mobile gain pace, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: barclays appoint jpmorgan paul compton new coo, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: fastjet slams easyjet founder stelio go public take legal advice letter contractual, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nyse owner ice consider offer lse, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: news feedftse 100 mover lse surge ice say mull offer ashtead barclay tank, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: balfour beatty plc set reinstate dividend rival national grid plc centrica plc, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: intertek swing Ã¢Â£347 mln loss oil slump, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sanofi poache astrazeneca scientist new research head, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco break downward slide cut sale decline half, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: news feedschroder book solid earning growth board change, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: intertek group announce strategic update outline plan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: london stock exchange seal Ã¢Â£22 billion merger germany deutsche bÃ£Â¶rse, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: nyse owner ice gatecrash deutsche boerse lse merger, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ab inbev sell sabmiller stake china snow beer, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: lse deutsche boerse merger signal end exchange mega deal, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: rbs pay $ 1.7 billion scrap u.k treasury dividend right, Sentiment Scores: [[-36933544.  61553836. -20764644.]]\n",
            "Sentence: industry newswolseley confident reslilience amid mixed market, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco criticise disgraceful advert show domestic worker slap, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ftse edge investor cheer kingfisher result, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: barclay bond rise lender cut dividend shore capital, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: britain ftse get lift prudential result, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: amazon grocery deal morrison beginning, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ice say start line financing lse bidding war, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bp statoil withdraw staff algeria follow rocket attack, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: merkel government say support deutsche boerse lse merger, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aviva weigh cash handout beat profit forecast, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: wpp world large ad agency report strong 2015 growth, Sentiment Scores: [[-74.31373  123.88804  -41.877747]]\n",
            "Sentence: saudi aramco shell plan break motiva divide asset, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ab inbev sell sab asset seek eu deal approval, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco sale pickup, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: spain caixabank expect close deal banco bpi, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: itv share price group mull takeover canada entertainment one, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: entertainment one dispel itv takeover rumour, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ge sell majority stake bank bph core bank alior bank, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tata steel work stanchart uk unit sale source, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: crown castle buy tower development corp $ 461 million, Sentiment Scores: [[-16.919003  28.233383  -9.609498]]\n",
            "Sentence: tesco sell half stake ecommerce site lazada alibaba Ã¢Â£90 m, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: caixabank do santo agree plan bpi angola exposure, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bpi say caixabank isabel do santo reach agreement angola exposure, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: spain caixabank launch new takeover bid banco bpi, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: despite sale growth uk tesco caution recovery bumpy, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: itv pursue takeover canada entertainment one bloomberg, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651]]\n",
            "Sentence: shire see baxalta deal closing expect new rule, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: ocbc buy barclay wealth management unit singapore hong kong, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco share price steady analyst weigh result, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: lloyds banking group share price lift amid report bank poise axe hundred uk job, Sentiment Scores: [[-3.587666   6.012506  -2.1139667]]\n",
            "Sentence: follow berkshire hathaway apple stock, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: morrison book second consecutive quarter sale growth, Sentiment Scores: [[ 0.09229714 -0.11852994 -0.12051044]]\n",
            "Sentence: royal mail get mixed bag ofcom postal regulation report, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 3 ex barclay director accuse illegal tip plumber, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: eu regulator clear $ 100 billion plus ab inbev sabmiller deal, Sentiment Scores: [[-3.5876660e+00  6.0125060e+00 -2.1139667e+00 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: retail giant kingfisher report solid start year, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: berkshire disclose unit tie iran open probe, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: berkshire hathaway name kara raiguel lead general unit, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: european stock hover near 3 week low dialog bhp slump, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: hargreave lansdown buck weak market asset rise 2.6 percent, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: australia clear ab inbev $ 100 billion sabmiller buyout plan, Sentiment Scores: [[-3.5876660e+00  6.0125060e+00 -2.1139667e+00 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: goodwin face scottish prosecution rbs, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: royal mail turnaround prove expensive tough uk market, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: whitbread buy 49 stake pure food chain, Sentiment Scores: [[-1.7198433  2.8738136 -1.059759 ]]\n",
            "Sentence: irish say chase standard chartered rbs brexit vote near, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: royal mail share price rally amid positive broker comment, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: intercontinental hotel first quarter global room revenue lag estimate, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aspen buy anaesthetic astrazeneca $ 520 million, Sentiment Scores: [[-19.098083  31.865059 -10.83461 ]]\n",
            "Sentence: london stock exchange Ã¢â‚¬ deutsche boerse merger threat brexit, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: sainsbury cfo roger replace home retail ceo walden, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: bp join force det norske norway, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: brief legal general retirement business book 4 billion stg h1 sale, Sentiment Scores: [[-6.1134160e-02  9.6568055e-02 -1.4681245e-01 -3.6933544e+07\n",
            "   6.1553836e+07 -2.0764644e+07]]\n",
            "Sentence: johnson matthey revs clean air drive, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: goldman sachs barclay hsbc downplay brexit threat, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: asahi snap sabmiller beer ahead ab inbev sale, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: lse deutsche bÃ£Â¶rse dealmaker wrong ignore brexit risk, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco sale recover focus return core business, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: johnson matthey profit fall dividend rise, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: arm holdings plc domino pizza group plc asos plc 3 growth stock, Sentiment Scores: [[-0.02353548  0.03430881 -0.12772216]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: priceline stock jump new high year barclay upgrade, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco set sell kipa giraffe business sky news, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: coca cola company coca cola femsa acquire ade soy base beverage business unilever, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: hsbc say unit book $ 585 million charge settlement, Sentiment Scores: [[-2.1498764e+01  3.5866058e+01 -1.2184313e+01 -3.6933438e+04\n",
            "   6.1553691e+04 -2.0764678e+04]]\n",
            "Sentence: hammerson jv partner secure ownership ireland dundrum quick fact, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aviva promise high dividend boost flagging share price, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: companiesfresnillo share jump 8 silver price break $ 21, Sentiment Scores: [[-0.2115289   0.34560505 -0.22317363 -0.69437206  1.1506104  -0.48097852]]\n",
            "Sentence: buy associate british foods plc great portland estates plc dunelm group plc follow today news, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: nan, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: berkshire seek boost wells fargo stake 10 percent, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: tesco share price tumble negative broker note, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: london stock exchange shareholder approve merger deutsche bÃ£Â¶rse, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: update 1 berkshire applie boost wells fargo stake 10 pct, Sentiment Scores: [[ 0.05843232 -0.08583678 -0.08687651 -0.28672627  0.4701236  -0.26135424]]\n",
            "Sentence: berkshire apply boost wells fargo stake 10 percent, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: aviva m&g suspend property fund investor panic, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: uk housing market steady brexit dip persimmon say, Sentiment Scores: [[0. 0. 0.]]\n",
            "Sentence: brief aviva aim increase dividend pay ratio 50 pct 2017, Sentiment Scores: [[ -1.7564672   2.9353569  -1.0804299 -74.387596  124.011154  -41.919277 ]]\n",
            "Sentence: builder persimmon hail 6 rise house sale, Sentiment Scores: [[-0.13633153  0.22108659 -0.18499303]]\n",
            "Sentence: easyjet attract passenger june lag ryanair, Sentiment Scores: [[0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "sentiment_scores_list = []\n",
        "print(\"\\nSentiment Scores for Each Sentence:\")\n",
        "for idx, row in df.iterrows():\n",
        "    if row['encoded_values'].numel() == 0:\n",
        "        print(f\"Sentence: {row['sentence']}, No numerical values found.\")\n",
        "        continue\n",
        "    sentiment_scores = row['encoded_values'].detach().numpy()\n",
        "    print(f\"Sentence: {row['preprocessed_sentence']}, Sentiment Scores: {sentiment_scores}\")\n",
        "    sentiment_scores_list.append(sentiment_scores)\n",
        "df['sentiment_scores_for_numerical_encoded_values'] = sentiment_scores_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOmZV9JQgAv7"
      },
      "source": [
        "#Creating Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Of9mZ-um8QZT"
      },
      "outputs": [],
      "source": [
        "increase_words = ['up', 'rise', 'high', 'grows', 'increase', 'boost', 'gain', 'improve', 'surge', 'climb','strong',\n",
        "    'advance', 'appreciate', 'augment', 'balloon', 'boom', 'broaden', 'build', 'develop', 'double', 'elevate',\n",
        "    'escalate', 'expand', 'extend', 'flourish', 'heighten', 'inflate', 'intensify', 'magnify', 'multiply',\n",
        "    'progress', 'prosper', 'rally', 'skyrocket', 'soar', 'strengthen', 'swell', 'thrive', 'triple', 'upgrade',\n",
        "    'widen']\n",
        "\n",
        "decrease_words = ['down', 'fall', 'low', 'decrement', 'decrease', 'decline', 'drop', 'reduce', 'slump', 'plunge','loses',\n",
        "                  'tough','abate', 'contract', 'curb', 'dampen', 'depreciate', 'deteriorate', 'diminish', 'disappear', 'dwindle',\n",
        "    'ebb', 'erode', 'fade', 'flag', 'lessen', 'narrow', 'recede', 'regress', 'retract', 'retreat', 'shrink',\n",
        "    'subside', 'taper', 'undermine', 'wane', 'weaken', 'wither', 'stagnate', 'deflate', 'cut', 'sag']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyCDY-pXg9Tm"
      },
      "source": [
        "#Aspects Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihxsn7NIahcx"
      },
      "outputs": [],
      "source": [
        "def embed_with_aspect(df, increase_words, decrease_words):\n",
        "    embedded_sentences = []\n",
        "    for index, row in df.iterrows():\n",
        "        sentence = row['preprocessed_sentence']\n",
        "        aspect = row['info__target']\n",
        "        embedded = {'sentence': sentence, 'aspect': aspect, 'trend': None, 'embedded_aspect': None}\n",
        "        for word in sentence.split():\n",
        "            if word in increase_words:\n",
        "                embedded['trend'] = 'increase'\n",
        "                embedded['embedded_aspect'] = f\"{word} {aspect}\"\n",
        "                break\n",
        "            elif word in decrease_words:\n",
        "                embedded['trend'] = 'decrease'\n",
        "                embedded['embedded_aspect'] = f\"{word} {aspect}\"\n",
        "                break\n",
        "        if embedded['embedded_aspect'] is None:\n",
        "            embedded['embedded_aspect'] = aspect\n",
        "        embedded_sentences.append(embedded)\n",
        "    return embedded_sentences\n",
        "embedded_results = embed_with_aspect(df, increase_words, decrease_words)\n",
        "embedded_df = pd.DataFrame(embedded_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mV23d9tqgjpD",
        "outputId": "3b6094c6-602b-462e-bd65-e5b9606a8426"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"embedded_df\",\n  \"rows\": 498,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 436,\n        \"samples\": [\n          \"berkshire disclose unit tie iran open probe\",\n          \"kraft cadbury britvic total recall pull product affect profit\",\n          \"dollar wipe sale gain sabmiller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 226,\n        \"samples\": [\n          \"Royal Dutch Shell\",\n          \"JP Morgan Chase\",\n          \"Zurich Insurance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trend\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"decrease\",\n          \"increase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedded_aspect\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"Det Norske\",\n          \"Rio Tinto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "embedded_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d67df1b3-7421-48cf-9754-2eaec8429bc1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>aspect</th>\n",
              "      <th>trend</th>\n",
              "      <th>embedded_aspect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>royal mail chairman donald brydon set step</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>None</td>\n",
              "      <td>Royal Mail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stake high astrazeneca heart drug face tough c...</td>\n",
              "      <td>AstraZeneca</td>\n",
              "      <td>increase</td>\n",
              "      <td>high AstraZeneca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>update 1 dairy crest lose third morrison milk ...</td>\n",
              "      <td>Morrisons</td>\n",
              "      <td>decrease</td>\n",
              "      <td>contract Morrisons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>insight hire aviva david hillier multi asset team</td>\n",
              "      <td>Insight</td>\n",
              "      <td>None</td>\n",
              "      <td>Insight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>primark rack happy christmas strong sale</td>\n",
              "      <td>Primark</td>\n",
              "      <td>increase</td>\n",
              "      <td>strong Primark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>aviva m&amp;g suspend property fund investor panic</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>None</td>\n",
              "      <td>M&amp;G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>uk housing market steady brexit dip persimmon say</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>None</td>\n",
              "      <td>Perssimon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>brief aviva aim increase dividend pay ratio 50...</td>\n",
              "      <td>Aviva</td>\n",
              "      <td>increase</td>\n",
              "      <td>increase Aviva</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>builder persimmon hail 6 rise house sale</td>\n",
              "      <td>Persimmon</td>\n",
              "      <td>increase</td>\n",
              "      <td>rise Persimmon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>easyjet attract passenger june lag ryanair</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>None</td>\n",
              "      <td>Ryanair</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d67df1b3-7421-48cf-9754-2eaec8429bc1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d67df1b3-7421-48cf-9754-2eaec8429bc1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d67df1b3-7421-48cf-9754-2eaec8429bc1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f60fe52-ba46-436b-9870-fe68ec31525f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f60fe52-ba46-436b-9870-fe68ec31525f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f60fe52-ba46-436b-9870-fe68ec31525f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f8a99428-4b81-4a6d-b7ee-92144c1f4402\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('embedded_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f8a99428-4b81-4a6d-b7ee-92144c1f4402 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('embedded_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              sentence       aspect     trend  \\\n",
              "0           royal mail chairman donald brydon set step   Royal Mail      None   \n",
              "1    stake high astrazeneca heart drug face tough c...  AstraZeneca  increase   \n",
              "2    update 1 dairy crest lose third morrison milk ...    Morrisons  decrease   \n",
              "3    insight hire aviva david hillier multi asset team      Insight      None   \n",
              "4             primark rack happy christmas strong sale      Primark  increase   \n",
              "..                                                 ...          ...       ...   \n",
              "493     aviva m&g suspend property fund investor panic          M&G      None   \n",
              "494  uk housing market steady brexit dip persimmon say    Perssimon      None   \n",
              "495  brief aviva aim increase dividend pay ratio 50...        Aviva  increase   \n",
              "496           builder persimmon hail 6 rise house sale    Persimmon  increase   \n",
              "497         easyjet attract passenger june lag ryanair      Ryanair      None   \n",
              "\n",
              "        embedded_aspect  \n",
              "0            Royal Mail  \n",
              "1      high AstraZeneca  \n",
              "2    contract Morrisons  \n",
              "3               Insight  \n",
              "4        strong Primark  \n",
              "..                  ...  \n",
              "493                 M&G  \n",
              "494           Perssimon  \n",
              "495      increase Aviva  \n",
              "496      rise Persimmon  \n",
              "497             Ryanair  \n",
              "\n",
              "[498 rows x 4 columns]"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedded_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnsCdHAGisxX"
      },
      "source": [
        "## Adding trend and embedded_aspect in df from embedded_df\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dM4r3iphvuA"
      },
      "outputs": [],
      "source": [
        "df['trend'] = embedded_df['trend']\n",
        "df['embedded_aspect'] = embedded_df['embedded_aspect']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpmYzncaiQZO"
      },
      "source": [
        "## Final dataframe after inseting trends and embedded_aspect from embedded_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U3ZEcaplgoIx",
        "outputId": "36a3bc78-e492-47a2-e121-7dc59d022821"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 498,\n  \"fields\": [\n    {\n      \"column\": \"No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 512.897703134483,\n        \"min\": 1.0,\n        \"max\": 1779.0,\n        \"num_unique_values\": 436,\n        \"samples\": [\n          1581.0,\n          257.0,\n          1052.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 436,\n        \"samples\": [\n          \"Berkshire discloses unit's ties to Iran, opens probe\",\n          \"How Kraft-Heinz Merger Came Together in Speedy 10 Weeks\",\n          \"US dollar wipes out sales gains for SABMiller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__snippets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 458,\n        \"samples\": [\n          \"['chases Acerta to secure next cancer drug winner']\",\n          \"['Smartphone Market Regains Strength']\",\n          \"['Britain's FTSE outperforms Europe, Royal Mail and Tesco rise']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 226,\n        \"samples\": [\n          \"Royal Dutch Shell\",\n          \"JP Morgan Chase\",\n          \"Zurich Insurance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_sentiment_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3757132285813035,\n        \"min\": -0.938,\n        \"max\": 0.975,\n        \"num_unique_values\": 407,\n        \"samples\": [\n          0.315,\n          0.357,\n          0.593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_aspects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 82,\n        \"samples\": [\n          \"['Corporate/Appointment/Staff Hiring']\",\n          \"['Corporate/Appointment']\",\n          \"['Corporate/Dividend Policy/Dividend/Dividend going up']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 436,\n        \"samples\": [\n          \"berkshire disclose unit tie iran open probe\",\n          \"kraft cadbury britvic total recall pull product affect profit\",\n          \"dollar wipe sale gain sabmiller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"numerical_info\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoded_values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"tensor([[0., 0., 0.]])\",\n          \"tensor([[-3.5877,  6.0125, -2.1140]], grad_fn=<CatBackward0>)\",\n          \"tensor([[-0.6577,  1.0891, -0.4603]], grad_fn=<CatBackward0>)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores_for_numerical_encoded_values\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trend\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"decrease\",\n          \"increase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedded_aspect\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"Det Norske\",\n          \"Rio Tinto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-d577aa95-a674-42d5-9fa2-49f0bf1cc9c8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>sentence</th>\n",
              "      <th>info__snippets</th>\n",
              "      <th>info__target</th>\n",
              "      <th>info_sentiment_score</th>\n",
              "      <th>info_aspects</th>\n",
              "      <th>preprocessed_sentence</th>\n",
              "      <th>numerical_info</th>\n",
              "      <th>encoded_values</th>\n",
              "      <th>sentiment_scores_for_numerical_encoded_values</th>\n",
              "      <th>trend</th>\n",
              "      <th>embedded_aspect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
              "      <td>['set to step down']</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "      <td>royal mail chairman donald brydon set step</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Royal Mail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
              "      <td>['Facing Tough Competition']</td>\n",
              "      <td>AstraZeneca</td>\n",
              "      <td>-0.240</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>stake high astrazeneca heart drug face tough c...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>high AstraZeneca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>UPDATE 1-Dairy Crest loses a third of Morrison...</td>\n",
              "      <td>['Crest loses a third of Morrisons milk contra...</td>\n",
              "      <td>Morrisons</td>\n",
              "      <td>-0.161</td>\n",
              "      <td>['Corporate/Sales/Failed Contract Discussion']</td>\n",
              "      <td>update 1 dairy crest lose third morrison milk ...</td>\n",
              "      <td>[{'value': '1', 'type': 'cardinal', 'aspect': ...</td>\n",
              "      <td>[[tensor(0.0584, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
              "      <td>[[0.05843232, -0.085836776, -0.08687651, 0.092...</td>\n",
              "      <td>decrease</td>\n",
              "      <td>contract Morrisons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.0</td>\n",
              "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
              "      <td>['hires Aviva's David Hillier for multi-asset ...</td>\n",
              "      <td>Insight</td>\n",
              "      <td>0.137</td>\n",
              "      <td>['Corporate/Appointment/Executive Appointment']</td>\n",
              "      <td>insight hire aviva david hillier multi asset team</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Insight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.0</td>\n",
              "      <td>Primark racks up a happy Christmas after stron...</td>\n",
              "      <td>['after strong sales']</td>\n",
              "      <td>Primark</td>\n",
              "      <td>0.704</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>primark rack happy christmas strong sale</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>strong Primark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>1750.0</td>\n",
              "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
              "      <td>['M&amp;G suspend property funds as investors panic']</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>-0.807</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>aviva m&amp;g suspend property fund investor panic</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>M&amp;G</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>1754.0</td>\n",
              "      <td>UK housing market steadies after Brexit dip, P...</td>\n",
              "      <td>['housing market']</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>0.339</td>\n",
              "      <td>['Market/Market']</td>\n",
              "      <td>uk housing market steady brexit dip persimmon say</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Perssimon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1755.0</td>\n",
              "      <td>BRIEF-Aviva aims to increase dividend pay-out ...</td>\n",
              "      <td>['increase dividend pay-out']</td>\n",
              "      <td>Aviva</td>\n",
              "      <td>0.439</td>\n",
              "      <td>['Corporate/Dividend Policy']</td>\n",
              "      <td>brief aviva aim increase dividend pay ratio 50...</td>\n",
              "      <td>[{'value': '50', 'type': 'cardinal', 'aspect':...</td>\n",
              "      <td>[[tensor(-1.7565, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n",
              "      <td>[[-1.7564672, 2.9353569, -1.0804299, -74.38759...</td>\n",
              "      <td>increase</td>\n",
              "      <td>increase Aviva</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1764.0</td>\n",
              "      <td>Builder Persimmon hails 6% rise in house sales</td>\n",
              "      <td>['6% rise in house sales']</td>\n",
              "      <td>Persimmon</td>\n",
              "      <td>0.435</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>builder persimmon hail 6 rise house sale</td>\n",
              "      <td>[{'value': '6', 'type': 'cardinal', 'aspect': ...</td>\n",
              "      <td>[[tensor(-0.1363, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n",
              "      <td>[[-0.13633153, 0.22108659, -0.18499303]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>rise Persimmon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1779.0</td>\n",
              "      <td>EasyJet attracts more passengers in June but s...</td>\n",
              "      <td>['attracts more passengers']</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>0.259</td>\n",
              "      <td>['Corporate/Sales/Sales']</td>\n",
              "      <td>easyjet attract passenger june lag ryanair</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Ryanair</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows Ã— 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d577aa95-a674-42d5-9fa2-49f0bf1cc9c8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d577aa95-a674-42d5-9fa2-49f0bf1cc9c8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d577aa95-a674-42d5-9fa2-49f0bf1cc9c8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8c164b3a-ef9f-4d5a-abef-81ea04253b2b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8c164b3a-ef9f-4d5a-abef-81ea04253b2b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8c164b3a-ef9f-4d5a-abef-81ea04253b2b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_595c6c78-959a-4fce-bb89-f3b65509282b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_595c6c78-959a-4fce-bb89-f3b65509282b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         No                                           sentence  \\\n",
              "0       1.0  Royal Mail chairman Donald Brydon set to step ...   \n",
              "1       7.0  Stakes High for AstraZeneca Heart Drug Facing ...   \n",
              "2       8.0  UPDATE 1-Dairy Crest loses a third of Morrison...   \n",
              "3      22.0  Insight hires Aviva's David Hillier for multi-...   \n",
              "4      30.0  Primark racks up a happy Christmas after stron...   \n",
              "..      ...                                                ...   \n",
              "493  1750.0  Aviva, M&G suspend property funds as investors...   \n",
              "494  1754.0  UK housing market steadies after Brexit dip, P...   \n",
              "495  1755.0  BRIEF-Aviva aims to increase dividend pay-out ...   \n",
              "496  1764.0     Builder Persimmon hails 6% rise in house sales   \n",
              "497  1779.0  EasyJet attracts more passengers in June but s...   \n",
              "\n",
              "                                        info__snippets info__target  \\\n",
              "0                                 ['set to step down']   Royal Mail   \n",
              "1                         ['Facing Tough Competition']  AstraZeneca   \n",
              "2    ['Crest loses a third of Morrisons milk contra...    Morrisons   \n",
              "3    ['hires Aviva's David Hillier for multi-asset ...      Insight   \n",
              "4                               ['after strong sales']      Primark   \n",
              "..                                                 ...          ...   \n",
              "493  ['M&G suspend property funds as investors panic']          M&G   \n",
              "494                                 ['housing market']    Perssimon   \n",
              "495                      ['increase dividend pay-out']        Aviva   \n",
              "496                         ['6% rise in house sales']    Persimmon   \n",
              "497                       ['attracts more passengers']      Ryanair   \n",
              "\n",
              "     info_sentiment_score                                     info_aspects  \\\n",
              "0                  -0.374                        ['Corporate/Appointment']   \n",
              "1                  -0.240                              ['Corporate/Risks']   \n",
              "2                  -0.161   ['Corporate/Sales/Failed Contract Discussion']   \n",
              "3                   0.137  ['Corporate/Appointment/Executive Appointment']   \n",
              "4                   0.704                              ['Corporate/Sales']   \n",
              "..                    ...                                              ...   \n",
              "493                -0.807                              ['Corporate/Risks']   \n",
              "494                 0.339                                ['Market/Market']   \n",
              "495                 0.439                    ['Corporate/Dividend Policy']   \n",
              "496                 0.435                              ['Corporate/Sales']   \n",
              "497                 0.259                        ['Corporate/Sales/Sales']   \n",
              "\n",
              "                                 preprocessed_sentence  \\\n",
              "0           royal mail chairman donald brydon set step   \n",
              "1    stake high astrazeneca heart drug face tough c...   \n",
              "2    update 1 dairy crest lose third morrison milk ...   \n",
              "3    insight hire aviva david hillier multi asset team   \n",
              "4             primark rack happy christmas strong sale   \n",
              "..                                                 ...   \n",
              "493     aviva m&g suspend property fund investor panic   \n",
              "494  uk housing market steady brexit dip persimmon say   \n",
              "495  brief aviva aim increase dividend pay ratio 50...   \n",
              "496           builder persimmon hail 6 rise house sale   \n",
              "497         easyjet attract passenger june lag ryanair   \n",
              "\n",
              "                                        numerical_info  \\\n",
              "0                                                   []   \n",
              "1                                                   []   \n",
              "2    [{'value': '1', 'type': 'cardinal', 'aspect': ...   \n",
              "3                                                   []   \n",
              "4                                                   []   \n",
              "..                                                 ...   \n",
              "493                                                 []   \n",
              "494                                                 []   \n",
              "495  [{'value': '50', 'type': 'cardinal', 'aspect':...   \n",
              "496  [{'value': '6', 'type': 'cardinal', 'aspect': ...   \n",
              "497                                                 []   \n",
              "\n",
              "                                        encoded_values  \\\n",
              "0               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "1               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "2    [[tensor(0.0584, grad_fn=<UnbindBackward0>), t...   \n",
              "3               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "4               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "..                                                 ...   \n",
              "493             [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "494             [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "495  [[tensor(-1.7565, grad_fn=<UnbindBackward0>), ...   \n",
              "496  [[tensor(-0.1363, grad_fn=<UnbindBackward0>), ...   \n",
              "497             [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "\n",
              "         sentiment_scores_for_numerical_encoded_values     trend  \\\n",
              "0                                    [[0.0, 0.0, 0.0]]      None   \n",
              "1                                    [[0.0, 0.0, 0.0]]  increase   \n",
              "2    [[0.05843232, -0.085836776, -0.08687651, 0.092...  decrease   \n",
              "3                                    [[0.0, 0.0, 0.0]]      None   \n",
              "4                                    [[0.0, 0.0, 0.0]]  increase   \n",
              "..                                                 ...       ...   \n",
              "493                                  [[0.0, 0.0, 0.0]]      None   \n",
              "494                                  [[0.0, 0.0, 0.0]]      None   \n",
              "495  [[-1.7564672, 2.9353569, -1.0804299, -74.38759...  increase   \n",
              "496           [[-0.13633153, 0.22108659, -0.18499303]]  increase   \n",
              "497                                  [[0.0, 0.0, 0.0]]      None   \n",
              "\n",
              "        embedded_aspect  \n",
              "0            Royal Mail  \n",
              "1      high AstraZeneca  \n",
              "2    contract Morrisons  \n",
              "3               Insight  \n",
              "4        strong Primark  \n",
              "..                  ...  \n",
              "493                 M&G  \n",
              "494           Perssimon  \n",
              "495      increase Aviva  \n",
              "496      rise Persimmon  \n",
              "497             Ryanair  \n",
              "\n",
              "[498 rows x 12 columns]"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4v-h6cZugwF"
      },
      "source": [
        "#Applying Attention Mechanism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65jx29JUuxEA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wOZOa6Puz3a"
      },
      "outputs": [],
      "source": [
        "df1 = df[['preprocessed_sentence', 'trend', 'embedded_aspect']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHkLPNC6u-aj"
      },
      "source": [
        "##Define the multi-head attention mechanism with projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx8162lCu5Az"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(torch.nn.Module):\n",
        "    def __init__(self, num_heads, model_dim):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.model_dim = model_dim\n",
        "\n",
        "        self.query_layer = torch.nn.Linear(model_dim, num_heads * model_dim)\n",
        "        self.key_layer = torch.nn.Linear(model_dim, num_heads * model_dim)\n",
        "        self.value_layer = torch.nn.Linear(model_dim, num_heads * model_dim)\n",
        "\n",
        "        self.projection_layer = torch.nn.Linear(num_heads * model_dim, model_dim)\n",
        "\n",
        "    def forward(self, input_data):\n",
        "        queries = self.query_layer(input_data)\n",
        "        keys = self.key_layer(input_data)\n",
        "        values = self.value_layer(input_data)\n",
        "\n",
        "        attention_scores = torch.matmul(queries, keys.transpose(-1, -2)) / (self.model_dim ** 0.5)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        attention_output = torch.matmul(attention_weights, values)\n",
        "\n",
        "        attention_output = self.projection_layer(attention_output)\n",
        "\n",
        "        return attention_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgSh_LnGgn39",
        "outputId": "53e64f0d-f0ac-4cc6-cded-a53d57c0c335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: royal mail chairman donald brydon set step\n",
            "Predicted sentiment probabilities: tensor([[0.2739, 0.3518, 0.3743]], grad_fn=<SoftmaxBackward0>) 0\n",
            "Sentence: stake high astrazeneca heart drug face tough competition\n",
            "Predicted sentiment probabilities: tensor([[0.3122, 0.3440, 0.3438]], grad_fn=<SoftmaxBackward0>) 1\n",
            "Sentence: update 1 dairy crest lose third morrison milk contract\n",
            "Predicted sentiment probabilities: tensor([[0.3311, 0.3450, 0.3239]], grad_fn=<SoftmaxBackward0>) 2\n",
            "Sentence: insight hire aviva david hillier multi asset team\n",
            "Predicted sentiment probabilities: tensor([[0.3211, 0.3146, 0.3643]], grad_fn=<SoftmaxBackward0>) 3\n",
            "Sentence: primark rack happy christmas strong sale\n",
            "Predicted sentiment probabilities: tensor([[0.2459, 0.4258, 0.3283]], grad_fn=<SoftmaxBackward0>) 4\n",
            "Sentence: update 1 pearson expect grow year solid end 2014\n",
            "Predicted sentiment probabilities: tensor([[0.3753, 0.3501, 0.2746]], grad_fn=<SoftmaxBackward0>) 5\n",
            "Sentence: tesco sell blinkbox broadband service talktalk\n",
            "Predicted sentiment probabilities: tensor([[0.4241, 0.2777, 0.2982]], grad_fn=<SoftmaxBackward0>) 6\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2792, 0.4264, 0.2944]], grad_fn=<SoftmaxBackward0>) 7\n",
            "Sentence: unilever profit rise despite sale slump china\n",
            "Predicted sentiment probabilities: tensor([[0.3763, 0.2841, 0.3396]], grad_fn=<SoftmaxBackward0>) 8\n",
            "Sentence: tesco lead leap ftse 100 mark spencer drop\n",
            "Predicted sentiment probabilities: tensor([[0.2983, 0.3424, 0.3594]], grad_fn=<SoftmaxBackward0>) 9\n",
            "Sentence: royal dutch shell profit rise dividend 4\n",
            "Predicted sentiment probabilities: tensor([[0.3432, 0.3552, 0.3016]], grad_fn=<SoftmaxBackward0>) 10\n",
            "Sentence: morning agenda shire deal nps\n",
            "Predicted sentiment probabilities: tensor([[0.3487, 0.2995, 0.3517]], grad_fn=<SoftmaxBackward0>) 11\n",
            "Sentence: carnival corporation china merchant group sign memo understanding\n",
            "Predicted sentiment probabilities: tensor([[0.3365, 0.3547, 0.3088]], grad_fn=<SoftmaxBackward0>) 12\n",
            "Sentence: teva fda approve generic version astrazeneca heartburn drug\n",
            "Predicted sentiment probabilities: tensor([[0.3547, 0.3164, 0.3289]], grad_fn=<SoftmaxBackward0>) 13\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3249, 0.3280, 0.3471]], grad_fn=<SoftmaxBackward0>) 14\n",
            "Sentence: passenger rise easyjet aer lingus\n",
            "Predicted sentiment probabilities: tensor([[0.3305, 0.3588, 0.3106]], grad_fn=<SoftmaxBackward0>) 15\n",
            "Sentence: tesco abandon video stream ambition blinkbox sale\n",
            "Predicted sentiment probabilities: tensor([[0.3649, 0.3473, 0.2878]], grad_fn=<SoftmaxBackward0>) 16\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3437, 0.3685, 0.2877]], grad_fn=<SoftmaxBackward0>) 17\n",
            "Sentence: fda approve nps drug validate shire takeover deal\n",
            "Predicted sentiment probabilities: tensor([[0.3932, 0.3233, 0.2835]], grad_fn=<SoftmaxBackward0>) 18\n",
            "Sentence: ocwen reach settlement california regulator\n",
            "Predicted sentiment probabilities: tensor([[0.3353, 0.3230, 0.3418]], grad_fn=<SoftmaxBackward0>) 19\n",
            "Sentence: morrison face festive sale test\n",
            "Predicted sentiment probabilities: tensor([[0.3620, 0.2586, 0.3794]], grad_fn=<SoftmaxBackward0>) 20\n",
            "Sentence: tesco share price dip blinkbox book close end supermarket digital\n",
            "Predicted sentiment probabilities: tensor([[0.3180, 0.3532, 0.3288]], grad_fn=<SoftmaxBackward0>) 21\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2804, 0.3760, 0.3436]], grad_fn=<SoftmaxBackward0>) 22\n",
            "Sentence: shire buy nps $ 5.2 billion boost rare disease drug\n",
            "Predicted sentiment probabilities: tensor([[0.3204, 0.2632, 0.4163]], grad_fn=<SoftmaxBackward0>) 23\n",
            "Sentence: astrazeneca medimmune ink licensing deal omnis pharmaceutical\n",
            "Predicted sentiment probabilities: tensor([[0.3420, 0.3448, 0.3132]], grad_fn=<SoftmaxBackward0>) 24\n",
            "Sentence: fda approve shire vyvanse binge eat disorder\n",
            "Predicted sentiment probabilities: tensor([[0.2954, 0.3848, 0.3198]], grad_fn=<SoftmaxBackward0>) 25\n",
            "Sentence: company thetrainline.com announce arrival london ipo\n",
            "Predicted sentiment probabilities: tensor([[0.3714, 0.3602, 0.2685]], grad_fn=<SoftmaxBackward0>) 26\n",
            "Sentence: breakingviews iag pay aer lingus\n",
            "Predicted sentiment probabilities: tensor([[0.2788, 0.4024, 0.3189]], grad_fn=<SoftmaxBackward0>) 27\n",
            "Sentence: tesco share price jump q3 sale estimate\n",
            "Predicted sentiment probabilities: tensor([[0.3590, 0.3411, 0.2999]], grad_fn=<SoftmaxBackward0>) 28\n",
            "Sentence: crh concrete bid holcim lafarge asset\n",
            "Predicted sentiment probabilities: tensor([[0.4126, 0.2603, 0.3270]], grad_fn=<SoftmaxBackward0>) 29\n",
            "Sentence: persimmon share price climb 23 rise year revenue\n",
            "Predicted sentiment probabilities: tensor([[0.3641, 0.3134, 0.3225]], grad_fn=<SoftmaxBackward0>) 30\n",
            "Sentence: ruling set low limit potential fine bp\n",
            "Predicted sentiment probabilities: tensor([[0.3457, 0.3127, 0.3416]], grad_fn=<SoftmaxBackward0>) 31\n",
            "Sentence: reed elsevi share price slide underwhelme year result\n",
            "Predicted sentiment probabilities: tensor([[0.3788, 0.2405, 0.3807]], grad_fn=<SoftmaxBackward0>) 32\n",
            "Sentence: update 1 meggitt reiterate annual outlook tough 2014\n",
            "Predicted sentiment probabilities: tensor([[0.3214, 0.3565, 0.3221]], grad_fn=<SoftmaxBackward0>) 33\n",
            "Sentence: slump weir lead ftse record high\n",
            "Predicted sentiment probabilities: tensor([[0.2999, 0.3464, 0.3537]], grad_fn=<SoftmaxBackward0>) 34\n",
            "Sentence: bunzl lift dividend acquisition continue boost profit\n",
            "Predicted sentiment probabilities: tensor([[0.3389, 0.3187, 0.3424]], grad_fn=<SoftmaxBackward0>) 35\n",
            "Sentence: refile update 4 britain lloyds pay first dividend rescue\n",
            "Predicted sentiment probabilities: tensor([[0.4228, 0.2953, 0.2818]], grad_fn=<SoftmaxBackward0>) 36\n",
            "Sentence: glaxosmithkline set complete $ 20 billion novartis asset swap week\n",
            "Predicted sentiment probabilities: tensor([[0.3259, 0.3709, 0.3032]], grad_fn=<SoftmaxBackward0>) 37\n",
            "Sentence: meggitt share price tumble profit fall challenging year\n",
            "Predicted sentiment probabilities: tensor([[0.2776, 0.3971, 0.3253]], grad_fn=<SoftmaxBackward0>) 38\n",
            "Sentence: analyst view astrazeneca share see recent volatility 2015\n",
            "Predicted sentiment probabilities: tensor([[0.3896, 0.3176, 0.2928]], grad_fn=<SoftmaxBackward0>) 39\n",
            "Sentence: arm royalty accelerate smartphone market regain strength\n",
            "Predicted sentiment probabilities: tensor([[0.3794, 0.2713, 0.3493]], grad_fn=<SoftmaxBackward0>) 40\n",
            "Sentence: conagra names hillshire farms ceo connolly post\n",
            "Predicted sentiment probabilities: tensor([[0.4171, 0.3152, 0.2677]], grad_fn=<SoftmaxBackward0>) 41\n",
            "Sentence: bg group appoint new ceo one month early\n",
            "Predicted sentiment probabilities: tensor([[0.2865, 0.3829, 0.3306]], grad_fn=<SoftmaxBackward0>) 42\n",
            "Sentence: glencore cut 2015 budget plan divest lonmin\n",
            "Predicted sentiment probabilities: tensor([[0.3373, 0.3474, 0.3153]], grad_fn=<SoftmaxBackward0>) 43\n",
            "Sentence: u.s debt lure schroder ecb depress rate\n",
            "Predicted sentiment probabilities: tensor([[0.3070, 0.3225, 0.3705]], grad_fn=<SoftmaxBackward0>) 44\n",
            "Sentence: tullow oil suspend dividend amid oil price fall\n",
            "Predicted sentiment probabilities: tensor([[0.3259, 0.3550, 0.3190]], grad_fn=<SoftmaxBackward0>) 45\n",
            "Sentence: oil major like royal dutch shell chevron bp fail find reserve counter\n",
            "Predicted sentiment probabilities: tensor([[0.3493, 0.3319, 0.3187]], grad_fn=<SoftmaxBackward0>) 46\n",
            "Sentence: standard charter lag capital worry\n",
            "Predicted sentiment probabilities: tensor([[0.3819, 0.2685, 0.3496]], grad_fn=<SoftmaxBackward0>) 47\n",
            "Sentence: standard life share price insurer buy advice firm pearson jones\n",
            "Predicted sentiment probabilities: tensor([[0.3756, 0.2939, 0.3304]], grad_fn=<SoftmaxBackward0>) 48\n",
            "Sentence: tesco close new chairman dixon carphone john allan frame\n",
            "Predicted sentiment probabilities: tensor([[0.2821, 0.2214, 0.4965]], grad_fn=<SoftmaxBackward0>) 49\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2549, 0.4106, 0.3345]], grad_fn=<SoftmaxBackward0>) 50\n",
            "Sentence: millercoor deliver 2.9 underlie net income growth 2014\n",
            "Predicted sentiment probabilities: tensor([[0.3349, 0.2817, 0.3834]], grad_fn=<SoftmaxBackward0>) 51\n",
            "Sentence: rbs reportedly appoint howard davy chairman\n",
            "Predicted sentiment probabilities: tensor([[0.3132, 0.3562, 0.3306]], grad_fn=<SoftmaxBackward0>) 52\n",
            "Sentence: hsbc hit fresh detail tax evasion claim\n",
            "Predicted sentiment probabilities: tensor([[0.4851, 0.2955, 0.2195]], grad_fn=<SoftmaxBackward0>) 53\n",
            "Sentence: relief lewis tesco see sale grow first time year\n",
            "Predicted sentiment probabilities: tensor([[0.3734, 0.3077, 0.3189]], grad_fn=<SoftmaxBackward0>) 54\n",
            "Sentence: morrison finance chief fill gap ceo leave early\n",
            "Predicted sentiment probabilities: tensor([[0.3391, 0.2712, 0.3897]], grad_fn=<SoftmaxBackward0>) 55\n",
            "Sentence: update persimmon profit strongly outlook positive\n",
            "Predicted sentiment probabilities: tensor([[0.3146, 0.3270, 0.3584]], grad_fn=<SoftmaxBackward0>) 56\n",
            "Sentence: trlpc crh back lafarge holcim asset buy 6.5 bln euro bridge loan\n",
            "Predicted sentiment probabilities: tensor([[0.4439, 0.2510, 0.3051]], grad_fn=<SoftmaxBackward0>) 57\n",
            "Sentence: tesco shareholder itv head chairman\n",
            "Predicted sentiment probabilities: tensor([[0.3832, 0.3127, 0.3041]], grad_fn=<SoftmaxBackward0>) 58\n",
            "Sentence: buffett berkshire build deere stake dump exxon\n",
            "Predicted sentiment probabilities: tensor([[0.3005, 0.3676, 0.3319]], grad_fn=<SoftmaxBackward0>) 59\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3959, 0.2627, 0.3414]], grad_fn=<SoftmaxBackward0>) 60\n",
            "Sentence: aviva fine $ 27 million u.k regulator fee failing\n",
            "Predicted sentiment probabilities: tensor([[0.2654, 0.3393, 0.3953]], grad_fn=<SoftmaxBackward0>) 61\n",
            "Sentence: astrazeneca patent asthma drug invalidate court\n",
            "Predicted sentiment probabilities: tensor([[0.3605, 0.3067, 0.3327]], grad_fn=<SoftmaxBackward0>) 62\n",
            "Sentence: roll royce ensure compliance petrobras bribery report\n",
            "Predicted sentiment probabilities: tensor([[0.5078, 0.2519, 0.2403]], grad_fn=<SoftmaxBackward0>) 63\n",
            "Sentence: whitbread share price climb q4 sale growth\n",
            "Predicted sentiment probabilities: tensor([[0.3063, 0.3744, 0.3194]], grad_fn=<SoftmaxBackward0>) 64\n",
            "Sentence: warren buffett defend berkshire hathaway conglomerate structure\n",
            "Predicted sentiment probabilities: tensor([[0.3291, 0.4118, 0.2591]], grad_fn=<SoftmaxBackward0>) 65\n",
            "Sentence: g4s see profit rise uk contract problem remain\n",
            "Predicted sentiment probabilities: tensor([[0.2651, 0.4160, 0.3189]], grad_fn=<SoftmaxBackward0>) 66\n",
            "Sentence: friend life lift profit 38 hike divi ahead propose aviva takeover\n",
            "Predicted sentiment probabilities: tensor([[0.3401, 0.2943, 0.3656]], grad_fn=<SoftmaxBackward0>) 67\n",
            "Sentence: auto trader share price surge company float lse\n",
            "Predicted sentiment probabilities: tensor([[0.2728, 0.4118, 0.3155]], grad_fn=<SoftmaxBackward0>) 68\n",
            "Sentence: new credit suisse boss face stiff challenge asia\n",
            "Predicted sentiment probabilities: tensor([[0.3422, 0.3691, 0.2887]], grad_fn=<SoftmaxBackward0>) 69\n",
            "Sentence: update easyjet passenger number aer lingus traffic february\n",
            "Predicted sentiment probabilities: tensor([[0.2807, 0.3200, 0.3992]], grad_fn=<SoftmaxBackward0>) 70\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3769, 0.3382, 0.2849]], grad_fn=<SoftmaxBackward0>) 71\n",
            "Sentence: worth invest tesco plc prudential plc\n",
            "Predicted sentiment probabilities: tensor([[0.3198, 0.2929, 0.3873]], grad_fn=<SoftmaxBackward0>) 72\n",
            "Sentence: uk winner loser aviva friend life lead ftse 100 gainer\n",
            "Predicted sentiment probabilities: tensor([[0.2518, 0.3245, 0.4237]], grad_fn=<SoftmaxBackward0>) 73\n",
            "Sentence: sainsbury say outperform rival tough market\n",
            "Predicted sentiment probabilities: tensor([[0.3218, 0.2999, 0.3783]], grad_fn=<SoftmaxBackward0>) 74\n",
            "Sentence: companieskingfisher bid mr bricolage run trouble\n",
            "Predicted sentiment probabilities: tensor([[0.2373, 0.3732, 0.3895]], grad_fn=<SoftmaxBackward0>) 75\n",
            "Sentence: update 3 auto trader share leap uk big private equity back listing\n",
            "Predicted sentiment probabilities: tensor([[0.4011, 0.2824, 0.3165]], grad_fn=<SoftmaxBackward0>) 76\n",
            "Sentence: london open taylor wimpey ashtead drive market higher barclay fall\n",
            "Predicted sentiment probabilities: tensor([[0.2917, 0.3396, 0.3687]], grad_fn=<SoftmaxBackward0>) 77\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.4119, 0.2668, 0.3212]], grad_fn=<SoftmaxBackward0>) 78\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3788, 0.3192, 0.3020]], grad_fn=<SoftmaxBackward0>) 79\n",
            "Sentence: gsk novartis complete deal reshape drugmaker\n",
            "Predicted sentiment probabilities: tensor([[0.3447, 0.2991, 0.3563]], grad_fn=<SoftmaxBackward0>) 80\n",
            "Sentence: aviva friend life forecast ahead 5.6 billion pound merger\n",
            "Predicted sentiment probabilities: tensor([[0.3082, 0.3815, 0.3103]], grad_fn=<SoftmaxBackward0>) 81\n",
            "Sentence: citigroup sell onemain springleaf $ 4.25 billion\n",
            "Predicted sentiment probabilities: tensor([[0.3254, 0.3645, 0.3100]], grad_fn=<SoftmaxBackward0>) 82\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2864, 0.3778, 0.3358]], grad_fn=<SoftmaxBackward0>) 83\n",
            "Sentence: u.k stock resume gain rally record crh tullow climb\n",
            "Predicted sentiment probabilities: tensor([[0.2896, 0.4069, 0.3035]], grad_fn=<SoftmaxBackward0>) 84\n",
            "Sentence: british american tobacco drop sue pwc pollution scandal\n",
            "Predicted sentiment probabilities: tensor([[0.3557, 0.3370, 0.3073]], grad_fn=<SoftmaxBackward0>) 85\n",
            "Sentence: uk ftse bad day far 2015 bg prudential fall\n",
            "Predicted sentiment probabilities: tensor([[0.2769, 0.3482, 0.3750]], grad_fn=<SoftmaxBackward0>) 86\n",
            "Sentence: kraft cadbury britvic total recall pull product affect profit\n",
            "Predicted sentiment probabilities: tensor([[0.4338, 0.2071, 0.3592]], grad_fn=<SoftmaxBackward0>) 87\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3263, 0.3198, 0.3539]], grad_fn=<SoftmaxBackward0>) 88\n",
            "Sentence: kraft heinz merger come speedy 10 week\n",
            "Predicted sentiment probabilities: tensor([[0.3943, 0.3062, 0.2995]], grad_fn=<SoftmaxBackward0>) 89\n",
            "Sentence: astrazeneca team daiichi sankyo sell movantik\n",
            "Predicted sentiment probabilities: tensor([[0.3214, 0.3290, 0.3495]], grad_fn=<SoftmaxBackward0>) 90\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.4001, 0.2582, 0.3417]], grad_fn=<SoftmaxBackward0>) 91\n",
            "Sentence: rbi surprises street sensex pare gain hit mount 30k\n",
            "Predicted sentiment probabilities: tensor([[0.3045, 0.3292, 0.3663]], grad_fn=<SoftmaxBackward0>) 92\n",
            "Sentence: credit suisse poache prudential thiam asian push\n",
            "Predicted sentiment probabilities: tensor([[0.2844, 0.3419, 0.3737]], grad_fn=<SoftmaxBackward0>) 93\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3394, 0.2886, 0.3720]], grad_fn=<SoftmaxBackward0>) 94\n",
            "Sentence: kingfisher takeover mr bricolage hit brick wall\n",
            "Predicted sentiment probabilities: tensor([[0.3803, 0.2830, 0.3367]], grad_fn=<SoftmaxBackward0>) 95\n",
            "Sentence: u.k stock little change near record barclay shell fall\n",
            "Predicted sentiment probabilities: tensor([[0.3599, 0.2859, 0.3542]], grad_fn=<SoftmaxBackward0>) 96\n",
            "Sentence: insurer admiral blow hot cold aviva soar pre friends life merger\n",
            "Predicted sentiment probabilities: tensor([[0.3643, 0.2855, 0.3502]], grad_fn=<SoftmaxBackward0>) 97\n",
            "Sentence: astrazeneca daiichi sankyo jointly commercialise movantik\n",
            "Predicted sentiment probabilities: tensor([[0.3047, 0.3807, 0.3146]], grad_fn=<SoftmaxBackward0>) 98\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2542, 0.3503, 0.3956]], grad_fn=<SoftmaxBackward0>) 99\n",
            "Sentence: legal general arm buy 50 pct stake mediacityuk manchester\n",
            "Predicted sentiment probabilities: tensor([[0.3555, 0.3248, 0.3197]], grad_fn=<SoftmaxBackward0>) 100\n",
            "Sentence: randgold profit hit poor gold price dividend increase\n",
            "Predicted sentiment probabilities: tensor([[0.2830, 0.4455, 0.2716]], grad_fn=<SoftmaxBackward0>) 101\n",
            "Sentence: companiestravis perkin lift dividend earning rise 15\n",
            "Predicted sentiment probabilities: tensor([[0.3365, 0.3115, 0.3521]], grad_fn=<SoftmaxBackward0>) 102\n",
            "Sentence: market report aviva top market trader approve choice friend\n",
            "Predicted sentiment probabilities: tensor([[0.3216, 0.3275, 0.3510]], grad_fn=<SoftmaxBackward0>) 103\n",
            "Sentence: insurer old mutual pick standard bank hemphill new ceo\n",
            "Predicted sentiment probabilities: tensor([[0.4367, 0.2957, 0.2676]], grad_fn=<SoftmaxBackward0>) 104\n",
            "Sentence: fda panel back safety update astrazeneca takeda drug\n",
            "Predicted sentiment probabilities: tensor([[0.3227, 0.3025, 0.3749]], grad_fn=<SoftmaxBackward0>) 105\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3062, 0.4242, 0.2696]], grad_fn=<SoftmaxBackward0>) 106\n",
            "Sentence: companiesdiageo stay neutral india boardroom turmoil\n",
            "Predicted sentiment probabilities: tensor([[0.3650, 0.3339, 0.3011]], grad_fn=<SoftmaxBackward0>) 107\n",
            "Sentence: germanwing disaster affect image budget air travel easyjet\n",
            "Predicted sentiment probabilities: tensor([[0.3505, 0.2923, 0.3571]], grad_fn=<SoftmaxBackward0>) 108\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3193, 0.3052, 0.3755]], grad_fn=<SoftmaxBackward0>) 109\n",
            "Sentence: shell $ 70 billion bg deal meet shareholder skepticism\n",
            "Predicted sentiment probabilities: tensor([[0.3277, 0.3230, 0.3493]], grad_fn=<SoftmaxBackward0>) 110\n",
            "Sentence: shell offer 50 percent premium buy bg $ 70 billion\n",
            "Predicted sentiment probabilities: tensor([[0.3781, 0.3139, 0.3080]], grad_fn=<SoftmaxBackward0>) 111\n",
            "Sentence: wpp boost sale despite cautious client\n",
            "Predicted sentiment probabilities: tensor([[0.3742, 0.2885, 0.3372]], grad_fn=<SoftmaxBackward0>) 112\n",
            "Sentence: shell buy bg group $ 69.7 billion takeover\n",
            "Predicted sentiment probabilities: tensor([[0.2629, 0.3032, 0.4339]], grad_fn=<SoftmaxBackward0>) 113\n",
            "Sentence: london morning briefing hsbc standard charter share rise\n",
            "Predicted sentiment probabilities: tensor([[0.2843, 0.3936, 0.3220]], grad_fn=<SoftmaxBackward0>) 114\n",
            "Sentence: update 1 bp shareholder disclosure climate change risk\n",
            "Predicted sentiment probabilities: tensor([[0.3295, 0.3258, 0.3448]], grad_fn=<SoftmaxBackward0>) 115\n",
            "Sentence: shell challenge exxon dominance 47 billion pound bid bg\n",
            "Predicted sentiment probabilities: tensor([[0.3658, 0.4005, 0.2337]], grad_fn=<SoftmaxBackward0>) 116\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2926, 0.4168, 0.2906]], grad_fn=<SoftmaxBackward0>) 117\n",
            "Sentence: royal dutch shell buy bg group nearly $ 70 billion\n",
            "Predicted sentiment probabilities: tensor([[0.3105, 0.3289, 0.3606]], grad_fn=<SoftmaxBackward0>) 118\n",
            "Sentence: city spirit sink diageo come short sale slide\n",
            "Predicted sentiment probabilities: tensor([[0.3720, 0.2711, 0.3569]], grad_fn=<SoftmaxBackward0>) 119\n",
            "Sentence: diageo receive report united spirit financial irregularity involve\n",
            "Predicted sentiment probabilities: tensor([[0.2546, 0.4159, 0.3295]], grad_fn=<SoftmaxBackward0>) 120\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3007, 0.3512, 0.3480]], grad_fn=<SoftmaxBackward0>) 121\n",
            "Sentence: roll royce win $ 9.2 billion order emirate airline\n",
            "Predicted sentiment probabilities: tensor([[0.4158, 0.2894, 0.2948]], grad_fn=<SoftmaxBackward0>) 122\n",
            "Sentence: tesco sale rise show tentative recovery continue\n",
            "Predicted sentiment probabilities: tensor([[0.3092, 0.3734, 0.3174]], grad_fn=<SoftmaxBackward0>) 123\n",
            "Sentence: diageo sale disappoint currency comparative leave bitter taste\n",
            "Predicted sentiment probabilities: tensor([[0.3692, 0.3120, 0.3189]], grad_fn=<SoftmaxBackward0>) 124\n",
            "Sentence: astrazeneca profit sale stalwart fade\n",
            "Predicted sentiment probabilities: tensor([[0.2722, 0.4069, 0.3209]], grad_fn=<SoftmaxBackward0>) 125\n",
            "Sentence: whitbread profit sale continue rise look new ceo\n",
            "Predicted sentiment probabilities: tensor([[0.3483, 0.2888, 0.3629]], grad_fn=<SoftmaxBackward0>) 126\n",
            "Sentence: glencore blame rival create metal glut\n",
            "Predicted sentiment probabilities: tensor([[0.4032, 0.2944, 0.3024]], grad_fn=<SoftmaxBackward0>) 127\n",
            "Sentence: doubt grow glaxosmithkline $ 6 bln capital return plan\n",
            "Predicted sentiment probabilities: tensor([[0.3731, 0.3471, 0.2798]], grad_fn=<SoftmaxBackward0>) 128\n",
            "Sentence: easyjet lead britain ftse low global bond rout resume\n",
            "Predicted sentiment probabilities: tensor([[0.3187, 0.3227, 0.3586]], grad_fn=<SoftmaxBackward0>) 129\n",
            "Sentence: imperial tobacco add quarterly dividend profit rise\n",
            "Predicted sentiment probabilities: tensor([[0.4250, 0.2002, 0.3748]], grad_fn=<SoftmaxBackward0>) 130\n",
            "Sentence: bg group happy shell $ 70 billion offer\n",
            "Predicted sentiment probabilities: tensor([[0.3369, 0.4163, 0.2469]], grad_fn=<SoftmaxBackward0>) 131\n",
            "Sentence: sabmiller buy meantime quench thirst craft beer\n",
            "Predicted sentiment probabilities: tensor([[0.3767, 0.3436, 0.2797]], grad_fn=<SoftmaxBackward0>) 132\n",
            "Sentence: aviva shut friends life head office rapid integration\n",
            "Predicted sentiment probabilities: tensor([[0.3489, 0.3570, 0.2941]], grad_fn=<SoftmaxBackward0>) 133\n",
            "Sentence: retailer kingfisher sport direct rise britain share index\n",
            "Predicted sentiment probabilities: tensor([[0.3187, 0.3091, 0.3722]], grad_fn=<SoftmaxBackward0>) 134\n",
            "Sentence: glaxosmithkline target growth unit scrap viiv ipo\n",
            "Predicted sentiment probabilities: tensor([[0.2987, 0.3555, 0.3458]], grad_fn=<SoftmaxBackward0>) 135\n",
            "Sentence: tesco share price close high two director leave grocer\n",
            "Predicted sentiment probabilities: tensor([[0.3241, 0.3656, 0.3103]], grad_fn=<SoftmaxBackward0>) 136\n",
            "Sentence: tesco lead ftse higher clubcard bid report\n",
            "Predicted sentiment probabilities: tensor([[0.3143, 0.3268, 0.3589]], grad_fn=<SoftmaxBackward0>) 137\n",
            "Sentence: eli lilly co. lly break new high astrazeneca collaboration\n",
            "Predicted sentiment probabilities: tensor([[0.3612, 0.2944, 0.3444]], grad_fn=<SoftmaxBackward0>) 138\n",
            "Sentence: rpt old mutual q1 gross sale beat forecast 18 pct\n",
            "Predicted sentiment probabilities: tensor([[0.2925, 0.3421, 0.3654]], grad_fn=<SoftmaxBackward0>) 139\n",
            "Sentence: update 3 bp settle oil spill relate claim halliburton transocean\n",
            "Predicted sentiment probabilities: tensor([[0.2915, 0.3378, 0.3707]], grad_fn=<SoftmaxBackward0>) 140\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3903, 0.3014, 0.3082]], grad_fn=<SoftmaxBackward0>) 141\n",
            "Sentence: glaxosmithkline share price slip fda okay asthma therapy adult\n",
            "Predicted sentiment probabilities: tensor([[0.3170, 0.3911, 0.2919]], grad_fn=<SoftmaxBackward0>) 142\n",
            "Sentence: glencore chief blame rival overproduction share price fall\n",
            "Predicted sentiment probabilities: tensor([[0.4202, 0.2513, 0.3285]], grad_fn=<SoftmaxBackward0>) 143\n",
            "Sentence: philip morris bat sue law take brand pack\n",
            "Predicted sentiment probabilities: tensor([[0.3668, 0.3333, 0.2999]], grad_fn=<SoftmaxBackward0>) 144\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3442, 0.4095, 0.2463]], grad_fn=<SoftmaxBackward0>) 145\n",
            "Sentence: hargreave lansdown share price fall cost mount pension\n",
            "Predicted sentiment probabilities: tensor([[0.3318, 0.3114, 0.3568]], grad_fn=<SoftmaxBackward0>) 146\n",
            "Sentence: press serco set appoint roy gardner ex centrica chairman ft\n",
            "Predicted sentiment probabilities: tensor([[0.3004, 0.3211, 0.3785]], grad_fn=<SoftmaxBackward0>) 147\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3469, 0.3906, 0.2624]], grad_fn=<SoftmaxBackward0>) 148\n",
            "Sentence: update 1 cypress semiconductor offer buy integrate silicon solution\n",
            "Predicted sentiment probabilities: tensor([[0.3737, 0.3609, 0.2653]], grad_fn=<SoftmaxBackward0>) 149\n",
            "Sentence: update 1 nomura rbs pay $ 806 mln mortgage bond case judge\n",
            "Predicted sentiment probabilities: tensor([[0.2979, 0.4161, 0.2860]], grad_fn=<SoftmaxBackward0>) 150\n",
            "Sentence: millercoor board name gavin hattersley interim ceo\n",
            "Predicted sentiment probabilities: tensor([[0.3314, 0.3259, 0.3428]], grad_fn=<SoftmaxBackward0>) 151\n",
            "Sentence: britain ftse gain land security dividend hike\n",
            "Predicted sentiment probabilities: tensor([[0.2957, 0.4006, 0.3037]], grad_fn=<SoftmaxBackward0>) 152\n",
            "Sentence: britain ftse bounce mondi barratt lead\n",
            "Predicted sentiment probabilities: tensor([[0.3823, 0.3705, 0.2472]], grad_fn=<SoftmaxBackward0>) 153\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3001, 0.3897, 0.3102]], grad_fn=<SoftmaxBackward0>) 154\n",
            "Sentence: old mutual first quarter sale 18 buoy emerge market\n",
            "Predicted sentiment probabilities: tensor([[0.3540, 0.3295, 0.3165]], grad_fn=<SoftmaxBackward0>) 155\n",
            "Sentence: trend underpin uk sale growth kingfisher\n",
            "Predicted sentiment probabilities: tensor([[0.2710, 0.3546, 0.3745]], grad_fn=<SoftmaxBackward0>) 156\n",
            "Sentence: aldi lidl expansion plan speed ahead tesco sainsbury morrison\n",
            "Predicted sentiment probabilities: tensor([[0.3618, 0.3096, 0.3286]], grad_fn=<SoftmaxBackward0>) 157\n",
            "Sentence: centrica extend gas deal gazprom statoil\n",
            "Predicted sentiment probabilities: tensor([[0.3850, 0.3248, 0.2902]], grad_fn=<SoftmaxBackward0>) 158\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2747, 0.3117, 0.4137]], grad_fn=<SoftmaxBackward0>) 159\n",
            "Sentence: aberdeen post h1 outflow say condition remain challenge\n",
            "Predicted sentiment probabilities: tensor([[0.3333, 0.3401, 0.3266]], grad_fn=<SoftmaxBackward0>) 160\n",
            "Sentence: severn trent share price jump canadian investor renew pursuit utility\n",
            "Predicted sentiment probabilities: tensor([[0.2589, 0.3642, 0.3769]], grad_fn=<SoftmaxBackward0>) 161\n",
            "Sentence: new morrison duo boss support diffuse investor tension\n",
            "Predicted sentiment probabilities: tensor([[0.3293, 0.3213, 0.3494]], grad_fn=<SoftmaxBackward0>) 162\n",
            "Sentence: s&p downgrade barclay rbs government bailout fear\n",
            "Predicted sentiment probabilities: tensor([[0.3116, 0.3528, 0.3355]], grad_fn=<SoftmaxBackward0>) 163\n",
            "Sentence: irish housebuilder cairn home plan london list\n",
            "Predicted sentiment probabilities: tensor([[0.2741, 0.3071, 0.4188]], grad_fn=<SoftmaxBackward0>) 164\n",
            "Sentence: arm slam handset sale outlook\n",
            "Predicted sentiment probabilities: tensor([[0.4160, 0.3086, 0.2754]], grad_fn=<SoftmaxBackward0>) 165\n",
            "Sentence: companieslse add ex sec head schapiro board\n",
            "Predicted sentiment probabilities: tensor([[0.2532, 0.4307, 0.3161]], grad_fn=<SoftmaxBackward0>) 166\n",
            "Sentence: sale boost new morrison chief david potts tesco turnaround stall\n",
            "Predicted sentiment probabilities: tensor([[0.3549, 0.2960, 0.3491]], grad_fn=<SoftmaxBackward0>) 167\n",
            "Sentence: ftse 100 flat standard chartered lead riser\n",
            "Predicted sentiment probabilities: tensor([[0.3111, 0.2775, 0.4114]], grad_fn=<SoftmaxBackward0>) 168\n",
            "Sentence: companieshoward davy appointment rbs director delay\n",
            "Predicted sentiment probabilities: tensor([[0.2810, 0.3342, 0.3847]], grad_fn=<SoftmaxBackward0>) 169\n",
            "Sentence: keith skeoch step david nish quit chief executive standard life\n",
            "Predicted sentiment probabilities: tensor([[0.3405, 0.3440, 0.3155]], grad_fn=<SoftmaxBackward0>) 170\n",
            "Sentence: dixon carphone profit boost strong sale\n",
            "Predicted sentiment probabilities: tensor([[0.3581, 0.3119, 0.3299]], grad_fn=<SoftmaxBackward0>) 171\n",
            "Sentence: ftse rally three month low boost stanchart sainsbury\n",
            "Predicted sentiment probabilities: tensor([[0.2774, 0.4047, 0.3178]], grad_fn=<SoftmaxBackward0>) 172\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3559, 0.4002, 0.2439]], grad_fn=<SoftmaxBackward0>) 173\n",
            "Sentence: royal mail johnson matthey lead ftse lower\n",
            "Predicted sentiment probabilities: tensor([[0.3255, 0.2982, 0.3763]], grad_fn=<SoftmaxBackward0>) 174\n",
            "Sentence: sainsbury sale slip price pressure toll\n",
            "Predicted sentiment probabilities: tensor([[0.3607, 0.3521, 0.2872]], grad_fn=<SoftmaxBackward0>) 175\n",
            "Sentence: sophos aim raise $ 100 m london ipo\n",
            "Predicted sentiment probabilities: tensor([[0.3052, 0.2691, 0.4257]], grad_fn=<SoftmaxBackward0>) 176\n",
            "Sentence: update 3 stifel buy lehman brokerage barclay\n",
            "Predicted sentiment probabilities: tensor([[0.2219, 0.4437, 0.3344]], grad_fn=<SoftmaxBackward0>) 177\n",
            "Sentence: borealis infrastructure put new severn trent bid\n",
            "Predicted sentiment probabilities: tensor([[0.3658, 0.3056, 0.3285]], grad_fn=<SoftmaxBackward0>) 178\n",
            "Sentence: ftse fall 3 month low greek debt concern easyjet skid\n",
            "Predicted sentiment probabilities: tensor([[0.3270, 0.2892, 0.3838]], grad_fn=<SoftmaxBackward0>) 179\n",
            "Sentence: johnson matthey share price slump company post year result\n",
            "Predicted sentiment probabilities: tensor([[0.3808, 0.3096, 0.3096]], grad_fn=<SoftmaxBackward0>) 180\n",
            "Sentence: update barclay expect gain settle lehman bros trustee\n",
            "Predicted sentiment probabilities: tensor([[0.3168, 0.2890, 0.3942]], grad_fn=<SoftmaxBackward0>) 181\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3195, 0.3478, 0.3327]], grad_fn=<SoftmaxBackward0>) 182\n",
            "Sentence: petrofac book Ã¢Â£30 m cost shetland gas terminal delay\n",
            "Predicted sentiment probabilities: tensor([[0.3546, 0.2768, 0.3686]], grad_fn=<SoftmaxBackward0>) 183\n",
            "Sentence: petrofac share price rise despite Ã¢Â£30 m cost north sea project\n",
            "Predicted sentiment probabilities: tensor([[0.3408, 0.3642, 0.2951]], grad_fn=<SoftmaxBackward0>) 184\n",
            "Sentence: whitbread boss andy harrison defend sale fall blip\n",
            "Predicted sentiment probabilities: tensor([[0.3791, 0.3399, 0.2809]], grad_fn=<SoftmaxBackward0>) 185\n",
            "Sentence: barclay share price subdue bank face fresh forex probe\n",
            "Predicted sentiment probabilities: tensor([[0.3334, 0.2962, 0.3704]], grad_fn=<SoftmaxBackward0>) 186\n",
            "Sentence: companiesactelion share hit record shire takeover talk\n",
            "Predicted sentiment probabilities: tensor([[0.3308, 0.3457, 0.3236]], grad_fn=<SoftmaxBackward0>) 187\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2962, 0.3807, 0.3231]], grad_fn=<SoftmaxBackward0>) 188\n",
            "Sentence: lse get hong kong regulatory nod hk firm lse member\n",
            "Predicted sentiment probabilities: tensor([[0.3613, 0.3521, 0.2866]], grad_fn=<SoftmaxBackward0>) 189\n",
            "Sentence: diageo share surge report possible takeover lemann\n",
            "Predicted sentiment probabilities: tensor([[0.2449, 0.3178, 0.4373]], grad_fn=<SoftmaxBackward0>) 190\n",
            "Sentence: rbs chairman admit surprise size regulatory penalty\n",
            "Predicted sentiment probabilities: tensor([[0.4064, 0.2856, 0.3080]], grad_fn=<SoftmaxBackward0>) 191\n",
            "Sentence: rsa insurance hire towergate egan chief financial officer\n",
            "Predicted sentiment probabilities: tensor([[0.2315, 0.3983, 0.3702]], grad_fn=<SoftmaxBackward0>) 192\n",
            "Sentence: johnson matthey raise prospect investor payout\n",
            "Predicted sentiment probabilities: tensor([[0.3658, 0.2995, 0.3347]], grad_fn=<SoftmaxBackward0>) 193\n",
            "Sentence: intercontinental hotel deny report starwood merger talk\n",
            "Predicted sentiment probabilities: tensor([[0.3359, 0.3287, 0.3355]], grad_fn=<SoftmaxBackward0>) 194\n",
            "Sentence: refile hikma barclay help britain ftse climb high\n",
            "Predicted sentiment probabilities: tensor([[0.3279, 0.3559, 0.3161]], grad_fn=<SoftmaxBackward0>) 195\n",
            "Sentence: fda approve astrazeneca iressa lung cancer treatment\n",
            "Predicted sentiment probabilities: tensor([[0.3176, 0.4315, 0.2509]], grad_fn=<SoftmaxBackward0>) 196\n",
            "Sentence: astrazeneca suffer setback drug fail treat eye cancer\n",
            "Predicted sentiment probabilities: tensor([[0.3906, 0.3641, 0.2453]], grad_fn=<SoftmaxBackward0>) 197\n",
            "Sentence: british american tobacco first half sale hurt currency move\n",
            "Predicted sentiment probabilities: tensor([[0.3164, 0.3646, 0.3189]], grad_fn=<SoftmaxBackward0>) 198\n",
            "Sentence: zurich insurance consider offer uk rival rsa insurance\n",
            "Predicted sentiment probabilities: tensor([[0.4081, 0.2625, 0.3295]], grad_fn=<SoftmaxBackward0>) 199\n",
            "Sentence: japan nikkei land financial time $ 1.3 billion deal\n",
            "Predicted sentiment probabilities: tensor([[0.3308, 0.2974, 0.3718]], grad_fn=<SoftmaxBackward0>) 200\n",
            "Sentence: ingenious hsbc ubs coutt sue tax avoidance client\n",
            "Predicted sentiment probabilities: tensor([[0.2956, 0.3487, 0.3557]], grad_fn=<SoftmaxBackward0>) 201\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3065, 0.4606, 0.2329]], grad_fn=<SoftmaxBackward0>) 202\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2740, 0.3197, 0.4063]], grad_fn=<SoftmaxBackward0>) 203\n",
            "Sentence: update 1 astrazeneca sell rare cancer drug sanofi $ 300 mln\n",
            "Predicted sentiment probabilities: tensor([[0.3012, 0.3847, 0.3142]], grad_fn=<SoftmaxBackward0>) 204\n",
            "Sentence: sainsbury sell unit lloydspharmacy\n",
            "Predicted sentiment probabilities: tensor([[0.2911, 0.3748, 0.3341]], grad_fn=<SoftmaxBackward0>) 205\n",
            "Sentence: bae system sale boost european typhoon currency\n",
            "Predicted sentiment probabilities: tensor([[0.2821, 0.3485, 0.3694]], grad_fn=<SoftmaxBackward0>) 206\n",
            "Sentence: royal mail breach competition law delivery service change ofcom claim\n",
            "Predicted sentiment probabilities: tensor([[0.3638, 0.3810, 0.2551]], grad_fn=<SoftmaxBackward0>) 207\n",
            "Sentence: britain ftse steady support dixon carphone\n",
            "Predicted sentiment probabilities: tensor([[0.3588, 0.3765, 0.2647]], grad_fn=<SoftmaxBackward0>) 208\n",
            "Sentence: glaxo viiv healthcare sign china manufacturing deal desano\n",
            "Predicted sentiment probabilities: tensor([[0.2905, 0.3217, 0.3879]], grad_fn=<SoftmaxBackward0>) 209\n",
            "Sentence: astrazeneca sell caprelsa right sanofi unit\n",
            "Predicted sentiment probabilities: tensor([[0.3195, 0.3693, 0.3112]], grad_fn=<SoftmaxBackward0>) 210\n",
            "Sentence: update 5 barclay chairman mcfarlane axis ceo speed strategic change\n",
            "Predicted sentiment probabilities: tensor([[0.3528, 0.3476, 0.2996]], grad_fn=<SoftmaxBackward0>) 211\n",
            "Sentence: miner meltdown bhp rio tinto sink commodity rout\n",
            "Predicted sentiment probabilities: tensor([[0.3489, 0.3312, 0.3199]], grad_fn=<SoftmaxBackward0>) 212\n",
            "Sentence: ftse lead lower m&s glaxosmithkline\n",
            "Predicted sentiment probabilities: tensor([[0.2936, 0.4209, 0.2856]], grad_fn=<SoftmaxBackward0>) 213\n",
            "Sentence: gkn buy fokker technology 706 mln euro\n",
            "Predicted sentiment probabilities: tensor([[0.3867, 0.2907, 0.3225]], grad_fn=<SoftmaxBackward0>) 214\n",
            "Sentence: diageo sell ryder cup venue gleneagle hotel ennismore group\n",
            "Predicted sentiment probabilities: tensor([[0.3238, 0.3267, 0.3495]], grad_fn=<SoftmaxBackward0>) 215\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3414, 0.3056, 0.3530]], grad_fn=<SoftmaxBackward0>) 216\n",
            "Sentence: update cib legal general sell egyptian life joint venture axa\n",
            "Predicted sentiment probabilities: tensor([[0.3422, 0.3294, 0.3284]], grad_fn=<SoftmaxBackward0>) 217\n",
            "Sentence: chime communication set acquire wpp providence\n",
            "Predicted sentiment probabilities: tensor([[0.3572, 0.2827, 0.3601]], grad_fn=<SoftmaxBackward0>) 218\n",
            "Sentence: companiesnew aggreko ceo reshape business strip cost\n",
            "Predicted sentiment probabilities: tensor([[0.3108, 0.3604, 0.3288]], grad_fn=<SoftmaxBackward0>) 219\n",
            "Sentence: astrazeneca pay inovio $ 700 million cancer drug\n",
            "Predicted sentiment probabilities: tensor([[0.3498, 0.3478, 0.3024]], grad_fn=<SoftmaxBackward0>) 220\n",
            "Sentence: rio tinto ceo say iron ore market equilibrium\n",
            "Predicted sentiment probabilities: tensor([[0.3748, 0.2875, 0.3377]], grad_fn=<SoftmaxBackward0>) 221\n",
            "Sentence: sanction gazprom shell alliance plan jeopardy\n",
            "Predicted sentiment probabilities: tensor([[0.2635, 0.3744, 0.3621]], grad_fn=<SoftmaxBackward0>) 222\n",
            "Sentence: standard charter raise capital dividend cut\n",
            "Predicted sentiment probabilities: tensor([[0.3159, 0.3914, 0.2927]], grad_fn=<SoftmaxBackward0>) 223\n",
            "Sentence: update 1 bhp billiton credit rating fragile fy16 agency warn\n",
            "Predicted sentiment probabilities: tensor([[0.2717, 0.4500, 0.2783]], grad_fn=<SoftmaxBackward0>) 224\n",
            "Sentence: crh add cr laurence acquisition tally $ 1.3bn\n",
            "Predicted sentiment probabilities: tensor([[0.3145, 0.3391, 0.3464]], grad_fn=<SoftmaxBackward0>) 225\n",
            "Sentence: novartis buy remain right gsk treatment deal $ 1 billion\n",
            "Predicted sentiment probabilities: tensor([[0.3825, 0.3073, 0.3102]], grad_fn=<SoftmaxBackward0>) 226\n",
            "Sentence: astrazeneca bag cancer drug deal time inovio\n",
            "Predicted sentiment probabilities: tensor([[0.3573, 0.3675, 0.2752]], grad_fn=<SoftmaxBackward0>) 227\n",
            "Sentence: refile aviva investor 34 bln euro asset axa fund arm\n",
            "Predicted sentiment probabilities: tensor([[0.4535, 0.2448, 0.3018]], grad_fn=<SoftmaxBackward0>) 228\n",
            "Sentence: l&g pay price dividend cut crisis chief say\n",
            "Predicted sentiment probabilities: tensor([[0.3376, 0.2951, 0.3673]], grad_fn=<SoftmaxBackward0>) 229\n",
            "Sentence: buffett company report 37 percent drop 2q earning\n",
            "Predicted sentiment probabilities: tensor([[0.3516, 0.2740, 0.3744]], grad_fn=<SoftmaxBackward0>) 230\n",
            "Sentence: travis perkin hike dividend 20 profit revenue rise\n",
            "Predicted sentiment probabilities: tensor([[0.3828, 0.3611, 0.2560]], grad_fn=<SoftmaxBackward0>) 231\n",
            "Sentence: tesco asda sale fall march discounter continue kantar\n",
            "Predicted sentiment probabilities: tensor([[0.3788, 0.2437, 0.3775]], grad_fn=<SoftmaxBackward0>) 232\n",
            "Sentence: shire propose $ 30 bln share tie baxalta\n",
            "Predicted sentiment probabilities: tensor([[0.3195, 0.3526, 0.3279]], grad_fn=<SoftmaxBackward0>) 233\n",
            "Sentence: shire ceo step drive baxalta board talk\n",
            "Predicted sentiment probabilities: tensor([[0.3092, 0.3932, 0.2976]], grad_fn=<SoftmaxBackward0>) 234\n",
            "Sentence: tesco asda sale fall march discounter continue kantar\n",
            "Predicted sentiment probabilities: tensor([[0.3141, 0.3143, 0.3716]], grad_fn=<SoftmaxBackward0>) 235\n",
            "Sentence: verizon at&t accuse hurt rival\n",
            "Predicted sentiment probabilities: tensor([[0.2888, 0.3303, 0.3809]], grad_fn=<SoftmaxBackward0>) 236\n",
            "Sentence: ftse 100 fall china devaluation hit burberry mining stock\n",
            "Predicted sentiment probabilities: tensor([[0.3256, 0.2948, 0.3795]], grad_fn=<SoftmaxBackward0>) 237\n",
            "Sentence: nine bank include barclay citi agree pay $ 2 billion settle forex\n",
            "Predicted sentiment probabilities: tensor([[0.3382, 0.3858, 0.2760]], grad_fn=<SoftmaxBackward0>) 238\n",
            "Sentence: companiescar insurer hastings group drive Ã¢Â£180 m ipo\n",
            "Predicted sentiment probabilities: tensor([[0.4518, 0.2679, 0.2803]], grad_fn=<SoftmaxBackward0>) 239\n",
            "Sentence: glencore slump 25 pct debt fear grow\n",
            "Predicted sentiment probabilities: tensor([[0.3270, 0.3818, 0.2912]], grad_fn=<SoftmaxBackward0>) 240\n",
            "Sentence: horizonte acquire neighbouring glencore nickel property brazil\n",
            "Predicted sentiment probabilities: tensor([[0.2969, 0.4016, 0.3016]], grad_fn=<SoftmaxBackward0>) 241\n",
            "Sentence: update 1 engineering firm smith group confirm ceo appointment\n",
            "Predicted sentiment probabilities: tensor([[0.3552, 0.2915, 0.3533]], grad_fn=<SoftmaxBackward0>) 242\n",
            "Sentence: industry newsmorrison unveil store close 900 job face axe\n",
            "Predicted sentiment probabilities: tensor([[0.3787, 0.3249, 0.2964]], grad_fn=<SoftmaxBackward0>) 243\n",
            "Sentence: glencore slump 30 percent debt fear grow\n",
            "Predicted sentiment probabilities: tensor([[0.3888, 0.2941, 0.3171]], grad_fn=<SoftmaxBackward0>) 244\n",
            "Sentence: aberdeen asset management gain foothold china\n",
            "Predicted sentiment probabilities: tensor([[0.3142, 0.3170, 0.3688]], grad_fn=<SoftmaxBackward0>) 245\n",
            "Sentence: arm holdings plc partner international business machines corp drive\n",
            "Predicted sentiment probabilities: tensor([[0.2729, 0.3553, 0.3718]], grad_fn=<SoftmaxBackward0>) 246\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3297, 0.2737, 0.3966]], grad_fn=<SoftmaxBackward0>) 247\n",
            "Sentence: ftse 100 drop 2.5 pct glencore metal price fear\n",
            "Predicted sentiment probabilities: tensor([[0.3602, 0.2978, 0.3421]], grad_fn=<SoftmaxBackward0>) 248\n",
            "Sentence: barclay bank america citigroup blockchain sight\n",
            "Predicted sentiment probabilities: tensor([[0.2673, 0.3946, 0.3381]], grad_fn=<SoftmaxBackward0>) 249\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3085, 0.4595, 0.2319]], grad_fn=<SoftmaxBackward0>) 250\n",
            "Sentence: ab inbev approach sabmiller explore $ 250bn tie\n",
            "Predicted sentiment probabilities: tensor([[0.3045, 0.4108, 0.2846]], grad_fn=<SoftmaxBackward0>) 251\n",
            "Sentence: eu regulator back approval gsk injectable asthma drug\n",
            "Predicted sentiment probabilities: tensor([[0.4769, 0.2189, 0.3042]], grad_fn=<SoftmaxBackward0>) 252\n",
            "Sentence: glencore fight debt fear lift share\n",
            "Predicted sentiment probabilities: tensor([[0.4259, 0.2832, 0.2909]], grad_fn=<SoftmaxBackward0>) 253\n",
            "Sentence: news feedftse 100 mover ashtead jump strong interim glencore bp\n",
            "Predicted sentiment probabilities: tensor([[0.3318, 0.2867, 0.3816]], grad_fn=<SoftmaxBackward0>) 254\n",
            "Sentence: brewer ab inbev seek $ 275 bln tie sabmiller\n",
            "Predicted sentiment probabilities: tensor([[0.3589, 0.3597, 0.2814]], grad_fn=<SoftmaxBackward0>) 255\n",
            "Sentence: ab inbev look win sabmiller investor\n",
            "Predicted sentiment probabilities: tensor([[0.3917, 0.3550, 0.2532]], grad_fn=<SoftmaxBackward0>) 256\n",
            "Sentence: update 1 eu regulator back approval gsk injectable asthma drug\n",
            "Predicted sentiment probabilities: tensor([[0.3947, 0.2636, 0.3417]], grad_fn=<SoftmaxBackward0>) 257\n",
            "Sentence: copper market 2003 style supply shock glencore closure\n",
            "Predicted sentiment probabilities: tensor([[0.3777, 0.2751, 0.3471]], grad_fn=<SoftmaxBackward0>) 258\n",
            "Sentence: talktalk hire bae system investigate cyber attack\n",
            "Predicted sentiment probabilities: tensor([[0.2610, 0.3803, 0.3587]], grad_fn=<SoftmaxBackward0>) 259\n",
            "Sentence: renew ab inbev bid sabmiller up stake beer battle\n",
            "Predicted sentiment probabilities: tensor([[0.3089, 0.3441, 0.3469]], grad_fn=<SoftmaxBackward0>) 260\n",
            "Sentence: companiesab inbev signal will hostile sabmiller\n",
            "Predicted sentiment probabilities: tensor([[0.3410, 0.3599, 0.2992]], grad_fn=<SoftmaxBackward0>) 261\n",
            "Sentence: astrazeneca diabete drug combination face delay fda rebuff\n",
            "Predicted sentiment probabilities: tensor([[0.4216, 0.2730, 0.3054]], grad_fn=<SoftmaxBackward0>) 262\n",
            "Sentence: mylan appoint ranjan ray chaudhuri global commercial lead mylan\n",
            "Predicted sentiment probabilities: tensor([[0.3033, 0.3436, 0.3531]], grad_fn=<SoftmaxBackward0>) 263\n",
            "Sentence: sabmiller revenue hit weak em currency\n",
            "Predicted sentiment probabilities: tensor([[0.3046, 0.3348, 0.3606]], grad_fn=<SoftmaxBackward0>) 264\n",
            "Sentence: update 5 sabmiller reject ab inbev $ 104 bln takeover approach\n",
            "Predicted sentiment probabilities: tensor([[0.4055, 0.2975, 0.2970]], grad_fn=<SoftmaxBackward0>) 265\n",
            "Sentence: market report eight day rally end ftse 100 standard charter\n",
            "Predicted sentiment probabilities: tensor([[0.3015, 0.3318, 0.3667]], grad_fn=<SoftmaxBackward0>) 266\n",
            "Sentence: ab inbev offer sabmiller $ 3 billion breakup fee\n",
            "Predicted sentiment probabilities: tensor([[0.2971, 0.4123, 0.2906]], grad_fn=<SoftmaxBackward0>) 267\n",
            "Sentence: gsk join china trade push uk trumpets healthcare deal\n",
            "Predicted sentiment probabilities: tensor([[0.3439, 0.3421, 0.3140]], grad_fn=<SoftmaxBackward0>) 268\n",
            "Sentence: ab inbev up offer sabmiller deadline loom\n",
            "Predicted sentiment probabilities: tensor([[0.4363, 0.2847, 0.2790]], grad_fn=<SoftmaxBackward0>) 269\n",
            "Sentence: tesco plc recovery continue Ã¢Â£250 m cash infusion\n",
            "Predicted sentiment probabilities: tensor([[0.3286, 0.3587, 0.3127]], grad_fn=<SoftmaxBackward0>) 270\n",
            "Sentence: metal zinc surge 12 pct glencore cut output fuel metal rally\n",
            "Predicted sentiment probabilities: tensor([[0.3487, 0.3213, 0.3300]], grad_fn=<SoftmaxBackward0>) 271\n",
            "Sentence: companiesunilever sale lift ice cream soft economy\n",
            "Predicted sentiment probabilities: tensor([[0.2827, 0.3589, 0.3584]], grad_fn=<SoftmaxBackward0>) 272\n",
            "Sentence: ab inbev late bid say unlikely win sabmiller approval\n",
            "Predicted sentiment probabilities: tensor([[0.2900, 0.2867, 0.4233]], grad_fn=<SoftmaxBackward0>) 273\n",
            "Sentence: britain ftse forge ahead shire surge\n",
            "Predicted sentiment probabilities: tensor([[0.3620, 0.3295, 0.3085]], grad_fn=<SoftmaxBackward0>) 274\n",
            "Sentence: ab inbev attack sabmiller bid rebuffal\n",
            "Predicted sentiment probabilities: tensor([[0.3597, 0.2833, 0.3569]], grad_fn=<SoftmaxBackward0>) 275\n",
            "Sentence: anheuser busch inbev increase offer rival sabmiller\n",
            "Predicted sentiment probabilities: tensor([[0.3474, 0.3207, 0.3319]], grad_fn=<SoftmaxBackward0>) 276\n",
            "Sentence: buy arm holdings plc bhp billiton plc today\n",
            "Predicted sentiment probabilities: tensor([[0.2960, 0.3379, 0.3661]], grad_fn=<SoftmaxBackward0>) 277\n",
            "Sentence: barclays plc lloyds banking group plc 2 bank buy today\n",
            "Predicted sentiment probabilities: tensor([[0.3001, 0.2934, 0.4065]], grad_fn=<SoftmaxBackward0>) 278\n",
            "Sentence: easyjet dismisse lufthansa low cost plan contest germany\n",
            "Predicted sentiment probabilities: tensor([[0.3574, 0.3080, 0.3346]], grad_fn=<SoftmaxBackward0>) 279\n",
            "Sentence: exclusive bp china cnpc unveil oil alliance source\n",
            "Predicted sentiment probabilities: tensor([[0.3567, 0.3169, 0.3264]], grad_fn=<SoftmaxBackward0>) 280\n",
            "Sentence: sab chairman dig board divide inbev offer\n",
            "Predicted sentiment probabilities: tensor([[0.2940, 0.3943, 0.3116]], grad_fn=<SoftmaxBackward0>) 281\n",
            "Sentence: kinder morgan bp form joint venture limited liability company purchase\n",
            "Predicted sentiment probabilities: tensor([[0.3319, 0.3798, 0.2883]], grad_fn=<SoftmaxBackward0>) 282\n",
            "Sentence: supreme court uphold $ 236 million jury award exxonmobil\n",
            "Predicted sentiment probabilities: tensor([[0.3258, 0.3693, 0.3049]], grad_fn=<SoftmaxBackward0>) 283\n",
            "Sentence: standard chartered share plunge 7 fitch downgrade\n",
            "Predicted sentiment probabilities: tensor([[0.4514, 0.2474, 0.3013]], grad_fn=<SoftmaxBackward0>) 284\n",
            "Sentence: wpp win race programmatic buying agency essence digital\n",
            "Predicted sentiment probabilities: tensor([[0.2943, 0.3039, 0.4017]], grad_fn=<SoftmaxBackward0>) 285\n",
            "Sentence: bhp billiton share price brazil sue samarco Ã¢Â£3.5bn\n",
            "Predicted sentiment probabilities: tensor([[0.2985, 0.3258, 0.3757]], grad_fn=<SoftmaxBackward0>) 286\n",
            "Sentence: g4s slide balance sheet worry\n",
            "Predicted sentiment probabilities: tensor([[0.4380, 0.2260, 0.3360]], grad_fn=<SoftmaxBackward0>) 287\n",
            "Sentence: fda approve astrazeneca drug advanced lung cancer\n",
            "Predicted sentiment probabilities: tensor([[0.3002, 0.3458, 0.3540]], grad_fn=<SoftmaxBackward0>) 288\n",
            "Sentence: hsbc appoint business leader board\n",
            "Predicted sentiment probabilities: tensor([[0.3403, 0.3884, 0.2713]], grad_fn=<SoftmaxBackward0>) 289\n",
            "Sentence: hsbc shake board two new business chief three departure\n",
            "Predicted sentiment probabilities: tensor([[0.3692, 0.2091, 0.4217]], grad_fn=<SoftmaxBackward0>) 290\n",
            "Sentence: astrazeneca win fda approval key new lung cancer pill\n",
            "Predicted sentiment probabilities: tensor([[0.2626, 0.5080, 0.2294]], grad_fn=<SoftmaxBackward0>) 291\n",
            "Sentence: update 1 lloyds cut 945 job 3 year restructuring plan\n",
            "Predicted sentiment probabilities: tensor([[0.3598, 0.3419, 0.2983]], grad_fn=<SoftmaxBackward0>) 292\n",
            "Sentence: standard charter shift emerge market strategy loss\n",
            "Predicted sentiment probabilities: tensor([[0.3260, 0.3639, 0.3101]], grad_fn=<SoftmaxBackward0>) 293\n",
            "Sentence: astrazeneca lung cancer drug tagrisso get fda approval\n",
            "Predicted sentiment probabilities: tensor([[0.3283, 0.3631, 0.3086]], grad_fn=<SoftmaxBackward0>) 294\n",
            "Sentence: severn trent share price rise first half profit inch customer\n",
            "Predicted sentiment probabilities: tensor([[0.3111, 0.3619, 0.3270]], grad_fn=<SoftmaxBackward0>) 295\n",
            "Sentence: glencore see tripoli base noc sole legal seller libyan oil\n",
            "Predicted sentiment probabilities: tensor([[0.3625, 0.3003, 0.3372]], grad_fn=<SoftmaxBackward0>) 296\n",
            "Sentence: lloyds cut 945 job three year restructuring strategy\n",
            "Predicted sentiment probabilities: tensor([[0.3875, 0.3056, 0.3069]], grad_fn=<SoftmaxBackward0>) 297\n",
            "Sentence: astrazeneca buy zs pharma $ 2.7 billion\n",
            "Predicted sentiment probabilities: tensor([[0.3253, 0.3221, 0.3526]], grad_fn=<SoftmaxBackward0>) 298\n",
            "Sentence: ackman email say support valeant ceo pearson\n",
            "Predicted sentiment probabilities: tensor([[0.2661, 0.4010, 0.3330]], grad_fn=<SoftmaxBackward0>) 299\n",
            "Sentence: astrazeneca sell drug right perrigo $ 380 mln\n",
            "Predicted sentiment probabilities: tensor([[0.3353, 0.3178, 0.3469]], grad_fn=<SoftmaxBackward0>) 300\n",
            "Sentence: update 1 astrazeneca buy zs pharma $ 2.7 billion pip actelion\n",
            "Predicted sentiment probabilities: tensor([[0.3022, 0.3081, 0.3897]], grad_fn=<SoftmaxBackward0>) 301\n",
            "Sentence: correct shire buy dyax $ 5.9 bln\n",
            "Predicted sentiment probabilities: tensor([[0.3457, 0.3192, 0.3351]], grad_fn=<SoftmaxBackward0>) 302\n",
            "Sentence: barclay poise replace sir mike rake head exit\n",
            "Predicted sentiment probabilities: tensor([[0.3281, 0.3783, 0.2935]], grad_fn=<SoftmaxBackward0>) 303\n",
            "Sentence: astrazeneca acquire zs pharma $ 2.7 billion deal\n",
            "Predicted sentiment probabilities: tensor([[0.2597, 0.3475, 0.3928]], grad_fn=<SoftmaxBackward0>) 304\n",
            "Sentence: astrazeneca share climb 3 drug maker up profit forecast\n",
            "Predicted sentiment probabilities: tensor([[0.3317, 0.2870, 0.3814]], grad_fn=<SoftmaxBackward0>) 305\n",
            "Sentence: peroni grolsch sale ab inbev plan acquisition sabmiller\n",
            "Predicted sentiment probabilities: tensor([[0.3392, 0.3551, 0.3057]], grad_fn=<SoftmaxBackward0>) 306\n",
            "Sentence: easyjet expect resilient demand withstand security fear\n",
            "Predicted sentiment probabilities: tensor([[0.3497, 0.2847, 0.3656]], grad_fn=<SoftmaxBackward0>) 307\n",
            "Sentence: compass group say positive year ahead\n",
            "Predicted sentiment probabilities: tensor([[0.3009, 0.4085, 0.2907]], grad_fn=<SoftmaxBackward0>) 308\n",
            "Sentence: dollar wipe sale gain sabmiller\n",
            "Predicted sentiment probabilities: tensor([[0.3015, 0.3435, 0.3550]], grad_fn=<SoftmaxBackward0>) 309\n",
            "Sentence: update 1 sabmiller 2nd quarter underlying sale rise forex impact margin\n",
            "Predicted sentiment probabilities: tensor([[0.3135, 0.3439, 0.3426]], grad_fn=<SoftmaxBackward0>) 310\n",
            "Sentence: update 2 pricey beer lift sabmiller quarterly underlying sale\n",
            "Predicted sentiment probabilities: tensor([[0.2901, 0.4265, 0.2834]], grad_fn=<SoftmaxBackward0>) 311\n",
            "Sentence: valeant ceo pledge heed critic ` painful experience\n",
            "Predicted sentiment probabilities: tensor([[0.3187, 0.3328, 0.3485]], grad_fn=<SoftmaxBackward0>) 312\n",
            "Sentence: aviva plc direct line insurance group plc admiral group plc set soar\n",
            "Predicted sentiment probabilities: tensor([[0.3741, 0.3526, 0.2733]], grad_fn=<SoftmaxBackward0>) 313\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3049, 0.3655, 0.3297]], grad_fn=<SoftmaxBackward0>) 314\n",
            "Sentence: stanchart rbs struggle bank england stress test\n",
            "Predicted sentiment probabilities: tensor([[0.3746, 0.2973, 0.3281]], grad_fn=<SoftmaxBackward0>) 315\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2846, 0.3865, 0.3290]], grad_fn=<SoftmaxBackward0>) 316\n",
            "Sentence: barclays sell benchmark index unit bloomberg\n",
            "Predicted sentiment probabilities: tensor([[0.3280, 0.3045, 0.3674]], grad_fn=<SoftmaxBackward0>) 317\n",
            "Sentence: sainsbury asda tesco morrison cut petrol price oil fall\n",
            "Predicted sentiment probabilities: tensor([[0.3390, 0.2702, 0.3908]], grad_fn=<SoftmaxBackward0>) 318\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3405, 0.3110, 0.3484]], grad_fn=<SoftmaxBackward0>) 319\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3670, 0.3280, 0.3050]], grad_fn=<SoftmaxBackward0>) 320\n",
            "Sentence: eu drop shell bp statoil ethanol benchmark investigation\n",
            "Predicted sentiment probabilities: tensor([[0.3284, 0.3619, 0.3096]], grad_fn=<SoftmaxBackward0>) 321\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3318, 0.2800, 0.3882]], grad_fn=<SoftmaxBackward0>) 322\n",
            "Sentence: astrazeneca explore potential deal acerta cancer drug\n",
            "Predicted sentiment probabilities: tensor([[0.2782, 0.3968, 0.3249]], grad_fn=<SoftmaxBackward0>) 323\n",
            "Sentence: shell bg shareholder vote deal end january\n",
            "Predicted sentiment probabilities: tensor([[0.2909, 0.3210, 0.3881]], grad_fn=<SoftmaxBackward0>) 324\n",
            "Sentence: astrazeneca chase acerta secure cancer drug winner\n",
            "Predicted sentiment probabilities: tensor([[0.3505, 0.4526, 0.1970]], grad_fn=<SoftmaxBackward0>) 325\n",
            "Sentence: companiestesco bad start xmas Ã¢â‚¬ kantar\n",
            "Predicted sentiment probabilities: tensor([[0.3916, 0.2892, 0.3193]], grad_fn=<SoftmaxBackward0>) 326\n",
            "Sentence: dbs julius baer emerge potential bidder barclays asia wealth unit\n",
            "Predicted sentiment probabilities: tensor([[0.4000, 0.2646, 0.3354]], grad_fn=<SoftmaxBackward0>) 327\n",
            "Sentence: astrazeneca plc dixons carphone plc red hot growth star\n",
            "Predicted sentiment probabilities: tensor([[0.2505, 0.3130, 0.4365]], grad_fn=<SoftmaxBackward0>) 328\n",
            "Sentence: bbcn bancorp buy wilshire bancorp $ 1 bln deal\n",
            "Predicted sentiment probabilities: tensor([[0.3425, 0.3128, 0.3447]], grad_fn=<SoftmaxBackward0>) 329\n",
            "Sentence: itv share price jump report comcast nbcuniversal bidding takeover\n",
            "Predicted sentiment probabilities: tensor([[0.3436, 0.2888, 0.3676]], grad_fn=<SoftmaxBackward0>) 330\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3276, 0.3790, 0.2934]], grad_fn=<SoftmaxBackward0>) 331\n",
            "Sentence: glencore study possible ipo agricultural trading business\n",
            "Predicted sentiment probabilities: tensor([[0.2733, 0.4285, 0.2982]], grad_fn=<SoftmaxBackward0>) 332\n",
            "Sentence: christmas save sainsbury plc tesco plc\n",
            "Predicted sentiment probabilities: tensor([[0.2921, 0.4043, 0.3036]], grad_fn=<SoftmaxBackward0>) 333\n",
            "Sentence: update 1 astrazeneca boost respiratory unit $ 575 mln takeda deal\n",
            "Predicted sentiment probabilities: tensor([[0.2464, 0.4338, 0.3198]], grad_fn=<SoftmaxBackward0>) 334\n",
            "Sentence: bilfinger industrial service win Ã¢Â£100 m bp contract extension\n",
            "Predicted sentiment probabilities: tensor([[0.2479, 0.3961, 0.3560]], grad_fn=<SoftmaxBackward0>) 335\n",
            "Sentence: standard chartered rbs escape capital raising stress test\n",
            "Predicted sentiment probabilities: tensor([[0.2751, 0.3451, 0.3798]], grad_fn=<SoftmaxBackward0>) 336\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3324, 0.3452, 0.3224]], grad_fn=<SoftmaxBackward0>) 337\n",
            "Sentence: astrazeneca weigh acerta bid secure blood cancer drug\n",
            "Predicted sentiment probabilities: tensor([[0.2946, 0.3234, 0.3819]], grad_fn=<SoftmaxBackward0>) 338\n",
            "Sentence: 2 turnaround buy 2016 bhp billiton plc home retail group plc\n",
            "Predicted sentiment probabilities: tensor([[0.3415, 0.3725, 0.2860]], grad_fn=<SoftmaxBackward0>) 339\n",
            "Sentence: l&g complete uk large medically underwritten bulk pension risk deal\n",
            "Predicted sentiment probabilities: tensor([[0.2420, 0.3966, 0.3614]], grad_fn=<SoftmaxBackward0>) 340\n",
            "Sentence: drugmaker shire buy baxalta $ 32 billion 6 month pursuit\n",
            "Predicted sentiment probabilities: tensor([[0.3032, 0.3699, 0.3269]], grad_fn=<SoftmaxBackward0>) 341\n",
            "Sentence: kingfisher share price slide cost implement new strategy\n",
            "Predicted sentiment probabilities: tensor([[0.3016, 0.3671, 0.3313]], grad_fn=<SoftmaxBackward0>) 342\n",
            "Sentence: shire say internal synergy goal baxalta deal higher\n",
            "Predicted sentiment probabilities: tensor([[0.2784, 0.3919, 0.3297]], grad_fn=<SoftmaxBackward0>) 343\n",
            "Sentence: european share plunge roil bhp oil hope turn ecb\n",
            "Predicted sentiment probabilities: tensor([[0.4049, 0.2546, 0.3405]], grad_fn=<SoftmaxBackward0>) 344\n",
            "Sentence: morrison debenham surprise city christmas bounce\n",
            "Predicted sentiment probabilities: tensor([[0.3171, 0.4082, 0.2747]], grad_fn=<SoftmaxBackward0>) 345\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.4005, 0.3225, 0.2769]], grad_fn=<SoftmaxBackward0>) 346\n",
            "Sentence: britain ftse fall ashtead commodity pressure\n",
            "Predicted sentiment probabilities: tensor([[0.3267, 0.3139, 0.3594]], grad_fn=<SoftmaxBackward0>) 347\n",
            "Sentence: tesco share jump 6 christmas sale beat expectation\n",
            "Predicted sentiment probabilities: tensor([[0.2453, 0.4194, 0.3353]], grad_fn=<SoftmaxBackward0>) 348\n",
            "Sentence: ceos bpm ubi meet italy econ minister m&a talk heat\n",
            "Predicted sentiment probabilities: tensor([[0.3309, 0.2569, 0.4122]], grad_fn=<SoftmaxBackward0>) 349\n",
            "Sentence: companieshome retail trim gain consider play\n",
            "Predicted sentiment probabilities: tensor([[0.4088, 0.2454, 0.3458]], grad_fn=<SoftmaxBackward0>) 350\n",
            "Sentence: philippine san miguel say partner kirin bid sabmiller\n",
            "Predicted sentiment probabilities: tensor([[0.3063, 0.3872, 0.3066]], grad_fn=<SoftmaxBackward0>) 351\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3265, 0.3467, 0.3268]], grad_fn=<SoftmaxBackward0>) 352\n",
            "Sentence: investor remain skeptical shell bg deal\n",
            "Predicted sentiment probabilities: tensor([[0.3528, 0.3275, 0.3197]], grad_fn=<SoftmaxBackward0>) 353\n",
            "Sentence: marketsshire 2.5 baxalta 6 $ 32bn deal\n",
            "Predicted sentiment probabilities: tensor([[0.4327, 0.2786, 0.2887]], grad_fn=<SoftmaxBackward0>) 354\n",
            "Sentence: shire share price pressure $ 32bn baxalta deal\n",
            "Predicted sentiment probabilities: tensor([[0.3457, 0.3408, 0.3135]], grad_fn=<SoftmaxBackward0>) 355\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3510, 0.3226, 0.3264]], grad_fn=<SoftmaxBackward0>) 356\n",
            "Sentence: valeant name interim leader ceo remains hospitalize\n",
            "Predicted sentiment probabilities: tensor([[0.3265, 0.3432, 0.3303]], grad_fn=<SoftmaxBackward0>) 357\n",
            "Sentence: valeant say new ceo pearson hospitalize\n",
            "Predicted sentiment probabilities: tensor([[0.3828, 0.2728, 0.3444]], grad_fn=<SoftmaxBackward0>) 358\n",
            "Sentence: share bae system hit 10 month high rating upgrade\n",
            "Predicted sentiment probabilities: tensor([[0.2772, 0.4289, 0.2939]], grad_fn=<SoftmaxBackward0>) 359\n",
            "Sentence: japan asahi submit bid week sabmiller grolsch peroni yomiuri\n",
            "Predicted sentiment probabilities: tensor([[0.4015, 0.3070, 0.2915]], grad_fn=<SoftmaxBackward0>) 360\n",
            "Sentence: companiesdixon carphone close 134 uk store sale jump\n",
            "Predicted sentiment probabilities: tensor([[0.3609, 0.3147, 0.3243]], grad_fn=<SoftmaxBackward0>) 361\n",
            "Sentence: broker tip rbs croda sage\n",
            "Predicted sentiment probabilities: tensor([[0.3442, 0.2964, 0.3594]], grad_fn=<SoftmaxBackward0>) 362\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2626, 0.3142, 0.4231]], grad_fn=<SoftmaxBackward0>) 363\n",
            "Sentence: shell share price standard life announce position bg acquisition\n",
            "Predicted sentiment probabilities: tensor([[0.3345, 0.3341, 0.3314]], grad_fn=<SoftmaxBackward0>) 364\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3467, 0.3432, 0.3102]], grad_fn=<SoftmaxBackward0>) 365\n",
            "Sentence: tesco share price grocer face sfo investigation outcome\n",
            "Predicted sentiment probabilities: tensor([[0.4896, 0.2123, 0.2981]], grad_fn=<SoftmaxBackward0>) 366\n",
            "Sentence: britain ftse outperform europe royal mail tesco rise\n",
            "Predicted sentiment probabilities: tensor([[0.3737, 0.2765, 0.3498]], grad_fn=<SoftmaxBackward0>) 367\n",
            "Sentence: greene king third quarter sale boost festive season\n",
            "Predicted sentiment probabilities: tensor([[0.3264, 0.3294, 0.3442]], grad_fn=<SoftmaxBackward0>) 368\n",
            "Sentence: intercontinental hotels group share price climb $ 1.5bn special dividend\n",
            "Predicted sentiment probabilities: tensor([[0.2888, 0.2820, 0.4292]], grad_fn=<SoftmaxBackward0>) 369\n",
            "Sentence: amazon attack uk grocery market morrison deal\n",
            "Predicted sentiment probabilities: tensor([[0.2960, 0.3411, 0.3628]], grad_fn=<SoftmaxBackward0>) 370\n",
            "Sentence: astrazeneca share price acerta deal pay orphan drug status\n",
            "Predicted sentiment probabilities: tensor([[0.3754, 0.3051, 0.3195]], grad_fn=<SoftmaxBackward0>) 371\n",
            "Sentence: bhp billiton post big loss slash dividend\n",
            "Predicted sentiment probabilities: tensor([[0.2709, 0.2889, 0.4402]], grad_fn=<SoftmaxBackward0>) 372\n",
            "Sentence: merge lse deutsche bÃ£Â¶rse lead germany kengeter\n",
            "Predicted sentiment probabilities: tensor([[0.3304, 0.2722, 0.3974]], grad_fn=<SoftmaxBackward0>) 373\n",
            "Sentence: buy jumbo yielder british american tobacco plc centrica plc john wood group plc\n",
            "Predicted sentiment probabilities: tensor([[0.3220, 0.2262, 0.4518]], grad_fn=<SoftmaxBackward0>) 374\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2603, 0.3685, 0.3712]], grad_fn=<SoftmaxBackward0>) 375\n",
            "Sentence: trouble brew legal general group plc aviva plc\n",
            "Predicted sentiment probabilities: tensor([[0.3448, 0.2813, 0.3739]], grad_fn=<SoftmaxBackward0>) 376\n",
            "Sentence: bhp billiton drag ftse lower slash dividend\n",
            "Predicted sentiment probabilities: tensor([[0.3388, 0.3831, 0.2781]], grad_fn=<SoftmaxBackward0>) 377\n",
            "Sentence: bhp billiton slashes dividend post $ 5.67 billion net loss\n",
            "Predicted sentiment probabilities: tensor([[0.3243, 0.3326, 0.3431]], grad_fn=<SoftmaxBackward0>) 378\n",
            "Sentence: companiesmeggitt profit hit weak energy military market\n",
            "Predicted sentiment probabilities: tensor([[0.3088, 0.3405, 0.3507]], grad_fn=<SoftmaxBackward0>) 379\n",
            "Sentence: royal mail share price edge lower group raise stamp price\n",
            "Predicted sentiment probabilities: tensor([[0.3069, 0.3537, 0.3394]], grad_fn=<SoftmaxBackward0>) 380\n",
            "Sentence: glaxosmithkline start hunt successor ceo witty\n",
            "Predicted sentiment probabilities: tensor([[0.3558, 0.3010, 0.3432]], grad_fn=<SoftmaxBackward0>) 381\n",
            "Sentence: rio tinto swing loss drop dividend policy\n",
            "Predicted sentiment probabilities: tensor([[0.4125, 0.2862, 0.3013]], grad_fn=<SoftmaxBackward0>) 382\n",
            "Sentence: france raise concern propose lse deutsche boerse deal\n",
            "Predicted sentiment probabilities: tensor([[0.3001, 0.4488, 0.2512]], grad_fn=<SoftmaxBackward0>) 383\n",
            "Sentence: marketsbp promote upstream boss deputy ceo\n",
            "Predicted sentiment probabilities: tensor([[0.2932, 0.3927, 0.3141]], grad_fn=<SoftmaxBackward0>) 384\n",
            "Sentence: legal general share price finance chief step\n",
            "Predicted sentiment probabilities: tensor([[0.3426, 0.3686, 0.2887]], grad_fn=<SoftmaxBackward0>) 385\n",
            "Sentence: barclay poache new chief operating officer paul compton jp morgan chase\n",
            "Predicted sentiment probabilities: tensor([[0.3406, 0.3076, 0.3518]], grad_fn=<SoftmaxBackward0>) 386\n",
            "Sentence: arm profit sale shift away mobile gain pace\n",
            "Predicted sentiment probabilities: tensor([[0.3201, 0.3828, 0.2971]], grad_fn=<SoftmaxBackward0>) 387\n",
            "Sentence: barclays appoint jpmorgan paul compton new coo\n",
            "Predicted sentiment probabilities: tensor([[0.2836, 0.3346, 0.3818]], grad_fn=<SoftmaxBackward0>) 388\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3373, 0.3504, 0.3124]], grad_fn=<SoftmaxBackward0>) 389\n",
            "Sentence: fastjet slams easyjet founder stelio go public take legal advice letter contractual\n",
            "Predicted sentiment probabilities: tensor([[0.3661, 0.3708, 0.2632]], grad_fn=<SoftmaxBackward0>) 390\n",
            "Sentence: nyse owner ice consider offer lse\n",
            "Predicted sentiment probabilities: tensor([[0.3968, 0.2863, 0.3169]], grad_fn=<SoftmaxBackward0>) 391\n",
            "Sentence: news feedftse 100 mover lse surge ice say mull offer ashtead barclay tank\n",
            "Predicted sentiment probabilities: tensor([[0.3727, 0.3402, 0.2871]], grad_fn=<SoftmaxBackward0>) 392\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3149, 0.3124, 0.3727]], grad_fn=<SoftmaxBackward0>) 393\n",
            "Sentence: balfour beatty plc set reinstate dividend rival national grid plc centrica plc\n",
            "Predicted sentiment probabilities: tensor([[0.2847, 0.3592, 0.3561]], grad_fn=<SoftmaxBackward0>) 394\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3749, 0.2915, 0.3337]], grad_fn=<SoftmaxBackward0>) 395\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3043, 0.3549, 0.3408]], grad_fn=<SoftmaxBackward0>) 396\n",
            "Sentence: intertek swing Ã¢Â£347 mln loss oil slump\n",
            "Predicted sentiment probabilities: tensor([[0.3355, 0.3635, 0.3010]], grad_fn=<SoftmaxBackward0>) 397\n",
            "Sentence: sanofi poache astrazeneca scientist new research head\n",
            "Predicted sentiment probabilities: tensor([[0.3398, 0.3328, 0.3273]], grad_fn=<SoftmaxBackward0>) 398\n",
            "Sentence: tesco break downward slide cut sale decline half\n",
            "Predicted sentiment probabilities: tensor([[0.2834, 0.4013, 0.3153]], grad_fn=<SoftmaxBackward0>) 399\n",
            "Sentence: news feedschroder book solid earning growth board change\n",
            "Predicted sentiment probabilities: tensor([[0.3178, 0.2700, 0.4122]], grad_fn=<SoftmaxBackward0>) 400\n",
            "Sentence: intertek group announce strategic update outline plan\n",
            "Predicted sentiment probabilities: tensor([[0.3514, 0.3159, 0.3327]], grad_fn=<SoftmaxBackward0>) 401\n",
            "Sentence: london stock exchange seal Ã¢Â£22 billion merger germany deutsche bÃ£Â¶rse\n",
            "Predicted sentiment probabilities: tensor([[0.3367, 0.3830, 0.2802]], grad_fn=<SoftmaxBackward0>) 402\n",
            "Sentence: nyse owner ice gatecrash deutsche boerse lse merger\n",
            "Predicted sentiment probabilities: tensor([[0.3267, 0.3446, 0.3287]], grad_fn=<SoftmaxBackward0>) 403\n",
            "Sentence: ab inbev sell sabmiller stake china snow beer\n",
            "Predicted sentiment probabilities: tensor([[0.2513, 0.3389, 0.4097]], grad_fn=<SoftmaxBackward0>) 404\n",
            "Sentence: lse deutsche boerse merger signal end exchange mega deal\n",
            "Predicted sentiment probabilities: tensor([[0.4178, 0.2643, 0.3180]], grad_fn=<SoftmaxBackward0>) 405\n",
            "Sentence: rbs pay $ 1.7 billion scrap u.k treasury dividend right\n",
            "Predicted sentiment probabilities: tensor([[0.3524, 0.2492, 0.3984]], grad_fn=<SoftmaxBackward0>) 406\n",
            "Sentence: industry newswolseley confident reslilience amid mixed market\n",
            "Predicted sentiment probabilities: tensor([[0.3427, 0.3646, 0.2927]], grad_fn=<SoftmaxBackward0>) 407\n",
            "Sentence: tesco criticise disgraceful advert show domestic worker slap\n",
            "Predicted sentiment probabilities: tensor([[0.3319, 0.3073, 0.3608]], grad_fn=<SoftmaxBackward0>) 408\n",
            "Sentence: ftse edge investor cheer kingfisher result\n",
            "Predicted sentiment probabilities: tensor([[0.3985, 0.3270, 0.2745]], grad_fn=<SoftmaxBackward0>) 409\n",
            "Sentence: barclay bond rise lender cut dividend shore capital\n",
            "Predicted sentiment probabilities: tensor([[0.3390, 0.3698, 0.2912]], grad_fn=<SoftmaxBackward0>) 410\n",
            "Sentence: britain ftse get lift prudential result\n",
            "Predicted sentiment probabilities: tensor([[0.3136, 0.3191, 0.3674]], grad_fn=<SoftmaxBackward0>) 411\n",
            "Sentence: amazon grocery deal morrison beginning\n",
            "Predicted sentiment probabilities: tensor([[0.4049, 0.2262, 0.3688]], grad_fn=<SoftmaxBackward0>) 412\n",
            "Sentence: ice say start line financing lse bidding war\n",
            "Predicted sentiment probabilities: tensor([[0.3101, 0.4000, 0.2899]], grad_fn=<SoftmaxBackward0>) 413\n",
            "Sentence: bp statoil withdraw staff algeria follow rocket attack\n",
            "Predicted sentiment probabilities: tensor([[0.4132, 0.2630, 0.3238]], grad_fn=<SoftmaxBackward0>) 414\n",
            "Sentence: merkel government say support deutsche boerse lse merger\n",
            "Predicted sentiment probabilities: tensor([[0.4098, 0.2823, 0.3080]], grad_fn=<SoftmaxBackward0>) 415\n",
            "Sentence: aviva weigh cash handout beat profit forecast\n",
            "Predicted sentiment probabilities: tensor([[0.3411, 0.2858, 0.3732]], grad_fn=<SoftmaxBackward0>) 416\n",
            "Sentence: wpp world large ad agency report strong 2015 growth\n",
            "Predicted sentiment probabilities: tensor([[0.3966, 0.2552, 0.3481]], grad_fn=<SoftmaxBackward0>) 417\n",
            "Sentence: saudi aramco shell plan break motiva divide asset\n",
            "Predicted sentiment probabilities: tensor([[0.3181, 0.3301, 0.3518]], grad_fn=<SoftmaxBackward0>) 418\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2872, 0.3452, 0.3676]], grad_fn=<SoftmaxBackward0>) 419\n",
            "Sentence: ab inbev sell sab asset seek eu deal approval\n",
            "Predicted sentiment probabilities: tensor([[0.3845, 0.3372, 0.2783]], grad_fn=<SoftmaxBackward0>) 420\n",
            "Sentence: tesco sale pickup\n",
            "Predicted sentiment probabilities: tensor([[0.3456, 0.3176, 0.3368]], grad_fn=<SoftmaxBackward0>) 421\n",
            "Sentence: spain caixabank expect close deal banco bpi\n",
            "Predicted sentiment probabilities: tensor([[0.3096, 0.2589, 0.4315]], grad_fn=<SoftmaxBackward0>) 422\n",
            "Sentence: itv share price group mull takeover canada entertainment one\n",
            "Predicted sentiment probabilities: tensor([[0.3354, 0.3508, 0.3138]], grad_fn=<SoftmaxBackward0>) 423\n",
            "Sentence: entertainment one dispel itv takeover rumour\n",
            "Predicted sentiment probabilities: tensor([[0.3983, 0.2642, 0.3375]], grad_fn=<SoftmaxBackward0>) 424\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3669, 0.3157, 0.3175]], grad_fn=<SoftmaxBackward0>) 425\n",
            "Sentence: ge sell majority stake bank bph core bank alior bank\n",
            "Predicted sentiment probabilities: tensor([[0.3812, 0.3338, 0.2850]], grad_fn=<SoftmaxBackward0>) 426\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3138, 0.2165, 0.4697]], grad_fn=<SoftmaxBackward0>) 427\n",
            "Sentence: tata steel work stanchart uk unit sale source\n",
            "Predicted sentiment probabilities: tensor([[0.3987, 0.3609, 0.2404]], grad_fn=<SoftmaxBackward0>) 428\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3290, 0.2893, 0.3817]], grad_fn=<SoftmaxBackward0>) 429\n",
            "Sentence: crown castle buy tower development corp $ 461 million\n",
            "Predicted sentiment probabilities: tensor([[0.3326, 0.3625, 0.3049]], grad_fn=<SoftmaxBackward0>) 430\n",
            "Sentence: tesco sell half stake ecommerce site lazada alibaba Ã¢Â£90 m\n",
            "Predicted sentiment probabilities: tensor([[0.2600, 0.4327, 0.3073]], grad_fn=<SoftmaxBackward0>) 431\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2574, 0.3258, 0.4169]], grad_fn=<SoftmaxBackward0>) 432\n",
            "Sentence: caixabank do santo agree plan bpi angola exposure\n",
            "Predicted sentiment probabilities: tensor([[0.3295, 0.3389, 0.3316]], grad_fn=<SoftmaxBackward0>) 433\n",
            "Sentence: bpi say caixabank isabel do santo reach agreement angola exposure\n",
            "Predicted sentiment probabilities: tensor([[0.3489, 0.3599, 0.2912]], grad_fn=<SoftmaxBackward0>) 434\n",
            "Sentence: spain caixabank launch new takeover bid banco bpi\n",
            "Predicted sentiment probabilities: tensor([[0.3185, 0.2821, 0.3994]], grad_fn=<SoftmaxBackward0>) 435\n",
            "Sentence: despite sale growth uk tesco caution recovery bumpy\n",
            "Predicted sentiment probabilities: tensor([[0.3863, 0.2862, 0.3275]], grad_fn=<SoftmaxBackward0>) 436\n",
            "Sentence: itv pursue takeover canada entertainment one bloomberg\n",
            "Predicted sentiment probabilities: tensor([[0.3187, 0.3662, 0.3151]], grad_fn=<SoftmaxBackward0>) 437\n",
            "Sentence: shire see baxalta deal closing expect new rule\n",
            "Predicted sentiment probabilities: tensor([[0.3150, 0.3383, 0.3467]], grad_fn=<SoftmaxBackward0>) 438\n",
            "Sentence: ocbc buy barclay wealth management unit singapore hong kong\n",
            "Predicted sentiment probabilities: tensor([[0.2954, 0.3621, 0.3425]], grad_fn=<SoftmaxBackward0>) 439\n",
            "Sentence: tesco share price steady analyst weigh result\n",
            "Predicted sentiment probabilities: tensor([[0.2459, 0.4091, 0.3450]], grad_fn=<SoftmaxBackward0>) 440\n",
            "Sentence: lloyds banking group share price lift amid report bank poise axe hundred uk job\n",
            "Predicted sentiment probabilities: tensor([[0.3720, 0.3599, 0.2681]], grad_fn=<SoftmaxBackward0>) 441\n",
            "Sentence: follow berkshire hathaway apple stock\n",
            "Predicted sentiment probabilities: tensor([[0.3161, 0.3094, 0.3745]], grad_fn=<SoftmaxBackward0>) 442\n",
            "Sentence: morrison book second consecutive quarter sale growth\n",
            "Predicted sentiment probabilities: tensor([[0.2703, 0.3631, 0.3666]], grad_fn=<SoftmaxBackward0>) 443\n",
            "Sentence: royal mail get mixed bag ofcom postal regulation report\n",
            "Predicted sentiment probabilities: tensor([[0.3073, 0.3970, 0.2956]], grad_fn=<SoftmaxBackward0>) 444\n",
            "Sentence: update 3 ex barclay director accuse illegal tip plumber\n",
            "Predicted sentiment probabilities: tensor([[0.2549, 0.4135, 0.3316]], grad_fn=<SoftmaxBackward0>) 445\n",
            "Sentence: eu regulator clear $ 100 billion plus ab inbev sabmiller deal\n",
            "Predicted sentiment probabilities: tensor([[0.3170, 0.3642, 0.3188]], grad_fn=<SoftmaxBackward0>) 446\n",
            "Sentence: retail giant kingfisher report solid start year\n",
            "Predicted sentiment probabilities: tensor([[0.3045, 0.4159, 0.2796]], grad_fn=<SoftmaxBackward0>) 447\n",
            "Sentence: berkshire disclose unit tie iran open probe\n",
            "Predicted sentiment probabilities: tensor([[0.3306, 0.3405, 0.3289]], grad_fn=<SoftmaxBackward0>) 448\n",
            "Sentence: berkshire hathaway name kara raiguel lead general unit\n",
            "Predicted sentiment probabilities: tensor([[0.3033, 0.2948, 0.4019]], grad_fn=<SoftmaxBackward0>) 449\n",
            "Sentence: european stock hover near 3 week low dialog bhp slump\n",
            "Predicted sentiment probabilities: tensor([[0.3194, 0.4161, 0.2645]], grad_fn=<SoftmaxBackward0>) 450\n",
            "Sentence: hargreave lansdown buck weak market asset rise 2.6 percent\n",
            "Predicted sentiment probabilities: tensor([[0.3261, 0.3102, 0.3637]], grad_fn=<SoftmaxBackward0>) 451\n",
            "Sentence: australia clear ab inbev $ 100 billion sabmiller buyout plan\n",
            "Predicted sentiment probabilities: tensor([[0.4008, 0.2671, 0.3321]], grad_fn=<SoftmaxBackward0>) 452\n",
            "Sentence: goodwin face scottish prosecution rbs\n",
            "Predicted sentiment probabilities: tensor([[0.3039, 0.2652, 0.4309]], grad_fn=<SoftmaxBackward0>) 453\n",
            "Sentence: royal mail turnaround prove expensive tough uk market\n",
            "Predicted sentiment probabilities: tensor([[0.3545, 0.3439, 0.3016]], grad_fn=<SoftmaxBackward0>) 454\n",
            "Sentence: whitbread buy 49 stake pure food chain\n",
            "Predicted sentiment probabilities: tensor([[0.2908, 0.3407, 0.3685]], grad_fn=<SoftmaxBackward0>) 455\n",
            "Sentence: irish say chase standard chartered rbs brexit vote near\n",
            "Predicted sentiment probabilities: tensor([[0.3200, 0.3051, 0.3749]], grad_fn=<SoftmaxBackward0>) 456\n",
            "Sentence: royal mail share price rally amid positive broker comment\n",
            "Predicted sentiment probabilities: tensor([[0.3783, 0.3180, 0.3038]], grad_fn=<SoftmaxBackward0>) 457\n",
            "Sentence: intercontinental hotel first quarter global room revenue lag estimate\n",
            "Predicted sentiment probabilities: tensor([[0.3366, 0.2681, 0.3953]], grad_fn=<SoftmaxBackward0>) 458\n",
            "Sentence: aspen buy anaesthetic astrazeneca $ 520 million\n",
            "Predicted sentiment probabilities: tensor([[0.3588, 0.2368, 0.4044]], grad_fn=<SoftmaxBackward0>) 459\n",
            "Sentence: london stock exchange Ã¢â‚¬ deutsche boerse merger threat brexit\n",
            "Predicted sentiment probabilities: tensor([[0.2947, 0.2963, 0.4090]], grad_fn=<SoftmaxBackward0>) 460\n",
            "Sentence: sainsbury cfo roger replace home retail ceo walden\n",
            "Predicted sentiment probabilities: tensor([[0.3056, 0.3863, 0.3082]], grad_fn=<SoftmaxBackward0>) 461\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2725, 0.3465, 0.3810]], grad_fn=<SoftmaxBackward0>) 462\n",
            "Sentence: bp join force det norske norway\n",
            "Predicted sentiment probabilities: tensor([[0.3355, 0.3810, 0.2835]], grad_fn=<SoftmaxBackward0>) 463\n",
            "Sentence: brief legal general retirement business book 4 billion stg h1 sale\n",
            "Predicted sentiment probabilities: tensor([[0.2822, 0.3711, 0.3467]], grad_fn=<SoftmaxBackward0>) 464\n",
            "Sentence: johnson matthey revs clean air drive\n",
            "Predicted sentiment probabilities: tensor([[0.2498, 0.3705, 0.3797]], grad_fn=<SoftmaxBackward0>) 465\n",
            "Sentence: goldman sachs barclay hsbc downplay brexit threat\n",
            "Predicted sentiment probabilities: tensor([[0.2793, 0.3488, 0.3719]], grad_fn=<SoftmaxBackward0>) 466\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3383, 0.3558, 0.3059]], grad_fn=<SoftmaxBackward0>) 467\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2576, 0.2762, 0.4662]], grad_fn=<SoftmaxBackward0>) 468\n",
            "Sentence: asahi snap sabmiller beer ahead ab inbev sale\n",
            "Predicted sentiment probabilities: tensor([[0.2632, 0.3405, 0.3963]], grad_fn=<SoftmaxBackward0>) 469\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3458, 0.3167, 0.3375]], grad_fn=<SoftmaxBackward0>) 470\n",
            "Sentence: lse deutsche bÃ£Â¶rse dealmaker wrong ignore brexit risk\n",
            "Predicted sentiment probabilities: tensor([[0.3659, 0.3559, 0.2782]], grad_fn=<SoftmaxBackward0>) 471\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.2845, 0.3596, 0.3559]], grad_fn=<SoftmaxBackward0>) 472\n",
            "Sentence: tesco sale recover focus return core business\n",
            "Predicted sentiment probabilities: tensor([[0.3104, 0.3598, 0.3299]], grad_fn=<SoftmaxBackward0>) 473\n",
            "Sentence: johnson matthey profit fall dividend rise\n",
            "Predicted sentiment probabilities: tensor([[0.4150, 0.3125, 0.2725]], grad_fn=<SoftmaxBackward0>) 474\n",
            "Sentence: arm holdings plc domino pizza group plc asos plc 3 growth stock\n",
            "Predicted sentiment probabilities: tensor([[0.3374, 0.3365, 0.3261]], grad_fn=<SoftmaxBackward0>) 475\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3447, 0.3288, 0.3266]], grad_fn=<SoftmaxBackward0>) 476\n",
            "Sentence: priceline stock jump new high year barclay upgrade\n",
            "Predicted sentiment probabilities: tensor([[0.3339, 0.3043, 0.3618]], grad_fn=<SoftmaxBackward0>) 477\n",
            "Sentence: tesco set sell kipa giraffe business sky news\n",
            "Predicted sentiment probabilities: tensor([[0.3337, 0.3307, 0.3356]], grad_fn=<SoftmaxBackward0>) 478\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3289, 0.3846, 0.2865]], grad_fn=<SoftmaxBackward0>) 479\n",
            "Sentence: coca cola company coca cola femsa acquire ade soy base beverage business unilever\n",
            "Predicted sentiment probabilities: tensor([[0.3483, 0.3449, 0.3069]], grad_fn=<SoftmaxBackward0>) 480\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3136, 0.3563, 0.3301]], grad_fn=<SoftmaxBackward0>) 481\n",
            "Sentence: hsbc say unit book $ 585 million charge settlement\n",
            "Predicted sentiment probabilities: tensor([[0.3657, 0.3002, 0.3341]], grad_fn=<SoftmaxBackward0>) 482\n",
            "Sentence: hammerson jv partner secure ownership ireland dundrum quick fact\n",
            "Predicted sentiment probabilities: tensor([[0.3541, 0.3135, 0.3325]], grad_fn=<SoftmaxBackward0>) 483\n",
            "Sentence: aviva promise high dividend boost flagging share price\n",
            "Predicted sentiment probabilities: tensor([[0.3406, 0.3094, 0.3500]], grad_fn=<SoftmaxBackward0>) 484\n",
            "Sentence: companiesfresnillo share jump 8 silver price break $ 21\n",
            "Predicted sentiment probabilities: tensor([[0.2864, 0.3684, 0.3452]], grad_fn=<SoftmaxBackward0>) 485\n",
            "Sentence: buy associate british foods plc great portland estates plc dunelm group plc follow today news\n",
            "Predicted sentiment probabilities: tensor([[0.3151, 0.3413, 0.3436]], grad_fn=<SoftmaxBackward0>) 486\n",
            "Sentence: nan\n",
            "Predicted sentiment probabilities: tensor([[0.3559, 0.2811, 0.3630]], grad_fn=<SoftmaxBackward0>) 487\n",
            "Sentence: berkshire seek boost wells fargo stake 10 percent\n",
            "Predicted sentiment probabilities: tensor([[0.3873, 0.3170, 0.2957]], grad_fn=<SoftmaxBackward0>) 488\n",
            "Sentence: tesco share price tumble negative broker note\n",
            "Predicted sentiment probabilities: tensor([[0.3242, 0.2718, 0.4041]], grad_fn=<SoftmaxBackward0>) 489\n",
            "Sentence: london stock exchange shareholder approve merger deutsche bÃ£Â¶rse\n",
            "Predicted sentiment probabilities: tensor([[0.4179, 0.2711, 0.3110]], grad_fn=<SoftmaxBackward0>) 490\n",
            "Sentence: update 1 berkshire applie boost wells fargo stake 10 pct\n",
            "Predicted sentiment probabilities: tensor([[0.3458, 0.2916, 0.3626]], grad_fn=<SoftmaxBackward0>) 491\n",
            "Sentence: berkshire apply boost wells fargo stake 10 percent\n",
            "Predicted sentiment probabilities: tensor([[0.3381, 0.2844, 0.3775]], grad_fn=<SoftmaxBackward0>) 492\n",
            "Sentence: aviva m&g suspend property fund investor panic\n",
            "Predicted sentiment probabilities: tensor([[0.3973, 0.3023, 0.3005]], grad_fn=<SoftmaxBackward0>) 493\n",
            "Sentence: uk housing market steady brexit dip persimmon say\n",
            "Predicted sentiment probabilities: tensor([[0.2981, 0.3955, 0.3064]], grad_fn=<SoftmaxBackward0>) 494\n",
            "Sentence: brief aviva aim increase dividend pay ratio 50 pct 2017\n",
            "Predicted sentiment probabilities: tensor([[0.4077, 0.2926, 0.2997]], grad_fn=<SoftmaxBackward0>) 495\n",
            "Sentence: builder persimmon hail 6 rise house sale\n",
            "Predicted sentiment probabilities: tensor([[0.2782, 0.3600, 0.3618]], grad_fn=<SoftmaxBackward0>) 496\n",
            "Sentence: easyjet attract passenger june lag ryanair\n",
            "Predicted sentiment probabilities: tensor([[0.4099, 0.3123, 0.2778]], grad_fn=<SoftmaxBackward0>) 497\n"
          ]
        }
      ],
      "source": [
        "attention_layer = MultiHeadAttention(num_heads=8, model_dim=768)\n",
        "\n",
        "num_classes = 3\n",
        "predicted_sentiment_probability = []\n",
        "i = 0\n",
        "for _, row in df1.iterrows():\n",
        "    sentence = row['preprocessed_sentence']\n",
        "    trend = row['trend']\n",
        "    embedded_aspect = row['embedded_aspect']\n",
        "\n",
        "    aspect = embedded_aspect.split()[-1]\n",
        "    trend_word = embedded_aspect.split()[0]\n",
        "\n",
        "    inputs_sentence = tokenizer(sentence, return_tensors='pt')\n",
        "    outputs_sentence = model(**inputs_sentence)\n",
        "\n",
        "    inputs_trend_word = tokenizer(trend_word, return_tensors='pt')\n",
        "    inputs_aspect = tokenizer(aspect, return_tensors='pt')\n",
        "\n",
        "    sentence_embedding = outputs_sentence.last_hidden_state\n",
        "    trend_word_embedding = model(**inputs_trend_word).last_hidden_state.mean(dim=1)\n",
        "    aspect_embedding = model(**inputs_aspect).last_hidden_state.mean(dim=1)\n",
        "\n",
        "    seq_len = sentence_embedding.shape[1]\n",
        "\n",
        "    trend_word_embedding_expanded = trend_word_embedding.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "    aspect_embedding_expanded = aspect_embedding.unsqueeze(1).expand(-1, seq_len, -1)\n",
        "\n",
        "    combined_embedding = sentence_embedding + trend_word_embedding_expanded + aspect_embedding_expanded\n",
        "\n",
        "    attended_output = attention_layer(combined_embedding)\n",
        "\n",
        "    attended_output_mean = attended_output.mean(dim=1)\n",
        "\n",
        "    output_size = attended_output_mean.shape[-1]\n",
        "    sentiment_score = torch.nn.Linear(output_size, num_classes)\n",
        "\n",
        "    predicted_sentiment = sentiment_score(attended_output_mean)\n",
        "\n",
        "    predicted_sentiment_probs = F.softmax(predicted_sentiment, dim=-1)\n",
        "\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(\"Predicted sentiment probabilities:\", predicted_sentiment_probs,i)\n",
        "    i=i+1\n",
        "    predicted_sentiment_probability.append(predicted_sentiment_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uUy0hhhG823"
      },
      "outputs": [],
      "source": [
        "predicted_sentiment_probability = [x.detach().cpu().numpy() for x in predicted_sentiment_probability]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gy0PdlllH941"
      },
      "outputs": [],
      "source": [
        "predicted_sentiment_probability = np.array(predicted_sentiment_probability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFZtEIdGIUCY"
      },
      "outputs": [],
      "source": [
        "predicted_sentiment_probability = predicted_sentiment_probability.reshape(predicted_sentiment_probability.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxfmlL5BIIFU",
        "outputId": "975a2e99-3e72-414c-f647-2d63d8f6450a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.27385473, 0.35181287, 0.3743324 ],\n",
              "       [0.31220025, 0.3440081 , 0.34379163],\n",
              "       [0.3310783 , 0.34502226, 0.32389942],\n",
              "       ...,\n",
              "       [0.40770197, 0.29260528, 0.29969278],\n",
              "       [0.27824777, 0.35998258, 0.36176968],\n",
              "       [0.40991488, 0.31226966, 0.27781552]], dtype=float32)"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_sentiment_probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCQry5-kGjmw",
        "outputId": "c67b5307-86cb-43c3-8189-897eff9a1652"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(498, 3)"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_sentiment_probability.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LpHEKPMIe7e"
      },
      "outputs": [],
      "source": [
        "df['predicted_sentiment_probability_after_attention_mechanism'] = list(predicted_sentiment_probability)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2CNx1DWfMl95",
        "outputId": "78f999d4-e718-4bdd-eb90-79d60913b2b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 498,\n  \"fields\": [\n    {\n      \"column\": \"No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 512.897703134483,\n        \"min\": 1.0,\n        \"max\": 1779.0,\n        \"num_unique_values\": 436,\n        \"samples\": [\n          1581.0,\n          257.0,\n          1052.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 436,\n        \"samples\": [\n          \"Berkshire discloses unit's ties to Iran, opens probe\",\n          \"How Kraft-Heinz Merger Came Together in Speedy 10 Weeks\",\n          \"US dollar wipes out sales gains for SABMiller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__snippets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 458,\n        \"samples\": [\n          \"['chases Acerta to secure next cancer drug winner']\",\n          \"['Smartphone Market Regains Strength']\",\n          \"['Britain's FTSE outperforms Europe, Royal Mail and Tesco rise']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 226,\n        \"samples\": [\n          \"Royal Dutch Shell\",\n          \"JP Morgan Chase\",\n          \"Zurich Insurance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_sentiment_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3757132285813035,\n        \"min\": -0.938,\n        \"max\": 0.975,\n        \"num_unique_values\": 407,\n        \"samples\": [\n          0.315,\n          0.357,\n          0.593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_aspects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 82,\n        \"samples\": [\n          \"['Corporate/Appointment/Staff Hiring']\",\n          \"['Corporate/Appointment']\",\n          \"['Corporate/Dividend Policy/Dividend/Dividend going up']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 436,\n        \"samples\": [\n          \"berkshire disclose unit tie iran open probe\",\n          \"kraft cadbury britvic total recall pull product affect profit\",\n          \"dollar wipe sale gain sabmiller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"numerical_info\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoded_values\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"tensor([[0., 0., 0.]])\",\n          \"tensor([[-3.5877,  6.0125, -2.1140]], grad_fn=<CatBackward0>)\",\n          \"tensor([[-0.6577,  1.0891, -0.4603]], grad_fn=<CatBackward0>)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores_for_numerical_encoded_values\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trend\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"decrease\",\n          \"increase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedded_aspect\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"Det Norske\",\n          \"Rio Tinto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_sentiment_probability_after_attention_mechanism\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dac728fe-0cdd-412c-8e01-08d1d295f754\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>sentence</th>\n",
              "      <th>info__snippets</th>\n",
              "      <th>info__target</th>\n",
              "      <th>info_sentiment_score</th>\n",
              "      <th>info_aspects</th>\n",
              "      <th>preprocessed_sentence</th>\n",
              "      <th>numerical_info</th>\n",
              "      <th>encoded_values</th>\n",
              "      <th>sentiment_scores_for_numerical_encoded_values</th>\n",
              "      <th>trend</th>\n",
              "      <th>embedded_aspect</th>\n",
              "      <th>predicted_sentiment_probability_after_attention_mechanism</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
              "      <td>['set to step down']</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "      <td>royal mail chairman donald brydon set step</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>[0.27385473, 0.35181287, 0.3743324]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
              "      <td>['Facing Tough Competition']</td>\n",
              "      <td>AstraZeneca</td>\n",
              "      <td>-0.240</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>stake high astrazeneca heart drug face tough c...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>high AstraZeneca</td>\n",
              "      <td>[0.31220025, 0.3440081, 0.34379163]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>UPDATE 1-Dairy Crest loses a third of Morrison...</td>\n",
              "      <td>['Crest loses a third of Morrisons milk contra...</td>\n",
              "      <td>Morrisons</td>\n",
              "      <td>-0.161</td>\n",
              "      <td>['Corporate/Sales/Failed Contract Discussion']</td>\n",
              "      <td>update 1 dairy crest lose third morrison milk ...</td>\n",
              "      <td>[{'value': '1', 'type': 'cardinal', 'aspect': ...</td>\n",
              "      <td>[[tensor(0.0584, grad_fn=&lt;UnbindBackward0&gt;), t...</td>\n",
              "      <td>[[0.05843232, -0.085836776, -0.08687651, 0.092...</td>\n",
              "      <td>decrease</td>\n",
              "      <td>contract Morrisons</td>\n",
              "      <td>[0.3310783, 0.34502226, 0.32389942]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.0</td>\n",
              "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
              "      <td>['hires Aviva's David Hillier for multi-asset ...</td>\n",
              "      <td>Insight</td>\n",
              "      <td>0.137</td>\n",
              "      <td>['Corporate/Appointment/Executive Appointment']</td>\n",
              "      <td>insight hire aviva david hillier multi asset team</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Insight</td>\n",
              "      <td>[0.32109642, 0.31461018, 0.36429343]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.0</td>\n",
              "      <td>Primark racks up a happy Christmas after stron...</td>\n",
              "      <td>['after strong sales']</td>\n",
              "      <td>Primark</td>\n",
              "      <td>0.704</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>primark rack happy christmas strong sale</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>strong Primark</td>\n",
              "      <td>[0.24587269, 0.42583296, 0.32829437]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>1750.0</td>\n",
              "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
              "      <td>['M&amp;G suspend property funds as investors panic']</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>-0.807</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>aviva m&amp;g suspend property fund investor panic</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>[0.39725062, 0.3022558, 0.30049357]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>1754.0</td>\n",
              "      <td>UK housing market steadies after Brexit dip, P...</td>\n",
              "      <td>['housing market']</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>0.339</td>\n",
              "      <td>['Market/Market']</td>\n",
              "      <td>uk housing market steady brexit dip persimmon say</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>[0.29810035, 0.39548886, 0.30641082]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1755.0</td>\n",
              "      <td>BRIEF-Aviva aims to increase dividend pay-out ...</td>\n",
              "      <td>['increase dividend pay-out']</td>\n",
              "      <td>Aviva</td>\n",
              "      <td>0.439</td>\n",
              "      <td>['Corporate/Dividend Policy']</td>\n",
              "      <td>brief aviva aim increase dividend pay ratio 50...</td>\n",
              "      <td>[{'value': '50', 'type': 'cardinal', 'aspect':...</td>\n",
              "      <td>[[tensor(-1.7565, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n",
              "      <td>[[-1.7564672, 2.9353569, -1.0804299, -74.38759...</td>\n",
              "      <td>increase</td>\n",
              "      <td>increase Aviva</td>\n",
              "      <td>[0.40770197, 0.29260528, 0.29969278]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1764.0</td>\n",
              "      <td>Builder Persimmon hails 6% rise in house sales</td>\n",
              "      <td>['6% rise in house sales']</td>\n",
              "      <td>Persimmon</td>\n",
              "      <td>0.435</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>builder persimmon hail 6 rise house sale</td>\n",
              "      <td>[{'value': '6', 'type': 'cardinal', 'aspect': ...</td>\n",
              "      <td>[[tensor(-0.1363, grad_fn=&lt;UnbindBackward0&gt;), ...</td>\n",
              "      <td>[[-0.13633153, 0.22108659, -0.18499303]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>rise Persimmon</td>\n",
              "      <td>[0.27824777, 0.35998258, 0.36176968]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1779.0</td>\n",
              "      <td>EasyJet attracts more passengers in June but s...</td>\n",
              "      <td>['attracts more passengers']</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>0.259</td>\n",
              "      <td>['Corporate/Sales/Sales']</td>\n",
              "      <td>easyjet attract passenger june lag ryanair</td>\n",
              "      <td>[]</td>\n",
              "      <td>[[tensor(0.), tensor(0.), tensor(0.)]]</td>\n",
              "      <td>[[0.0, 0.0, 0.0]]</td>\n",
              "      <td>None</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>[0.40991488, 0.31226966, 0.27781552]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dac728fe-0cdd-412c-8e01-08d1d295f754')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dac728fe-0cdd-412c-8e01-08d1d295f754 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dac728fe-0cdd-412c-8e01-08d1d295f754');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-abb5c28f-0906-4267-bc26-957676f47558\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-abb5c28f-0906-4267-bc26-957676f47558')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-abb5c28f-0906-4267-bc26-957676f47558 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c0c88fea-1bd6-436d-a0f5-407d22d24b90\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c0c88fea-1bd6-436d-a0f5-407d22d24b90 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         No                                           sentence  \\\n",
              "0       1.0  Royal Mail chairman Donald Brydon set to step ...   \n",
              "1       7.0  Stakes High for AstraZeneca Heart Drug Facing ...   \n",
              "2       8.0  UPDATE 1-Dairy Crest loses a third of Morrison...   \n",
              "3      22.0  Insight hires Aviva's David Hillier for multi-...   \n",
              "4      30.0  Primark racks up a happy Christmas after stron...   \n",
              "..      ...                                                ...   \n",
              "493  1750.0  Aviva, M&G suspend property funds as investors...   \n",
              "494  1754.0  UK housing market steadies after Brexit dip, P...   \n",
              "495  1755.0  BRIEF-Aviva aims to increase dividend pay-out ...   \n",
              "496  1764.0     Builder Persimmon hails 6% rise in house sales   \n",
              "497  1779.0  EasyJet attracts more passengers in June but s...   \n",
              "\n",
              "                                        info__snippets info__target  \\\n",
              "0                                 ['set to step down']   Royal Mail   \n",
              "1                         ['Facing Tough Competition']  AstraZeneca   \n",
              "2    ['Crest loses a third of Morrisons milk contra...    Morrisons   \n",
              "3    ['hires Aviva's David Hillier for multi-asset ...      Insight   \n",
              "4                               ['after strong sales']      Primark   \n",
              "..                                                 ...          ...   \n",
              "493  ['M&G suspend property funds as investors panic']          M&G   \n",
              "494                                 ['housing market']    Perssimon   \n",
              "495                      ['increase dividend pay-out']        Aviva   \n",
              "496                         ['6% rise in house sales']    Persimmon   \n",
              "497                       ['attracts more passengers']      Ryanair   \n",
              "\n",
              "     info_sentiment_score                                     info_aspects  \\\n",
              "0                  -0.374                        ['Corporate/Appointment']   \n",
              "1                  -0.240                              ['Corporate/Risks']   \n",
              "2                  -0.161   ['Corporate/Sales/Failed Contract Discussion']   \n",
              "3                   0.137  ['Corporate/Appointment/Executive Appointment']   \n",
              "4                   0.704                              ['Corporate/Sales']   \n",
              "..                    ...                                              ...   \n",
              "493                -0.807                              ['Corporate/Risks']   \n",
              "494                 0.339                                ['Market/Market']   \n",
              "495                 0.439                    ['Corporate/Dividend Policy']   \n",
              "496                 0.435                              ['Corporate/Sales']   \n",
              "497                 0.259                        ['Corporate/Sales/Sales']   \n",
              "\n",
              "                                 preprocessed_sentence  \\\n",
              "0           royal mail chairman donald brydon set step   \n",
              "1    stake high astrazeneca heart drug face tough c...   \n",
              "2    update 1 dairy crest lose third morrison milk ...   \n",
              "3    insight hire aviva david hillier multi asset team   \n",
              "4             primark rack happy christmas strong sale   \n",
              "..                                                 ...   \n",
              "493     aviva m&g suspend property fund investor panic   \n",
              "494  uk housing market steady brexit dip persimmon say   \n",
              "495  brief aviva aim increase dividend pay ratio 50...   \n",
              "496           builder persimmon hail 6 rise house sale   \n",
              "497         easyjet attract passenger june lag ryanair   \n",
              "\n",
              "                                        numerical_info  \\\n",
              "0                                                   []   \n",
              "1                                                   []   \n",
              "2    [{'value': '1', 'type': 'cardinal', 'aspect': ...   \n",
              "3                                                   []   \n",
              "4                                                   []   \n",
              "..                                                 ...   \n",
              "493                                                 []   \n",
              "494                                                 []   \n",
              "495  [{'value': '50', 'type': 'cardinal', 'aspect':...   \n",
              "496  [{'value': '6', 'type': 'cardinal', 'aspect': ...   \n",
              "497                                                 []   \n",
              "\n",
              "                                        encoded_values  \\\n",
              "0               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "1               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "2    [[tensor(0.0584, grad_fn=<UnbindBackward0>), t...   \n",
              "3               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "4               [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "..                                                 ...   \n",
              "493             [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "494             [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "495  [[tensor(-1.7565, grad_fn=<UnbindBackward0>), ...   \n",
              "496  [[tensor(-0.1363, grad_fn=<UnbindBackward0>), ...   \n",
              "497             [[tensor(0.), tensor(0.), tensor(0.)]]   \n",
              "\n",
              "         sentiment_scores_for_numerical_encoded_values     trend  \\\n",
              "0                                    [[0.0, 0.0, 0.0]]      None   \n",
              "1                                    [[0.0, 0.0, 0.0]]  increase   \n",
              "2    [[0.05843232, -0.085836776, -0.08687651, 0.092...  decrease   \n",
              "3                                    [[0.0, 0.0, 0.0]]      None   \n",
              "4                                    [[0.0, 0.0, 0.0]]  increase   \n",
              "..                                                 ...       ...   \n",
              "493                                  [[0.0, 0.0, 0.0]]      None   \n",
              "494                                  [[0.0, 0.0, 0.0]]      None   \n",
              "495  [[-1.7564672, 2.9353569, -1.0804299, -74.38759...  increase   \n",
              "496           [[-0.13633153, 0.22108659, -0.18499303]]  increase   \n",
              "497                                  [[0.0, 0.0, 0.0]]      None   \n",
              "\n",
              "        embedded_aspect  \\\n",
              "0            Royal Mail   \n",
              "1      high AstraZeneca   \n",
              "2    contract Morrisons   \n",
              "3               Insight   \n",
              "4        strong Primark   \n",
              "..                  ...   \n",
              "493                 M&G   \n",
              "494           Perssimon   \n",
              "495      increase Aviva   \n",
              "496      rise Persimmon   \n",
              "497             Ryanair   \n",
              "\n",
              "    predicted_sentiment_probability_after_attention_mechanism  \n",
              "0                  [0.27385473, 0.35181287, 0.3743324]         \n",
              "1                  [0.31220025, 0.3440081, 0.34379163]         \n",
              "2                  [0.3310783, 0.34502226, 0.32389942]         \n",
              "3                 [0.32109642, 0.31461018, 0.36429343]         \n",
              "4                 [0.24587269, 0.42583296, 0.32829437]         \n",
              "..                                                 ...         \n",
              "493                [0.39725062, 0.3022558, 0.30049357]         \n",
              "494               [0.29810035, 0.39548886, 0.30641082]         \n",
              "495               [0.40770197, 0.29260528, 0.29969278]         \n",
              "496               [0.27824777, 0.35998258, 0.36176968]         \n",
              "497               [0.40991488, 0.31226966, 0.27781552]         \n",
              "\n",
              "[498 rows x 13 columns]"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVNb_FSeXPCS"
      },
      "source": [
        "## Data Saved Into .CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YWiCOMajFS6"
      },
      "outputs": [],
      "source": [
        "df.to_csv('sentiment_analysis_final_result.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjxs3dqRUI75"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/sentiment_analysis_final_result.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KggZFCNQGv_F",
        "outputId": "6d085321-2011-4d67-a26a-71e1772c025c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 498,\n  \"fields\": [\n    {\n      \"column\": \"No\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 512.897703134483,\n        \"min\": 1.0,\n        \"max\": 1779.0,\n        \"num_unique_values\": 436,\n        \"samples\": [\n          1581.0,\n          257.0,\n          1052.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 436,\n        \"samples\": [\n          \"Berkshire discloses unit's ties to Iran, opens probe\",\n          \"How Kraft-Heinz Merger Came Together in Speedy 10 Weeks\",\n          \"US dollar wipes out sales gains for SABMiller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__snippets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 458,\n        \"samples\": [\n          \"['chases Acerta to secure next cancer drug winner']\",\n          \"['Smartphone Market Regains Strength']\",\n          \"['Britain's FTSE outperforms Europe, Royal Mail and Tesco rise']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info__target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 226,\n        \"samples\": [\n          \"Royal Dutch Shell\",\n          \"JP Morgan Chase\",\n          \"Zurich Insurance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_sentiment_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3757132285813035,\n        \"min\": -0.938,\n        \"max\": 0.975,\n        \"num_unique_values\": 407,\n        \"samples\": [\n          0.315,\n          0.357,\n          0.593\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"info_aspects\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 82,\n        \"samples\": [\n          \"['Corporate/Appointment/Staff Hiring']\",\n          \"['Corporate/Appointment']\",\n          \"['Corporate/Dividend Policy/Dividend/Dividend going up']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 435,\n        \"samples\": [\n          \"valeant ceo pledge heed critic ` painful experience\",\n          \"kraft heinz merger come speedy 10 week\",\n          \"bg group happy shell $ 70 billion offer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"numerical_info\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 119,\n        \"samples\": [\n          \"[{'value': '100', 'type': 'cardinal', 'aspect': 'fall', 'dependency_type': 'nummod'}]\",\n          \"[{'value': '10', 'type': 'cardinal', 'aspect': 'month', 'dependency_type': 'nummod'}]\",\n          \"[{'value': '4', 'type': 'cardinal', 'aspect': 'dividend', 'dependency_type': 'nummod'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"encoded_values\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"tensor([[-1.0972e+00,  1.8276e+00, -7.0836e-01, -3.6934e+07,  6.1554e+07,\\n         -2.0765e+07, -1.3633e-01,  2.2109e-01, -1.8499e-01]],\\n       grad_fn=<CatBackward0>)\",\n          \"tensor([[-6.1134e-02,  9.6568e-02, -1.4681e-01, -3.6934e+07,  6.1554e+07,\\n         -2.0765e+07]], grad_fn=<CatBackward0>)\",\n          \"tensor([[0., 0., 0.]])\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_scores_for_numerical_encoded_values\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"[[-1.0972358e+00  1.8275831e+00 -7.0835650e-01 -3.6933544e+07\\n   6.1553836e+07 -2.0764644e+07 -1.3633153e-01  2.2108659e-01\\n  -1.8499303e-01]]\",\n          \"[[-6.1134160e-02  9.6568055e-02 -1.4681245e-01 -3.6933544e+07\\n   6.1553836e+07 -2.0764644e+07]]\",\n          \"[[0. 0. 0.]]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trend\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"decrease\",\n          \"increase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"embedded_aspect\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 295,\n        \"samples\": [\n          \"Det Norske\",\n          \"Rio Tinto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_sentiment_probability_after_attention_mechanism\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 498,\n        \"samples\": [\n          \"[0.35593155 0.28107637 0.36299208]\",\n          \"[0.25180364 0.3244845  0.42371184]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f2fdf60d-ec6b-4701-b520-8eebcf704b05\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>No</th>\n",
              "      <th>sentence</th>\n",
              "      <th>info__snippets</th>\n",
              "      <th>info__target</th>\n",
              "      <th>info_sentiment_score</th>\n",
              "      <th>info_aspects</th>\n",
              "      <th>preprocessed_sentence</th>\n",
              "      <th>numerical_info</th>\n",
              "      <th>encoded_values</th>\n",
              "      <th>sentiment_scores_for_numerical_encoded_values</th>\n",
              "      <th>trend</th>\n",
              "      <th>embedded_aspect</th>\n",
              "      <th>predicted_sentiment_probability_after_attention_mechanism</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Royal Mail chairman Donald Brydon set to step ...</td>\n",
              "      <td>['set to step down']</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>-0.374</td>\n",
              "      <td>['Corporate/Appointment']</td>\n",
              "      <td>royal mail chairman donald brydon set step</td>\n",
              "      <td>[]</td>\n",
              "      <td>tensor([[0., 0., 0.]])</td>\n",
              "      <td>[[0. 0. 0.]]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Royal Mail</td>\n",
              "      <td>[0.27385473 0.35181287 0.3743324 ]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>Stakes High for AstraZeneca Heart Drug Facing ...</td>\n",
              "      <td>['Facing Tough Competition']</td>\n",
              "      <td>AstraZeneca</td>\n",
              "      <td>-0.240</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>stake high astrazeneca heart drug face tough c...</td>\n",
              "      <td>[]</td>\n",
              "      <td>tensor([[0., 0., 0.]])</td>\n",
              "      <td>[[0. 0. 0.]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>high AstraZeneca</td>\n",
              "      <td>[0.31220025 0.3440081  0.34379163]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.0</td>\n",
              "      <td>UPDATE 1-Dairy Crest loses a third of Morrison...</td>\n",
              "      <td>['Crest loses a third of Morrisons milk contra...</td>\n",
              "      <td>Morrisons</td>\n",
              "      <td>-0.161</td>\n",
              "      <td>['Corporate/Sales/Failed Contract Discussion']</td>\n",
              "      <td>update 1 dairy crest lose third morrison milk ...</td>\n",
              "      <td>[{'value': '1', 'type': 'cardinal', 'aspect': ...</td>\n",
              "      <td>tensor([[ 0.0584, -0.0858, -0.0869,  0.0923, -...</td>\n",
              "      <td>[[ 0.05843232 -0.08583678 -0.08687651  0.09229...</td>\n",
              "      <td>decrease</td>\n",
              "      <td>contract Morrisons</td>\n",
              "      <td>[0.3310783  0.34502226 0.32389942]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22.0</td>\n",
              "      <td>Insight hires Aviva's David Hillier for multi-...</td>\n",
              "      <td>['hires Aviva's David Hillier for multi-asset ...</td>\n",
              "      <td>Insight</td>\n",
              "      <td>0.137</td>\n",
              "      <td>['Corporate/Appointment/Executive Appointment']</td>\n",
              "      <td>insight hire aviva david hillier multi asset team</td>\n",
              "      <td>[]</td>\n",
              "      <td>tensor([[0., 0., 0.]])</td>\n",
              "      <td>[[0. 0. 0.]]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Insight</td>\n",
              "      <td>[0.32109642 0.31461018 0.36429343]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30.0</td>\n",
              "      <td>Primark racks up a happy Christmas after stron...</td>\n",
              "      <td>['after strong sales']</td>\n",
              "      <td>Primark</td>\n",
              "      <td>0.704</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>primark rack happy christmas strong sale</td>\n",
              "      <td>[]</td>\n",
              "      <td>tensor([[0., 0., 0.]])</td>\n",
              "      <td>[[0. 0. 0.]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>strong Primark</td>\n",
              "      <td>[0.24587269 0.42583296 0.32829437]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>1750.0</td>\n",
              "      <td>Aviva, M&amp;G suspend property funds as investors...</td>\n",
              "      <td>['M&amp;G suspend property funds as investors panic']</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>-0.807</td>\n",
              "      <td>['Corporate/Risks']</td>\n",
              "      <td>aviva m&amp;g suspend property fund investor panic</td>\n",
              "      <td>[]</td>\n",
              "      <td>tensor([[0., 0., 0.]])</td>\n",
              "      <td>[[0. 0. 0.]]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M&amp;G</td>\n",
              "      <td>[0.39725062 0.3022558  0.30049357]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>1754.0</td>\n",
              "      <td>UK housing market steadies after Brexit dip, P...</td>\n",
              "      <td>['housing market']</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>0.339</td>\n",
              "      <td>['Market/Market']</td>\n",
              "      <td>uk housing market steady brexit dip persimmon say</td>\n",
              "      <td>[]</td>\n",
              "      <td>tensor([[0., 0., 0.]])</td>\n",
              "      <td>[[0. 0. 0.]]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Perssimon</td>\n",
              "      <td>[0.29810035 0.39548886 0.30641082]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1755.0</td>\n",
              "      <td>BRIEF-Aviva aims to increase dividend pay-out ...</td>\n",
              "      <td>['increase dividend pay-out']</td>\n",
              "      <td>Aviva</td>\n",
              "      <td>0.439</td>\n",
              "      <td>['Corporate/Dividend Policy']</td>\n",
              "      <td>brief aviva aim increase dividend pay ratio 50...</td>\n",
              "      <td>[{'value': '50', 'type': 'cardinal', 'aspect':...</td>\n",
              "      <td>tensor([[ -1.7565,   2.9354,  -1.0804, -74.387...</td>\n",
              "      <td>[[ -1.7564672   2.9353569  -1.0804299 -74.3875...</td>\n",
              "      <td>increase</td>\n",
              "      <td>increase Aviva</td>\n",
              "      <td>[0.40770197 0.29260528 0.29969278]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1764.0</td>\n",
              "      <td>Builder Persimmon hails 6% rise in house sales</td>\n",
              "      <td>['6% rise in house sales']</td>\n",
              "      <td>Persimmon</td>\n",
              "      <td>0.435</td>\n",
              "      <td>['Corporate/Sales']</td>\n",
              "      <td>builder persimmon hail 6 rise house sale</td>\n",
              "      <td>[{'value': '6', 'type': 'cardinal', 'aspect': ...</td>\n",
              "      <td>tensor([[-0.1363,  0.2211, -0.1850]], grad_fn=...</td>\n",
              "      <td>[[-0.13633153  0.22108659 -0.18499303]]</td>\n",
              "      <td>increase</td>\n",
              "      <td>rise Persimmon</td>\n",
              "      <td>[0.27824777 0.35998258 0.36176968]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1779.0</td>\n",
              "      <td>EasyJet attracts more passengers in June but s...</td>\n",
              "      <td>['attracts more passengers']</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>0.259</td>\n",
              "      <td>['Corporate/Sales/Sales']</td>\n",
              "      <td>easyjet attract passenger june lag ryanair</td>\n",
              "      <td>[]</td>\n",
              "      <td>tensor([[0., 0., 0.]])</td>\n",
              "      <td>[[0. 0. 0.]]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ryanair</td>\n",
              "      <td>[0.40991488 0.31226966 0.27781552]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows Ã— 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2fdf60d-ec6b-4701-b520-8eebcf704b05')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2fdf60d-ec6b-4701-b520-8eebcf704b05 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2fdf60d-ec6b-4701-b520-8eebcf704b05');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-25a82378-e79e-44a1-969b-9cd11c4f2cda\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-25a82378-e79e-44a1-969b-9cd11c4f2cda')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-25a82378-e79e-44a1-969b-9cd11c4f2cda button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4841d61b-92aa-4a49-813c-b26641857b89\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4841d61b-92aa-4a49-813c-b26641857b89 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "         No                                           sentence  \\\n",
              "0       1.0  Royal Mail chairman Donald Brydon set to step ...   \n",
              "1       7.0  Stakes High for AstraZeneca Heart Drug Facing ...   \n",
              "2       8.0  UPDATE 1-Dairy Crest loses a third of Morrison...   \n",
              "3      22.0  Insight hires Aviva's David Hillier for multi-...   \n",
              "4      30.0  Primark racks up a happy Christmas after stron...   \n",
              "..      ...                                                ...   \n",
              "493  1750.0  Aviva, M&G suspend property funds as investors...   \n",
              "494  1754.0  UK housing market steadies after Brexit dip, P...   \n",
              "495  1755.0  BRIEF-Aviva aims to increase dividend pay-out ...   \n",
              "496  1764.0     Builder Persimmon hails 6% rise in house sales   \n",
              "497  1779.0  EasyJet attracts more passengers in June but s...   \n",
              "\n",
              "                                        info__snippets info__target  \\\n",
              "0                                 ['set to step down']   Royal Mail   \n",
              "1                         ['Facing Tough Competition']  AstraZeneca   \n",
              "2    ['Crest loses a third of Morrisons milk contra...    Morrisons   \n",
              "3    ['hires Aviva's David Hillier for multi-asset ...      Insight   \n",
              "4                               ['after strong sales']      Primark   \n",
              "..                                                 ...          ...   \n",
              "493  ['M&G suspend property funds as investors panic']          M&G   \n",
              "494                                 ['housing market']    Perssimon   \n",
              "495                      ['increase dividend pay-out']        Aviva   \n",
              "496                         ['6% rise in house sales']    Persimmon   \n",
              "497                       ['attracts more passengers']      Ryanair   \n",
              "\n",
              "     info_sentiment_score                                     info_aspects  \\\n",
              "0                  -0.374                        ['Corporate/Appointment']   \n",
              "1                  -0.240                              ['Corporate/Risks']   \n",
              "2                  -0.161   ['Corporate/Sales/Failed Contract Discussion']   \n",
              "3                   0.137  ['Corporate/Appointment/Executive Appointment']   \n",
              "4                   0.704                              ['Corporate/Sales']   \n",
              "..                    ...                                              ...   \n",
              "493                -0.807                              ['Corporate/Risks']   \n",
              "494                 0.339                                ['Market/Market']   \n",
              "495                 0.439                    ['Corporate/Dividend Policy']   \n",
              "496                 0.435                              ['Corporate/Sales']   \n",
              "497                 0.259                        ['Corporate/Sales/Sales']   \n",
              "\n",
              "                                 preprocessed_sentence  \\\n",
              "0           royal mail chairman donald brydon set step   \n",
              "1    stake high astrazeneca heart drug face tough c...   \n",
              "2    update 1 dairy crest lose third morrison milk ...   \n",
              "3    insight hire aviva david hillier multi asset team   \n",
              "4             primark rack happy christmas strong sale   \n",
              "..                                                 ...   \n",
              "493     aviva m&g suspend property fund investor panic   \n",
              "494  uk housing market steady brexit dip persimmon say   \n",
              "495  brief aviva aim increase dividend pay ratio 50...   \n",
              "496           builder persimmon hail 6 rise house sale   \n",
              "497         easyjet attract passenger june lag ryanair   \n",
              "\n",
              "                                        numerical_info  \\\n",
              "0                                                   []   \n",
              "1                                                   []   \n",
              "2    [{'value': '1', 'type': 'cardinal', 'aspect': ...   \n",
              "3                                                   []   \n",
              "4                                                   []   \n",
              "..                                                 ...   \n",
              "493                                                 []   \n",
              "494                                                 []   \n",
              "495  [{'value': '50', 'type': 'cardinal', 'aspect':...   \n",
              "496  [{'value': '6', 'type': 'cardinal', 'aspect': ...   \n",
              "497                                                 []   \n",
              "\n",
              "                                        encoded_values  \\\n",
              "0                               tensor([[0., 0., 0.]])   \n",
              "1                               tensor([[0., 0., 0.]])   \n",
              "2    tensor([[ 0.0584, -0.0858, -0.0869,  0.0923, -...   \n",
              "3                               tensor([[0., 0., 0.]])   \n",
              "4                               tensor([[0., 0., 0.]])   \n",
              "..                                                 ...   \n",
              "493                             tensor([[0., 0., 0.]])   \n",
              "494                             tensor([[0., 0., 0.]])   \n",
              "495  tensor([[ -1.7565,   2.9354,  -1.0804, -74.387...   \n",
              "496  tensor([[-0.1363,  0.2211, -0.1850]], grad_fn=...   \n",
              "497                             tensor([[0., 0., 0.]])   \n",
              "\n",
              "         sentiment_scores_for_numerical_encoded_values     trend  \\\n",
              "0                                         [[0. 0. 0.]]       NaN   \n",
              "1                                         [[0. 0. 0.]]  increase   \n",
              "2    [[ 0.05843232 -0.08583678 -0.08687651  0.09229...  decrease   \n",
              "3                                         [[0. 0. 0.]]       NaN   \n",
              "4                                         [[0. 0. 0.]]  increase   \n",
              "..                                                 ...       ...   \n",
              "493                                       [[0. 0. 0.]]       NaN   \n",
              "494                                       [[0. 0. 0.]]       NaN   \n",
              "495  [[ -1.7564672   2.9353569  -1.0804299 -74.3875...  increase   \n",
              "496            [[-0.13633153  0.22108659 -0.18499303]]  increase   \n",
              "497                                       [[0. 0. 0.]]       NaN   \n",
              "\n",
              "        embedded_aspect  \\\n",
              "0            Royal Mail   \n",
              "1      high AstraZeneca   \n",
              "2    contract Morrisons   \n",
              "3               Insight   \n",
              "4        strong Primark   \n",
              "..                  ...   \n",
              "493                 M&G   \n",
              "494           Perssimon   \n",
              "495      increase Aviva   \n",
              "496      rise Persimmon   \n",
              "497             Ryanair   \n",
              "\n",
              "    predicted_sentiment_probability_after_attention_mechanism  \n",
              "0                   [0.27385473 0.35181287 0.3743324 ]         \n",
              "1                   [0.31220025 0.3440081  0.34379163]         \n",
              "2                   [0.3310783  0.34502226 0.32389942]         \n",
              "3                   [0.32109642 0.31461018 0.36429343]         \n",
              "4                   [0.24587269 0.42583296 0.32829437]         \n",
              "..                                                 ...         \n",
              "493                 [0.39725062 0.3022558  0.30049357]         \n",
              "494                 [0.29810035 0.39548886 0.30641082]         \n",
              "495                 [0.40770197 0.29260528 0.29969278]         \n",
              "496                 [0.27824777 0.35998258 0.36176968]         \n",
              "497                 [0.40991488 0.31226966 0.27781552]         \n",
              "\n",
              "[498 rows x 13 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzYWdCt5f_GZ"
      },
      "source": [
        "# Applying deep neural Network into it to"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-668YoJgCL9"
      },
      "source": [
        "## Bert embeddings outputs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqyBMC9zTem-"
      },
      "outputs": [],
      "source": [
        "null_sentences_indices = df['preprocessed_sentence'].isnull()\n",
        "\n",
        "non_null_sentences = df.loc[~null_sentences_indices, 'preprocessed_sentence']\n",
        "non_null_embeddings = get_bert_embeddings(non_null_sentences, tokenizer, bert_model)\n",
        "\n",
        "all_embeddings = []\n",
        "embedding_index = 0\n",
        "for i in range(len(df)):\n",
        "    if null_sentences_indices.iloc[i]:\n",
        "        all_embeddings.append(np.zeros(bert_model.config.hidden_size))\n",
        "    else:\n",
        "        all_embeddings.append(non_null_embeddings[embedding_index].numpy())\n",
        "        embedding_index += 1\n",
        "\n",
        "df['sentence_embedding'] = all_embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SubxQttlgINQ"
      },
      "source": [
        "## Parsing string input values into numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGWhdAtbMylz"
      },
      "outputs": [],
      "source": [
        "def parse_array_string(value):\n",
        "    if isinstance(value, str):\n",
        "        numbers = re.sub(r'[\\[\\]]', '', value).split()\n",
        "        return np.array([float(num) for num in numbers], dtype=float)\n",
        "    return np.array(value, dtype=float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6cPnrKRgPYZ"
      },
      "source": [
        "## scores in df is present in form of string and converting into integer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRAJQgLgM5t5"
      },
      "outputs": [],
      "source": [
        "df['sentiment_scores_for_numerical_encoded_values'] = df['sentiment_scores_for_numerical_encoded_values'].apply(parse_array_string)\n",
        "df['predicted_sentiment_probability_after_attention_mechanism'] = df['predicted_sentiment_probability_after_attention_mechanism'].apply(parse_array_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RdwsTsGgXic"
      },
      "source": [
        "## Combining sentence embedding with other numerical and probability features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELlwf8JxG5d7"
      },
      "outputs": [],
      "source": [
        "def combine_input_features(row):\n",
        "    sentence_embed = row['sentence_embedding']\n",
        "    numerical_features = np.array(row['sentiment_scores_for_numerical_encoded_values']).flatten()\n",
        "    probability_features = np.array(row['predicted_sentiment_probability_after_attention_mechanism']).flatten()\n",
        "    combined_features = np.concatenate([sentence_embed, numerical_features, probability_features])\n",
        "    return combined_features\n",
        "\n",
        "df['combined_features'] = df.apply(combine_input_features, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTzW92mRgiV6"
      },
      "source": [
        "## Padding '0' in combined features values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whC5S2a4HJRX"
      },
      "outputs": [],
      "source": [
        "max_len = max(df['combined_features'].apply(len))\n",
        "\n",
        "def pad_features(row):\n",
        "    return np.pad(row['combined_features'], (0, max_len - len(row['combined_features'])), 'constant')\n",
        "\n",
        "df['padded_features'] = df.apply(pad_features, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "l-64evlnLe6n",
        "outputId": "e93386c2-f52d-43b6-efdd-ccd43cca00fc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>padded_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.15728415548801422, 0.13684159517288208, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.6634877324104309, 0.05803902447223663, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.28981661796569824, -0.1630328744649887, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.5249969959259033, 0.09676232188940048, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.23952902853488922, -0.11516132205724716, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>[-0.3039036691188812, 0.12687204778194427, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>[-0.6879715323448181, -0.4613155722618103, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>[-0.3252580463886261, -0.023541629314422607, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>[-0.15889865159988403, 0.19436313211917877, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>[-0.2949851453304291, -0.012936169281601906, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>498 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0      [-0.15728415548801422, 0.13684159517288208, 0....\n",
              "1      [-0.6634877324104309, 0.05803902447223663, 0.0...\n",
              "2      [-0.28981661796569824, -0.1630328744649887, -0...\n",
              "3      [-0.5249969959259033, 0.09676232188940048, -0....\n",
              "4      [-0.23952902853488922, -0.11516132205724716, 0...\n",
              "                             ...                        \n",
              "493    [-0.3039036691188812, 0.12687204778194427, -0....\n",
              "494    [-0.6879715323448181, -0.4613155722618103, -0....\n",
              "495    [-0.3252580463886261, -0.023541629314422607, 0...\n",
              "496    [-0.15889865159988403, 0.19436313211917877, 0....\n",
              "497    [-0.2949851453304291, -0.012936169281601906, 0...\n",
              "Name: padded_features, Length: 498, dtype: object"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['padded_features']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6FH0jA-gtDc"
      },
      "source": [
        "## input as X_train and output as y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1TPE004HLw7"
      },
      "outputs": [],
      "source": [
        "X = np.vstack(df['padded_features'].values)\n",
        "y = df['info_sentiment_score'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W1RS3cFs09X"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-_LuqmQhEKy"
      },
      "source": [
        "## Normalize the combined features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ErAD_EmUhErx"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb_N2k5ugx9Y"
      },
      "source": [
        "## Deep Neural Network input values is X_train and output is y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tcQKUkmhSmW"
      },
      "source": [
        "## Calcuting predicted_sentiment and MSE , R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS1KhlJ_W4n2",
        "outputId": "e0650e59-a0c1-4aa7-c041-1552eac1bfe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.4057 - mse: 0.4057 - val_loss: 0.2773 - val_mse: 0.2773\n",
            "Epoch 2/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 0.2068 - val_mse: 0.2068\n",
            "Epoch 3/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.1808 - val_mse: 0.1808\n",
            "Epoch 4/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.1285 - mse: 0.1285 - val_loss: 0.1602 - val_mse: 0.1602\n",
            "Epoch 5/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.1067 - mse: 0.1067 - val_loss: 0.1713 - val_mse: 0.1713\n",
            "Epoch 6/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0973 - mse: 0.0973 - val_loss: 0.1563 - val_mse: 0.1563\n",
            "Epoch 7/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0862 - mse: 0.0862 - val_loss: 0.1532 - val_mse: 0.1532\n",
            "Epoch 8/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0707 - mse: 0.0707 - val_loss: 0.1412 - val_mse: 0.1412\n",
            "Epoch 9/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0651 - mse: 0.0651 - val_loss: 0.1494 - val_mse: 0.1494\n",
            "Epoch 10/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0715 - mse: 0.0715 - val_loss: 0.1307 - val_mse: 0.1307\n",
            "Epoch 11/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0656 - mse: 0.0656 - val_loss: 0.1543 - val_mse: 0.1543\n",
            "Epoch 12/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0515 - mse: 0.0515 - val_loss: 0.1313 - val_mse: 0.1313\n",
            "Epoch 13/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0498 - mse: 0.0498 - val_loss: 0.1245 - val_mse: 0.1245\n",
            "Epoch 14/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.1430 - val_mse: 0.1430\n",
            "Epoch 15/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0472 - mse: 0.0472 - val_loss: 0.1307 - val_mse: 0.1307\n",
            "Epoch 16/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0411 - mse: 0.0411 - val_loss: 0.1358 - val_mse: 0.1358\n",
            "Epoch 17/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0424 - mse: 0.0424 - val_loss: 0.1205 - val_mse: 0.1205\n",
            "Epoch 18/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 0.1325 - val_mse: 0.1325\n",
            "Epoch 19/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0356 - mse: 0.0356 - val_loss: 0.1476 - val_mse: 0.1476\n",
            "Epoch 20/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0393 - mse: 0.0393 - val_loss: 0.1324 - val_mse: 0.1324\n",
            "Epoch 21/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.1319 - val_mse: 0.1319\n",
            "Epoch 22/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0421 - mse: 0.0421 - val_loss: 0.1209 - val_mse: 0.1209\n",
            "Epoch 23/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0311 - mse: 0.0311 - val_loss: 0.1299 - val_mse: 0.1299\n",
            "Epoch 24/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.1236 - val_mse: 0.1236\n",
            "Epoch 25/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0320 - mse: 0.0320 - val_loss: 0.1211 - val_mse: 0.1211\n",
            "Epoch 26/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0352 - mse: 0.0352 - val_loss: 0.1200 - val_mse: 0.1200\n",
            "Epoch 27/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.1190 - val_mse: 0.1190\n",
            "Epoch 28/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.1189 - val_mse: 0.1189\n",
            "Epoch 29/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.1218 - val_mse: 0.1218\n",
            "Epoch 30/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.1243 - val_mse: 0.1243\n",
            "Epoch 31/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.1270 - val_mse: 0.1270\n",
            "Epoch 32/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.1241 - val_mse: 0.1241\n",
            "Epoch 33/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0278 - mse: 0.0278 - val_loss: 0.1236 - val_mse: 0.1236\n",
            "Epoch 34/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0287 - mse: 0.0287 - val_loss: 0.1272 - val_mse: 0.1272\n",
            "Epoch 35/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.1132 - val_mse: 0.1132\n",
            "Epoch 36/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.1132 - val_mse: 0.1132\n",
            "Epoch 37/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0259 - mse: 0.0259 - val_loss: 0.1094 - val_mse: 0.1094\n",
            "Epoch 38/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.1201 - val_mse: 0.1201\n",
            "Epoch 39/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.1167 - val_mse: 0.1167\n",
            "Epoch 40/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.1169 - val_mse: 0.1169\n",
            "Epoch 41/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.1125 - val_mse: 0.1125\n",
            "Epoch 42/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.1149 - val_mse: 0.1149\n",
            "Epoch 43/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.1105 - val_mse: 0.1105\n",
            "Epoch 44/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.1146 - val_mse: 0.1146\n",
            "Epoch 45/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.1205 - val_mse: 0.1205\n",
            "Epoch 46/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.1190 - val_mse: 0.1190\n",
            "Epoch 47/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.1188 - val_mse: 0.1188\n",
            "Epoch 48/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1225 - val_mse: 0.1225\n",
            "Epoch 49/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.1230 - val_mse: 0.1230\n",
            "Epoch 50/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.1171 - val_mse: 0.1171\n",
            "Epoch 51/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.1235 - val_mse: 0.1235\n",
            "Epoch 52/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.1202 - val_mse: 0.1202\n",
            "Epoch 53/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.1218 - val_mse: 0.1218\n",
            "Epoch 54/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.1172 - val_mse: 0.1172\n",
            "Epoch 55/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.1202 - val_mse: 0.1202\n",
            "Epoch 56/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.1232 - val_mse: 0.1232\n",
            "Epoch 57/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.1197 - val_mse: 0.1197\n",
            "Epoch 58/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.1210 - val_mse: 0.1210\n",
            "Epoch 59/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.1240 - val_mse: 0.1240\n",
            "Epoch 60/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.1255 - val_mse: 0.1255\n",
            "Epoch 61/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.1208 - val_mse: 0.1208\n",
            "Epoch 62/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1245 - val_mse: 0.1245\n",
            "Epoch 63/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1211 - val_mse: 0.1211\n",
            "Epoch 64/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.1219 - val_mse: 0.1219\n",
            "Epoch 65/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.1176 - val_mse: 0.1176\n",
            "Epoch 66/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.1202 - val_mse: 0.1202\n",
            "Epoch 67/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.1176 - val_mse: 0.1176\n",
            "Epoch 68/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.1203 - val_mse: 0.1203\n",
            "Epoch 69/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.1163 - val_mse: 0.1163\n",
            "Epoch 70/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1157 - val_mse: 0.1157\n",
            "Epoch 71/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.1142 - val_mse: 0.1142\n",
            "Epoch 72/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.1155 - val_mse: 0.1155\n",
            "Epoch 73/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1173 - val_mse: 0.1173\n",
            "Epoch 74/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.1156 - val_mse: 0.1156\n",
            "Epoch 75/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.1144 - val_mse: 0.1144\n",
            "Epoch 76/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.1145 - val_mse: 0.1145\n",
            "Epoch 77/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.1132 - val_mse: 0.1132\n",
            "Epoch 78/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.1244 - val_mse: 0.1244\n",
            "Epoch 79/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.1149 - val_mse: 0.1149\n",
            "Epoch 80/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.1218 - val_mse: 0.1218\n",
            "Epoch 81/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.1134 - val_mse: 0.1134\n",
            "Epoch 82/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.1123 - val_mse: 0.1123\n",
            "Epoch 83/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.1134 - val_mse: 0.1134\n",
            "Epoch 84/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.1083 - val_mse: 0.1083\n",
            "Epoch 85/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.1137 - val_mse: 0.1137\n",
            "Epoch 86/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1173 - val_mse: 0.1173\n",
            "Epoch 87/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.1149 - val_mse: 0.1149\n",
            "Epoch 88/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.1151 - val_mse: 0.1151\n",
            "Epoch 89/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1162 - val_mse: 0.1162\n",
            "Epoch 90/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.1179 - val_mse: 0.1179\n",
            "Epoch 91/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1206 - val_mse: 0.1206\n",
            "Epoch 92/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.1167 - val_mse: 0.1167\n",
            "Epoch 93/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.1140 - val_mse: 0.1140\n",
            "Epoch 94/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.1146 - val_mse: 0.1146\n",
            "Epoch 95/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1194 - val_mse: 0.1194\n",
            "Epoch 96/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1121 - val_mse: 0.1121\n",
            "Epoch 97/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.1162 - val_mse: 0.1162\n",
            "Epoch 98/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.1158 - val_mse: 0.1158\n",
            "Epoch 99/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.1172 - val_mse: 0.1172\n",
            "Epoch 100/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.1127 - val_mse: 0.1127\n",
            "Epoch 101/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.1117 - val_mse: 0.1117\n",
            "Epoch 102/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.1122 - val_mse: 0.1122\n",
            "Epoch 103/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1114 - val_mse: 0.1114\n",
            "Epoch 104/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1146 - val_mse: 0.1146\n",
            "Epoch 105/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 106/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.1140 - val_mse: 0.1140\n",
            "Epoch 107/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 108/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1128 - val_mse: 0.1128\n",
            "Epoch 109/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1117 - val_mse: 0.1117\n",
            "Epoch 110/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.1100 - val_mse: 0.1100\n",
            "Epoch 111/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 112/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.1061 - val_mse: 0.1061\n",
            "Epoch 113/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.1071 - val_mse: 0.1071\n",
            "Epoch 114/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 115/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.1105 - val_mse: 0.1105\n",
            "Epoch 116/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 117/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1084 - val_mse: 0.1084\n",
            "Epoch 118/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.1108 - val_mse: 0.1108\n",
            "Epoch 119/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 120/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 121/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1103 - val_mse: 0.1103\n",
            "Epoch 122/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1093 - val_mse: 0.1093\n",
            "Epoch 123/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1121 - val_mse: 0.1121\n",
            "Epoch 124/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.1119 - val_mse: 0.1119\n",
            "Epoch 125/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1080 - val_mse: 0.1080\n",
            "Epoch 126/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1061 - val_mse: 0.1061\n",
            "Epoch 127/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 128/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.1106 - val_mse: 0.1106\n",
            "Epoch 129/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.1106 - val_mse: 0.1106\n",
            "Epoch 130/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 131/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 132/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.1067 - val_mse: 0.1067\n",
            "Epoch 133/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.1075 - val_mse: 0.1075\n",
            "Epoch 134/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1046 - val_mse: 0.1046\n",
            "Epoch 135/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.1059 - val_mse: 0.1059\n",
            "Epoch 136/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1023 - val_mse: 0.1023\n",
            "Epoch 137/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.1063 - val_mse: 0.1063\n",
            "Epoch 138/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1104 - val_mse: 0.1104\n",
            "Epoch 139/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1080 - val_mse: 0.1080\n",
            "Epoch 140/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 141/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.1094 - val_mse: 0.1094\n",
            "Epoch 142/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1088 - val_mse: 0.1088\n",
            "Epoch 143/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1095 - val_mse: 0.1095\n",
            "Epoch 144/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.1072 - val_mse: 0.1072\n",
            "Epoch 145/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1127 - val_mse: 0.1127\n",
            "Epoch 146/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1108 - val_mse: 0.1108\n",
            "Epoch 147/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1114 - val_mse: 0.1114\n",
            "Epoch 148/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 149/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1097 - val_mse: 0.1097\n",
            "Epoch 150/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1054 - val_mse: 0.1054\n",
            "Epoch 151/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.1044 - val_mse: 0.1044\n",
            "Epoch 152/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 153/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 154/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.1048 - val_mse: 0.1048\n",
            "Epoch 155/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 156/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.1091 - val_mse: 0.1091\n",
            "Epoch 157/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.1102 - val_mse: 0.1102\n",
            "Epoch 158/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 159/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1085 - val_mse: 0.1085\n",
            "Epoch 160/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 161/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1065 - val_mse: 0.1065\n",
            "Epoch 162/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.1064 - val_mse: 0.1064\n",
            "Epoch 163/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 164/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.1083 - val_mse: 0.1083\n",
            "Epoch 165/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.1059 - val_mse: 0.1059\n",
            "Epoch 166/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1066 - val_mse: 0.1066\n",
            "Epoch 167/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 168/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.1100 - val_mse: 0.1100\n",
            "Epoch 169/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1104 - val_mse: 0.1104\n",
            "Epoch 170/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1088 - val_mse: 0.1088\n",
            "Epoch 171/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 172/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1076 - val_mse: 0.1076\n",
            "Epoch 173/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1097 - val_mse: 0.1097\n",
            "Epoch 174/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1091 - val_mse: 0.1091\n",
            "Epoch 175/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.1080 - val_mse: 0.1080\n",
            "Epoch 176/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1049 - val_mse: 0.1049\n",
            "Epoch 177/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1085 - val_mse: 0.1085\n",
            "Epoch 178/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.1094 - val_mse: 0.1094\n",
            "Epoch 179/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.1081 - val_mse: 0.1081\n",
            "Epoch 180/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1071 - val_mse: 0.1071\n",
            "Epoch 181/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 182/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.1059 - val_mse: 0.1059\n",
            "Epoch 183/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1079 - val_mse: 0.1079\n",
            "Epoch 184/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 185/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1103 - val_mse: 0.1103\n",
            "Epoch 186/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1114 - val_mse: 0.1114\n",
            "Epoch 187/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.1103 - val_mse: 0.1103\n",
            "Epoch 188/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1082 - val_mse: 0.1082\n",
            "Epoch 189/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1072 - val_mse: 0.1072\n",
            "Epoch 190/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.1045 - val_mse: 0.1045\n",
            "Epoch 191/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1084 - val_mse: 0.1084\n",
            "Epoch 192/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1075 - val_mse: 0.1075\n",
            "Epoch 193/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1091 - val_mse: 0.1091\n",
            "Epoch 194/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1096 - val_mse: 0.1096\n",
            "Epoch 195/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1088 - val_mse: 0.1088\n",
            "Epoch 196/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 197/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1123 - val_mse: 0.1123\n",
            "Epoch 198/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1122 - val_mse: 0.1122\n",
            "Epoch 199/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1140 - val_mse: 0.1140\n",
            "Epoch 200/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.1148 - val_mse: 0.1148\n",
            "Epoch 201/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1121 - val_mse: 0.1121\n",
            "Epoch 202/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 203/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1107 - val_mse: 0.1107\n",
            "Epoch 204/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.1092 - val_mse: 0.1092\n",
            "Epoch 205/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 206/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 207/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1082 - val_mse: 0.1082\n",
            "Epoch 208/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 209/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 210/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1104 - val_mse: 0.1104\n",
            "Epoch 211/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1131 - val_mse: 0.1131\n",
            "Epoch 212/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1108 - val_mse: 0.1108\n",
            "Epoch 213/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 214/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1072 - val_mse: 0.1072\n",
            "Epoch 215/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 216/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1091 - val_mse: 0.1091\n",
            "Epoch 217/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1102 - val_mse: 0.1102\n",
            "Epoch 218/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 219/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1112 - val_mse: 0.1112\n",
            "Epoch 220/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 221/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 222/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.1108 - val_mse: 0.1108\n",
            "Epoch 223/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1114 - val_mse: 0.1114\n",
            "Epoch 224/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1126 - val_mse: 0.1126\n",
            "Epoch 225/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.1104 - val_mse: 0.1104\n",
            "Epoch 226/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 227/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1110 - val_mse: 0.1110\n",
            "Epoch 228/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1141 - val_mse: 0.1141\n",
            "Epoch 229/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1117 - val_mse: 0.1117\n",
            "Epoch 230/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.1085 - val_mse: 0.1085\n",
            "Epoch 231/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1125 - val_mse: 0.1125\n",
            "Epoch 232/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.1147 - val_mse: 0.1147\n",
            "Epoch 233/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.1145 - val_mse: 0.1145\n",
            "Epoch 234/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.1124 - val_mse: 0.1124\n",
            "Epoch 235/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1062 - val_mse: 0.1062\n",
            "Epoch 236/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1055 - val_mse: 0.1055\n",
            "Epoch 237/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1056 - val_mse: 0.1056\n",
            "Epoch 238/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 239/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 240/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1064 - val_mse: 0.1064\n",
            "Epoch 241/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.1068 - val_mse: 0.1068\n",
            "Epoch 242/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.1094 - val_mse: 0.1094\n",
            "Epoch 243/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.1093 - val_mse: 0.1093\n",
            "Epoch 244/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.1065 - val_mse: 0.1065\n",
            "Epoch 245/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 246/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1079 - val_mse: 0.1079\n",
            "Epoch 247/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1066 - val_mse: 0.1066\n",
            "Epoch 248/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1073 - val_mse: 0.1073\n",
            "Epoch 249/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 250/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.1053 - val_mse: 0.1053\n",
            "Epoch 251/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1046 - val_mse: 0.1046\n",
            "Epoch 252/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.1044 - val_mse: 0.1044\n",
            "Epoch 253/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.1046 - val_mse: 0.1046\n",
            "Epoch 254/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 255/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.1080 - val_mse: 0.1080\n",
            "Epoch 256/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1084 - val_mse: 0.1084\n",
            "Epoch 257/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.1068 - val_mse: 0.1068\n",
            "Epoch 258/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1085 - val_mse: 0.1085\n",
            "Epoch 259/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.1102 - val_mse: 0.1102\n",
            "Epoch 260/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1107 - val_mse: 0.1107\n",
            "Epoch 261/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.1092 - val_mse: 0.1092\n",
            "Epoch 262/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 263/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1102 - val_mse: 0.1102\n",
            "Epoch 264/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1101 - val_mse: 0.1101\n",
            "Epoch 265/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.1107 - val_mse: 0.1107\n",
            "Epoch 266/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1116 - val_mse: 0.1116\n",
            "Epoch 267/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.1106 - val_mse: 0.1106\n",
            "Epoch 268/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.1116 - val_mse: 0.1116\n",
            "Epoch 269/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1095 - val_mse: 0.1095\n",
            "Epoch 270/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1054 - val_mse: 0.1054\n",
            "Epoch 271/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 272/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1074 - val_mse: 0.1074\n",
            "Epoch 273/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1077 - val_mse: 0.1077\n",
            "Epoch 274/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1062 - val_mse: 0.1062\n",
            "Epoch 275/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1093 - val_mse: 0.1093\n",
            "Epoch 276/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1056 - val_mse: 0.1056\n",
            "Epoch 277/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.1042 - val_mse: 0.1042\n",
            "Epoch 278/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1081 - val_mse: 0.1081\n",
            "Epoch 279/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 280/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1047 - val_mse: 0.1047\n",
            "Epoch 281/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1047 - val_mse: 0.1047\n",
            "Epoch 282/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1042 - val_mse: 0.1042\n",
            "Epoch 283/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1018 - val_mse: 0.1018\n",
            "Epoch 284/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1049 - val_mse: 0.1049\n",
            "Epoch 285/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.1072 - val_mse: 0.1072\n",
            "Epoch 286/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 287/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1056 - val_mse: 0.1056\n",
            "Epoch 288/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1084 - val_mse: 0.1084\n",
            "Epoch 289/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1094 - val_mse: 0.1094\n",
            "Epoch 290/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 291/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1103 - val_mse: 0.1103\n",
            "Epoch 292/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1134 - val_mse: 0.1134\n",
            "Epoch 293/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1077 - val_mse: 0.1077\n",
            "Epoch 294/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1063 - val_mse: 0.1063\n",
            "Epoch 295/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1045 - val_mse: 0.1045\n",
            "Epoch 296/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1054 - val_mse: 0.1054\n",
            "Epoch 297/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1064 - val_mse: 0.1064\n",
            "Epoch 298/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.1039 - val_mse: 0.1039\n",
            "Epoch 299/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1061 - val_mse: 0.1061\n",
            "Epoch 300/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1052 - val_mse: 0.1052\n",
            "Epoch 301/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.1038 - val_mse: 0.1038\n",
            "Epoch 302/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1029 - val_mse: 0.1029\n",
            "Epoch 303/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1028 - val_mse: 0.1028\n",
            "Epoch 304/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1041 - val_mse: 0.1041\n",
            "Epoch 305/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1045 - val_mse: 0.1045\n",
            "Epoch 306/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 307/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1061 - val_mse: 0.1061\n",
            "Epoch 308/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1052 - val_mse: 0.1052\n",
            "Epoch 309/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1127 - val_mse: 0.1127\n",
            "Epoch 310/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 311/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1075 - val_mse: 0.1075\n",
            "Epoch 312/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1069 - val_mse: 0.1069\n",
            "Epoch 313/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1063 - val_mse: 0.1063\n",
            "Epoch 314/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 315/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1077 - val_mse: 0.1077\n",
            "Epoch 316/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.1068 - val_mse: 0.1068\n",
            "Epoch 317/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.1039 - val_mse: 0.1039\n",
            "Epoch 318/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1007 - val_mse: 0.1007\n",
            "Epoch 319/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.1008 - val_mse: 0.1008\n",
            "Epoch 320/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 321/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1093 - val_mse: 0.1093\n",
            "Epoch 322/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1083 - val_mse: 0.1083\n",
            "Epoch 323/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1061 - val_mse: 0.1061\n",
            "Epoch 324/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.1083 - val_mse: 0.1083\n",
            "Epoch 325/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.1071 - val_mse: 0.1071\n",
            "Epoch 326/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.1068 - val_mse: 0.1068\n",
            "Epoch 327/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 328/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1096 - val_mse: 0.1096\n",
            "Epoch 329/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1046 - val_mse: 0.1046\n",
            "Epoch 330/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1034 - val_mse: 0.1034\n",
            "Epoch 331/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.1033 - val_mse: 0.1033\n",
            "Epoch 332/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.1045 - val_mse: 0.1045\n",
            "Epoch 333/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0993 - val_mse: 0.0993\n",
            "Epoch 334/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0987 - val_mse: 0.0987\n",
            "Epoch 335/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1022 - val_mse: 0.1022\n",
            "Epoch 336/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1039 - val_mse: 0.1039\n",
            "Epoch 337/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1040 - val_mse: 0.1040\n",
            "Epoch 338/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1004 - val_mse: 0.1004\n",
            "Epoch 339/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.1051 - val_mse: 0.1051\n",
            "Epoch 340/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 341/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1047 - val_mse: 0.1047\n",
            "Epoch 342/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1126 - val_mse: 0.1126\n",
            "Epoch 343/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.1115 - val_mse: 0.1115\n",
            "Epoch 344/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1036 - val_mse: 0.1036\n",
            "Epoch 345/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.1021 - val_mse: 0.1021\n",
            "Epoch 346/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 347/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 348/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.1064 - val_mse: 0.1064\n",
            "Epoch 349/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1023 - val_mse: 0.1023\n",
            "Epoch 350/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1064 - val_mse: 0.1064\n",
            "Epoch 351/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "Epoch 352/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1065 - val_mse: 0.1065\n",
            "Epoch 353/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1088 - val_mse: 0.1088\n",
            "Epoch 354/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.1105 - val_mse: 0.1105\n",
            "Epoch 355/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 356/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 357/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1075 - val_mse: 0.1075\n",
            "Epoch 358/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.0992 - val_mse: 0.0992\n",
            "Epoch 359/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.0980 - val_mse: 0.0980\n",
            "Epoch 360/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1023 - val_mse: 0.1023\n",
            "Epoch 361/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1062 - val_mse: 0.1062\n",
            "Epoch 362/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1048 - val_mse: 0.1048\n",
            "Epoch 363/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1045 - val_mse: 0.1045\n",
            "Epoch 364/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1019 - val_mse: 0.1019\n",
            "Epoch 365/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.1024 - val_mse: 0.1024\n",
            "Epoch 366/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1031 - val_mse: 0.1031\n",
            "Epoch 367/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1048 - val_mse: 0.1048\n",
            "Epoch 368/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1137 - val_mse: 0.1137\n",
            "Epoch 369/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 370/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 371/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 372/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.1092 - val_mse: 0.1092\n",
            "Epoch 373/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.1068 - val_mse: 0.1068\n",
            "Epoch 374/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1062 - val_mse: 0.1062\n",
            "Epoch 375/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1092 - val_mse: 0.1092\n",
            "Epoch 376/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1101 - val_mse: 0.1101\n",
            "Epoch 377/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.1079 - val_mse: 0.1079\n",
            "Epoch 378/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1050 - val_mse: 0.1050\n",
            "Epoch 379/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 380/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.1132 - val_mse: 0.1132\n",
            "Epoch 381/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1097 - val_mse: 0.1097\n",
            "Epoch 382/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.1063 - val_mse: 0.1063\n",
            "Epoch 383/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.1053 - val_mse: 0.1053\n",
            "Epoch 384/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.1051 - val_mse: 0.1051\n",
            "Epoch 385/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.1014 - val_mse: 0.1014\n",
            "Epoch 386/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.1044 - val_mse: 0.1044\n",
            "Epoch 387/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.1080 - val_mse: 0.1080\n",
            "Epoch 388/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.1061 - val_mse: 0.1061\n",
            "Epoch 389/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.1073 - val_mse: 0.1073\n",
            "Epoch 390/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.1074 - val_mse: 0.1074\n",
            "Epoch 391/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1021 - val_mse: 0.1021\n",
            "Epoch 392/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1060 - val_mse: 0.1060\n",
            "Epoch 393/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1029 - val_mse: 0.1029\n",
            "Epoch 394/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 395/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1102 - val_mse: 0.1102\n",
            "Epoch 396/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.1083 - val_mse: 0.1083\n",
            "Epoch 397/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1072 - val_mse: 0.1072\n",
            "Epoch 398/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 399/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1080 - val_mse: 0.1080\n",
            "Epoch 400/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1105 - val_mse: 0.1105\n",
            "Epoch 401/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1112 - val_mse: 0.1112\n",
            "Epoch 402/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.1108 - val_mse: 0.1108\n",
            "Epoch 403/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1162 - val_mse: 0.1162\n",
            "Epoch 404/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.1112 - val_mse: 0.1112\n",
            "Epoch 405/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.1029 - val_mse: 0.1029\n",
            "Epoch 406/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 407/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.1131 - val_mse: 0.1131\n",
            "Epoch 408/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.1123 - val_mse: 0.1123\n",
            "Epoch 409/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.1110 - val_mse: 0.1110\n",
            "Epoch 410/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1136 - val_mse: 0.1136\n",
            "Epoch 411/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1116 - val_mse: 0.1116\n",
            "Epoch 412/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1178 - val_mse: 0.1178\n",
            "Epoch 413/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 414/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.1121 - val_mse: 0.1121\n",
            "Epoch 415/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.1156 - val_mse: 0.1156\n",
            "Epoch 416/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 417/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.1050 - val_mse: 0.1050\n",
            "Epoch 418/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.1039 - val_mse: 0.1039\n",
            "Epoch 419/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1053 - val_mse: 0.1053\n",
            "Epoch 420/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 421/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.1136 - val_mse: 0.1136\n",
            "Epoch 422/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.1252 - val_mse: 0.1252\n",
            "Epoch 423/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1107 - val_mse: 0.1107\n",
            "Epoch 424/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 425/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 426/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 427/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1124 - val_mse: 0.1124\n",
            "Epoch 428/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1106 - val_mse: 0.1106\n",
            "Epoch 429/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1088 - val_mse: 0.1088\n",
            "Epoch 430/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1092 - val_mse: 0.1092\n",
            "Epoch 431/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 432/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 433/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1143 - val_mse: 0.1143\n",
            "Epoch 434/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 435/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1076 - val_mse: 0.1076\n",
            "Epoch 436/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.1096 - val_mse: 0.1096\n",
            "Epoch 437/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1097 - val_mse: 0.1097\n",
            "Epoch 438/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.1085 - val_mse: 0.1085\n",
            "Epoch 439/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1129 - val_mse: 0.1129\n",
            "Epoch 440/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0150 - mse: 0.0150 - val_loss: 0.1120 - val_mse: 0.1120\n",
            "Epoch 441/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0148 - mse: 0.0148 - val_loss: 0.1382 - val_mse: 0.1382\n",
            "Epoch 442/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.1176 - val_mse: 0.1176\n",
            "Epoch 443/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.1134 - val_mse: 0.1134\n",
            "Epoch 444/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.1147 - val_mse: 0.1147\n",
            "Epoch 445/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1085 - val_mse: 0.1085\n",
            "Epoch 446/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1340 - val_mse: 0.1340\n",
            "Epoch 447/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.1173 - val_mse: 0.1173\n",
            "Epoch 448/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 449/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.1338 - val_mse: 0.1338\n",
            "Epoch 450/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.1258 - val_mse: 0.1258\n",
            "Epoch 451/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.1395 - val_mse: 0.1395\n",
            "Epoch 452/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.1213 - val_mse: 0.1213\n",
            "Epoch 453/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1138 - val_mse: 0.1138\n",
            "Epoch 454/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1158 - val_mse: 0.1158\n",
            "Epoch 455/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.1249 - val_mse: 0.1249\n",
            "Epoch 456/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.1123 - val_mse: 0.1123\n",
            "Epoch 457/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1160 - val_mse: 0.1160\n",
            "Epoch 458/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.1052 - val_mse: 0.1052\n",
            "Epoch 459/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1163 - val_mse: 0.1163\n",
            "Epoch 460/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1145 - val_mse: 0.1145\n",
            "Epoch 461/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 462/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 463/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1045 - val_mse: 0.1045\n",
            "Epoch 464/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0939 - val_mse: 0.0939\n",
            "Epoch 465/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1034 - val_mse: 0.1034\n",
            "Epoch 466/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0947 - val_mse: 0.0947\n",
            "Epoch 467/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1146 - val_mse: 0.1146\n",
            "Epoch 468/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.1051 - val_mse: 0.1051\n",
            "Epoch 469/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.0987 - val_mse: 0.0987\n",
            "Epoch 470/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.1201 - val_mse: 0.1201\n",
            "Epoch 471/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.1204 - val_mse: 0.1204\n",
            "Epoch 472/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1246 - val_mse: 0.1246\n",
            "Epoch 473/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.1312 - val_mse: 0.1312\n",
            "Epoch 474/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.1323 - val_mse: 0.1323\n",
            "Epoch 475/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1303 - val_mse: 0.1303\n",
            "Epoch 476/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.1280 - val_mse: 0.1280\n",
            "Epoch 477/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1248 - val_mse: 0.1248\n",
            "Epoch 478/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.1124 - val_mse: 0.1124\n",
            "Epoch 479/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1197 - val_mse: 0.1197\n",
            "Epoch 480/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1197 - val_mse: 0.1197\n",
            "Epoch 481/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1185 - val_mse: 0.1185\n",
            "Epoch 482/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1219 - val_mse: 0.1219\n",
            "Epoch 483/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.1175 - val_mse: 0.1175\n",
            "Epoch 484/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.1119 - val_mse: 0.1119\n",
            "Epoch 485/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.1134 - val_mse: 0.1134\n",
            "Epoch 486/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 487/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1104 - val_mse: 0.1104\n",
            "Epoch 488/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.1098 - val_mse: 0.1098\n",
            "Epoch 489/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1118 - val_mse: 0.1118\n",
            "Epoch 490/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1143 - val_mse: 0.1143\n",
            "Epoch 491/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.1139 - val_mse: 0.1139\n",
            "Epoch 492/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1130 - val_mse: 0.1130\n",
            "Epoch 493/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1149 - val_mse: 0.1149\n",
            "Epoch 494/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1217 - val_mse: 0.1217\n",
            "Epoch 495/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1204 - val_mse: 0.1204\n",
            "Epoch 496/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1158 - val_mse: 0.1158\n",
            "Epoch 497/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1184 - val_mse: 0.1184\n",
            "Epoch 498/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1147 - val_mse: 0.1147\n",
            "Epoch 499/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.1173 - val_mse: 0.1173\n",
            "Epoch 500/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 501/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 502/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.1197 - val_mse: 0.1197\n",
            "Epoch 503/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.1191 - val_mse: 0.1191\n",
            "Epoch 504/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1143 - val_mse: 0.1143\n",
            "Epoch 505/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1085 - val_mse: 0.1085\n",
            "Epoch 506/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 507/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1241 - val_mse: 0.1241\n",
            "Epoch 508/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.1130 - val_mse: 0.1130\n",
            "Epoch 509/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1112 - val_mse: 0.1112\n",
            "Epoch 510/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1188 - val_mse: 0.1188\n",
            "Epoch 511/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 512/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.1067 - val_mse: 0.1067\n",
            "Epoch 513/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 514/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1097 - val_mse: 0.1097\n",
            "Epoch 515/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1061 - val_mse: 0.1061\n",
            "Epoch 516/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1087 - val_mse: 0.1087\n",
            "Epoch 517/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1068 - val_mse: 0.1068\n",
            "Epoch 518/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1053 - val_mse: 0.1053\n",
            "Epoch 519/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1105 - val_mse: 0.1105\n",
            "Epoch 520/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1160 - val_mse: 0.1160\n",
            "Epoch 521/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1209 - val_mse: 0.1209\n",
            "Epoch 522/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.1153 - val_mse: 0.1153\n",
            "Epoch 523/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1212 - val_mse: 0.1212\n",
            "Epoch 524/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1224 - val_mse: 0.1224\n",
            "Epoch 525/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.1222 - val_mse: 0.1222\n",
            "Epoch 526/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1197 - val_mse: 0.1197\n",
            "Epoch 527/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0131 - mse: 0.0131 - val_loss: 0.1171 - val_mse: 0.1171\n",
            "Epoch 528/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.1191 - val_mse: 0.1191\n",
            "Epoch 529/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1177 - val_mse: 0.1177\n",
            "Epoch 530/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1113 - val_mse: 0.1113\n",
            "Epoch 531/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1109 - val_mse: 0.1109\n",
            "Epoch 532/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0154 - mse: 0.0154 - val_loss: 0.1148 - val_mse: 0.1148\n",
            "Epoch 533/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1124 - val_mse: 0.1124\n",
            "Epoch 534/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1135 - val_mse: 0.1135\n",
            "Epoch 535/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1138 - val_mse: 0.1138\n",
            "Epoch 536/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.1181 - val_mse: 0.1181\n",
            "Epoch 537/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1181 - val_mse: 0.1181\n",
            "Epoch 538/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0069 - mse: 0.0069 - val_loss: 0.1194 - val_mse: 0.1194\n",
            "Epoch 539/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.1195 - val_mse: 0.1195\n",
            "Epoch 540/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1124 - val_mse: 0.1124\n",
            "Epoch 541/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.1122 - val_mse: 0.1122\n",
            "Epoch 542/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.1147 - val_mse: 0.1147\n",
            "Epoch 543/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.1183 - val_mse: 0.1183\n",
            "Epoch 544/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 545/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1093 - val_mse: 0.1093\n",
            "Epoch 546/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1170 - val_mse: 0.1170\n",
            "Epoch 547/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1132 - val_mse: 0.1132\n",
            "Epoch 548/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1101 - val_mse: 0.1101\n",
            "Epoch 549/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 550/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.1117 - val_mse: 0.1117\n",
            "Epoch 551/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.1071 - val_mse: 0.1071\n",
            "Epoch 552/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.1132 - val_mse: 0.1132\n",
            "Epoch 553/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 554/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.1107 - val_mse: 0.1107\n",
            "Epoch 555/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.1240 - val_mse: 0.1240\n",
            "Epoch 556/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1093 - val_mse: 0.1093\n",
            "Epoch 557/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1066 - val_mse: 0.1066\n",
            "Epoch 558/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1092 - val_mse: 0.1092\n",
            "Epoch 559/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1137 - val_mse: 0.1137\n",
            "Epoch 560/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1225 - val_mse: 0.1225\n",
            "Epoch 561/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.1224 - val_mse: 0.1224\n",
            "Epoch 562/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.1248 - val_mse: 0.1248\n",
            "Epoch 563/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.1177 - val_mse: 0.1177\n",
            "Epoch 564/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1027 - val_mse: 0.1027\n",
            "Epoch 565/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1119 - val_mse: 0.1119\n",
            "Epoch 566/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.1254 - val_mse: 0.1254\n",
            "Epoch 567/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.1195 - val_mse: 0.1195\n",
            "Epoch 568/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.1123 - val_mse: 0.1123\n",
            "Epoch 569/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.1127 - val_mse: 0.1127\n",
            "Epoch 570/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1091 - val_mse: 0.1091\n",
            "Epoch 571/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1074 - val_mse: 0.1074\n",
            "Epoch 572/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 573/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.1297 - val_mse: 0.1297\n",
            "Epoch 574/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.1280 - val_mse: 0.1280\n",
            "Epoch 575/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.1247 - val_mse: 0.1247\n",
            "Epoch 576/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.1040 - val_mse: 0.1040\n",
            "Epoch 577/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 578/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.1437 - val_mse: 0.1437\n",
            "Epoch 579/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1359 - val_mse: 0.1359\n",
            "Epoch 580/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.1257 - val_mse: 0.1257\n",
            "Epoch 581/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.1196 - val_mse: 0.1196\n",
            "Epoch 582/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.1256 - val_mse: 0.1256\n",
            "Epoch 583/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1292 - val_mse: 0.1292\n",
            "Epoch 584/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1205 - val_mse: 0.1205\n",
            "Epoch 585/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.1088 - val_mse: 0.1088\n",
            "Epoch 586/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.1215 - val_mse: 0.1215\n",
            "Epoch 587/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.1203 - val_mse: 0.1203\n",
            "Epoch 588/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.1222 - val_mse: 0.1222\n",
            "Epoch 589/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.1220 - val_mse: 0.1220\n",
            "Epoch 590/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.1215 - val_mse: 0.1215\n",
            "Epoch 591/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.1190 - val_mse: 0.1190\n",
            "Epoch 592/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.1248 - val_mse: 0.1248\n",
            "Epoch 593/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1146 - val_mse: 0.1146\n",
            "Epoch 594/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.1301 - val_mse: 0.1301\n",
            "Epoch 595/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.1326 - val_mse: 0.1326\n",
            "Epoch 596/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.1436 - val_mse: 0.1436\n",
            "Epoch 597/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1336 - val_mse: 0.1336\n",
            "Epoch 598/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1448 - val_mse: 0.1448\n",
            "Epoch 599/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.1094 - val_mse: 0.1094\n",
            "Epoch 600/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.1313 - val_mse: 0.1313\n",
            "Epoch 601/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.1289 - val_mse: 0.1289\n",
            "Epoch 602/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.1160 - val_mse: 0.1160\n",
            "Epoch 603/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1179 - val_mse: 0.1179\n",
            "Epoch 604/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1152 - val_mse: 0.1152\n",
            "Epoch 605/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.1139 - val_mse: 0.1139\n",
            "Epoch 606/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.1147 - val_mse: 0.1147\n",
            "Epoch 607/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1086 - val_mse: 0.1086\n",
            "Epoch 608/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1059 - val_mse: 0.1059\n",
            "Epoch 609/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1132 - val_mse: 0.1132\n",
            "Epoch 610/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1176 - val_mse: 0.1176\n",
            "Epoch 611/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1147 - val_mse: 0.1147\n",
            "Epoch 612/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.1166 - val_mse: 0.1166\n",
            "Epoch 613/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.1228 - val_mse: 0.1228\n",
            "Epoch 614/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1224 - val_mse: 0.1224\n",
            "Epoch 615/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.1196 - val_mse: 0.1196\n",
            "Epoch 616/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.1193 - val_mse: 0.1193\n",
            "Epoch 617/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.1295 - val_mse: 0.1295\n",
            "Epoch 618/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0152 - mse: 0.0152 - val_loss: 0.1304 - val_mse: 0.1304\n",
            "Epoch 619/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.1308 - val_mse: 0.1308\n",
            "Epoch 620/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1297 - val_mse: 0.1297\n",
            "Epoch 621/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.1253 - val_mse: 0.1253\n",
            "Epoch 622/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.1222 - val_mse: 0.1222\n",
            "Epoch 623/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.1228 - val_mse: 0.1228\n",
            "Epoch 624/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1222 - val_mse: 0.1222\n",
            "Epoch 625/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.1259 - val_mse: 0.1259\n",
            "Epoch 626/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.1292 - val_mse: 0.1292\n",
            "Epoch 627/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.1255 - val_mse: 0.1255\n",
            "Epoch 628/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1230 - val_mse: 0.1230\n",
            "Epoch 629/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.1232 - val_mse: 0.1232\n",
            "Epoch 630/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0157 - mse: 0.0157 - val_loss: 0.1248 - val_mse: 0.1248\n",
            "Epoch 631/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1229 - val_mse: 0.1229\n",
            "Epoch 632/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0151 - mse: 0.0151 - val_loss: 0.1202 - val_mse: 0.1202\n",
            "Epoch 633/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.1232 - val_mse: 0.1232\n",
            "Epoch 634/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.1253 - val_mse: 0.1253\n",
            "Epoch 635/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1229 - val_mse: 0.1229\n",
            "Epoch 636/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.1199 - val_mse: 0.1199\n",
            "Epoch 637/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.1159 - val_mse: 0.1159\n",
            "Epoch 638/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1126 - val_mse: 0.1126\n",
            "Epoch 639/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.1162 - val_mse: 0.1162\n",
            "Epoch 640/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 641/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.1139 - val_mse: 0.1139\n",
            "Epoch 642/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.1083 - val_mse: 0.1083\n",
            "Epoch 643/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.1084 - val_mse: 0.1084\n",
            "Epoch 644/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 645/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.1122 - val_mse: 0.1122\n",
            "Epoch 646/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1118 - val_mse: 0.1118\n",
            "Epoch 647/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.1126 - val_mse: 0.1126\n",
            "Epoch 648/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 649/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.1122 - val_mse: 0.1122\n",
            "Epoch 650/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.1111 - val_mse: 0.1111\n",
            "Epoch 651/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.1078 - val_mse: 0.1078\n",
            "Epoch 652/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1053 - val_mse: 0.1053\n",
            "Epoch 653/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1089 - val_mse: 0.1089\n",
            "Epoch 654/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.1114 - val_mse: 0.1114\n",
            "Epoch 655/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1121 - val_mse: 0.1121\n",
            "Epoch 656/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1168 - val_mse: 0.1168\n",
            "Epoch 657/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.1193 - val_mse: 0.1193\n",
            "Epoch 658/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.1156 - val_mse: 0.1156\n",
            "Epoch 659/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 660/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.1168 - val_mse: 0.1168\n",
            "Epoch 661/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1236 - val_mse: 0.1236\n",
            "Epoch 662/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.1218 - val_mse: 0.1218\n",
            "Epoch 663/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.1210 - val_mse: 0.1210\n",
            "Epoch 664/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.1202 - val_mse: 0.1202\n",
            "Epoch 665/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0144 - mse: 0.0144 - val_loss: 0.1170 - val_mse: 0.1170\n",
            "Epoch 666/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.1162 - val_mse: 0.1162\n",
            "Epoch 667/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0113 - mse: 0.0113 - val_loss: 0.1168 - val_mse: 0.1168\n",
            "Epoch 668/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0145 - mse: 0.0145 - val_loss: 0.1167 - val_mse: 0.1167\n",
            "Epoch 669/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.1151 - val_mse: 0.1151\n",
            "Epoch 670/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.1173 - val_mse: 0.1173\n",
            "Epoch 671/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.1187 - val_mse: 0.1187\n",
            "Epoch 672/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1101 - val_mse: 0.1101\n",
            "Epoch 673/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1054 - val_mse: 0.1054\n",
            "Epoch 674/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.1062 - val_mse: 0.1062\n",
            "Epoch 675/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1070 - val_mse: 0.1070\n",
            "Epoch 676/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.1084 - val_mse: 0.1084\n",
            "Epoch 677/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.1099 - val_mse: 0.1099\n",
            "Epoch 678/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.1133 - val_mse: 0.1133\n",
            "Epoch 679/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.1131 - val_mse: 0.1131\n",
            "Epoch 680/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1048 - val_mse: 0.1048\n",
            "Epoch 681/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1063 - val_mse: 0.1063\n",
            "Epoch 682/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0137 - mse: 0.0137 - val_loss: 0.1082 - val_mse: 0.1082\n",
            "Epoch 683/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.1074 - val_mse: 0.1074\n",
            "Epoch 684/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.0986 - val_mse: 0.0986\n",
            "Epoch 685/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.1021 - val_mse: 0.1021\n",
            "Epoch 686/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.1108 - val_mse: 0.1108\n",
            "Epoch 687/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.1152 - val_mse: 0.1152\n",
            "Epoch 688/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1191 - val_mse: 0.1191\n",
            "Epoch 689/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.1136 - val_mse: 0.1136\n",
            "Epoch 690/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.1118 - val_mse: 0.1118\n",
            "Epoch 691/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.1102 - val_mse: 0.1102\n",
            "Epoch 692/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.1054 - val_mse: 0.1054\n",
            "Epoch 693/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.1058 - val_mse: 0.1058\n",
            "Epoch 694/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.1068 - val_mse: 0.1068\n",
            "Epoch 695/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0136 - mse: 0.0136 - val_loss: 0.1075 - val_mse: 0.1075\n",
            "Epoch 696/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.1040 - val_mse: 0.1040\n",
            "Epoch 697/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.1033 - val_mse: 0.1033\n",
            "Epoch 698/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0159 - mse: 0.0159 - val_loss: 0.1035 - val_mse: 0.1035\n",
            "Epoch 699/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0135 - mse: 0.0135 - val_loss: 0.1046 - val_mse: 0.1046\n",
            "Epoch 700/700\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0142 - mse: 0.0142 - val_loss: 0.1060 - val_mse: 0.1060\n"
          ]
        }
      ],
      "source": [
        "def create_optimized_model(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(512, input_dim=input_dim),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(256),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(128),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "        Dropout(0.2),\n",
        "\n",
        "        Dense(64),\n",
        "        LeakyReLU(alpha=0.1),\n",
        "\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])\n",
        "    return model\n",
        "\n",
        "model = create_optimized_model(X_train.shape[1])\n",
        "history = model.fit(X_train, y_train, epochs=700, batch_size=32, validation_split=0.1, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOEm0bljHQU6",
        "outputId": "e0fda8d3-4663-4320-800d-f4faaf454263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Predicted vs. Actual Sentiment Scores (Test Set):\n",
            "     Actual  Predicted\n",
            "0    0.165   0.120466\n",
            "1    0.516   0.436710\n",
            "2    0.769   0.305050\n",
            "3   -0.303  -0.600214\n",
            "4   -0.479  -0.563444\n",
            "..     ...        ...\n",
            "70  -0.779  -0.175764\n",
            "71   0.296   0.299240\n",
            "72   0.364   0.305248\n",
            "73  -0.181  -0.242410\n",
            "74   0.432   0.260705\n",
            "\n",
            "[75 rows x 2 columns]\n",
            "Mean Squared Error (MSE) on Test Set: 0.0879522310260836\n",
            "Mean Absolute Error (MAE) on Test Set: 0.24549865304152169\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test).flatten()\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(\"Predicted vs. Actual Sentiment Scores (Test Set):\\n\", pd.DataFrame({'Actual': y_test, 'Predicted': y_pred}))\n",
        "print(f\"Mean Squared Error (MSE) on Test Set: {mse}\")\n",
        "print(f\"Mean Absolute Error (MAE) on Test Set: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR6j-txHhh4V"
      },
      "source": [
        "## Saving Model in .pkl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V544CVpUHShi",
        "outputId": "5b817daa-b0e1-48f5-b9b1-93259d7f32b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sentiment_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "joblib.dump({'model': model, 'tokenizer': tokenizer, 'bert_model': bert_model, 'max_len': max_len}, 'sentiment_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCG3stL5hlKb"
      },
      "source": [
        "## Plot Actual vs. Predicted Sentiment Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "O4Mr4-PdHVO7",
        "outputId": "b899676a-1aef-4fef-bcd5-13531b741a1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history.get('val_loss', []), label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REytPmkQhqxY"
      },
      "source": [
        "## Plot the distribution of errors (residuals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "77_nQT9KiyEZ",
        "outputId": "f7bf9c5a-44fb-4009-dfb0-9a1c4063bf9f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "errors = y_test - y_pred\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(errors, bins=30, alpha=0.7, color='blue')\n",
        "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Prediction Errors')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2smQ9WCOkF-X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0500ddf077224311993e90e6c8761299": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0acedf7fc4b54856a3401599c4c1b575": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1191cb75d06d475a96b4112ffd5a0351": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f7f2c806a04f5a9936fcd1cca26795",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_98efec6368af461eb3c13ae940bee34e",
            "value": "â€‡570/570â€‡[00:00&lt;00:00,â€‡29.7kB/s]"
          }
        },
        "19a88c4289e047d89941364fa6bbca89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8ca4d9c71f4724a74ef2af03ab364e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_986d746ef78545248b7848981f2e77f9",
            "value": "â€‡440M/440Mâ€‡[00:02&lt;00:00,â€‡219MB/s]"
          }
        },
        "1b1397f9d3d64145b16f6d2ce0c8c514": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0943783430e45e18b402f7ec91bc36b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0acedf7fc4b54856a3401599c4c1b575",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "1dfa0dba143f495a9a41145b72cb9552": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65be5a8bd61a46ac8f6bd8036b0b9a74",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9ba12b2f82b44a3cb0fe56b5fcaea0eb",
            "value": "config.json:â€‡100%"
          }
        },
        "20a59f96c91c4b22bd5565db386c9f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ceec00b2d44fd79144f775f53786e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b1397f9d3d64145b16f6d2ce0c8c514",
              "IPY_MODEL_87758afdf2ca470e97b27b0e0f346bb8",
              "IPY_MODEL_78ac2776d66c4baea161b859e1dd34db"
            ],
            "layout": "IPY_MODEL_2d672ce54d5d4d738071aee36615ea5a"
          }
        },
        "299e03e41a7448a2b43565e2309bba5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1546ce67484d939ab466cc6c14a0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d672ce54d5d4d738071aee36615ea5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d54641a7ac46c6922fa695f35676b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48be7e4d84b04e94b2f196ac7c46e263",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b4efbb193d74e139e11a2c0cf70e996",
            "value": 440449768
          }
        },
        "337448028f2d4fc9b3fcff45a366733a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ef6c1936d454ac9849e390a28ba7623": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75c2d05a172e4425b86e5dcc84aa5070",
              "IPY_MODEL_8eeb10f324d745488d6d62fe6ea3f119",
              "IPY_MODEL_9423f92c65604873a441dd3194b94358"
            ],
            "layout": "IPY_MODEL_e6b66fdae3f349c6b51b212917ccac0e"
          }
        },
        "42a599a7d40d4c74b0e83016603c8251": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f02cf2caeb4fbda1eee011e8dd9900": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47636113d7b148d8a36e798fed528ae2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48be7e4d84b04e94b2f196ac7c46e263": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d32711412964337a0f2fb31fc96250e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f60fb876b5d439cadd16aede0a7e397": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d1546ce67484d939ab466cc6c14a0b6",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af21d3535a0242438923f9740d89a8cf",
            "value": 570
          }
        },
        "53c3d7a37fa04bdca19ddf4969188447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a1c5fe077b2426ab33c1a78cc99fbd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b4efbb193d74e139e11a2c0cf70e996": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6154a16bb77e4ab18aa53d14abdb4359": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65be5a8bd61a46ac8f6bd8036b0b9a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e761b8c1aa74cf795ac41e915ad4cfd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75c2d05a172e4425b86e5dcc84aa5070": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a599a7d40d4c74b0e83016603c8251",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f7512de7894c4aea8f55aa4a8c9cda37",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "78ac2776d66c4baea161b859e1dd34db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d32711412964337a0f2fb31fc96250e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c3f6d024b01140b4bc5cf00681f52661",
            "value": "â€‡48.0/48.0â€‡[00:00&lt;00:00,â€‡2.98kB/s]"
          }
        },
        "7aac0e7e33714029aa0dbb637f0177db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87758afdf2ca470e97b27b0e0f346bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_337448028f2d4fc9b3fcff45a366733a",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5430d64738b4e1398e7dbab5ed4987b",
            "value": 48
          }
        },
        "8eeb10f324d745488d6d62fe6ea3f119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fa9168564084cd1a565e9ffe4451742",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7aac0e7e33714029aa0dbb637f0177db",
            "value": 466062
          }
        },
        "8fa9168564084cd1a565e9ffe4451742": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9423f92c65604873a441dd3194b94358": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6154a16bb77e4ab18aa53d14abdb4359",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5a1c5fe077b2426ab33c1a78cc99fbd8",
            "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡903kB/s]"
          }
        },
        "9634e556b5974b69b9b5076ccc66c8cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986d746ef78545248b7848981f2e77f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98efec6368af461eb3c13ae940bee34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ba12b2f82b44a3cb0fe56b5fcaea0eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af21d3535a0242438923f9740d89a8cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b85f118eead94e868a85a07fd80a953d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa1d640bd314eb997c957c4114e32ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e37f5f982c2f45e495be8b9b8b19dcc9",
              "IPY_MODEL_bb62bbbab4624dd8b87de7cb2080b221",
              "IPY_MODEL_d293b7d8db6a4b729a4144c45aa58e4a"
            ],
            "layout": "IPY_MODEL_e3ba76403163411885603a260e49ff71"
          }
        },
        "bb62bbbab4624dd8b87de7cb2080b221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53c3d7a37fa04bdca19ddf4969188447",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf52c3d1a65a40aeb5300cb7553582f0",
            "value": 231508
          }
        },
        "bf52c3d1a65a40aeb5300cb7553582f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3f6d024b01140b4bc5cf00681f52661": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5430d64738b4e1398e7dbab5ed4987b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cee26bec055047e9acfb1d4f811e1587": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed90eab72d9f4b1a96d2701a108f7beb",
              "IPY_MODEL_31d54641a7ac46c6922fa695f35676b9",
              "IPY_MODEL_19a88c4289e047d89941364fa6bbca89"
            ],
            "layout": "IPY_MODEL_9634e556b5974b69b9b5076ccc66c8cb"
          }
        },
        "d293b7d8db6a4b729a4144c45aa58e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e761b8c1aa74cf795ac41e915ad4cfd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_20a59f96c91c4b22bd5565db386c9f03",
            "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡666kB/s]"
          }
        },
        "d6f7f2c806a04f5a9936fcd1cca26795": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0943783430e45e18b402f7ec91bc36b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a3e03cad8d419692cc0f5235708e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dfa0dba143f495a9a41145b72cb9552",
              "IPY_MODEL_4f60fb876b5d439cadd16aede0a7e397",
              "IPY_MODEL_1191cb75d06d475a96b4112ffd5a0351"
            ],
            "layout": "IPY_MODEL_47636113d7b148d8a36e798fed528ae2"
          }
        },
        "e37f5f982c2f45e495be8b9b8b19dcc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_299e03e41a7448a2b43565e2309bba5e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b85f118eead94e868a85a07fd80a953d",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "e3ba76403163411885603a260e49ff71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b66fdae3f349c6b51b212917ccac0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed90eab72d9f4b1a96d2701a108f7beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42f02cf2caeb4fbda1eee011e8dd9900",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0500ddf077224311993e90e6c8761299",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "f7512de7894c4aea8f55aa4a8c9cda37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe8ca4d9c71f4724a74ef2af03ab364e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}